{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "co_training_reimplementation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdGOpCHInBS7",
        "outputId": "3caf04ba-f0be-43cc-81a9-af72d5812b49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOhTDp7kpTXV"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def load_amazon(n_features, filename):\n",
        "    \"\"\"\n",
        "    Load amazon reviews\n",
        "    \"\"\"\n",
        "    mat = loadmat(filename)\n",
        "    \n",
        "    xx=mat['xx']\n",
        "    yy=mat['yy']\n",
        "    offset=mat['offset']\n",
        "    \n",
        "    x=xx[:n_features,:].toarray().T#n_samples X n_features\n",
        "    y=yy.ravel()\n",
        "    \n",
        "    return x, y, offset\n",
        "\n",
        "def shuffle1(x, y):\n",
        "    \"\"\"\n",
        "    shuffle data (used by split)\n",
        "    \"\"\"\n",
        "    index_shuf = np.arange(x.shape[0])\n",
        "    np.random.shuffle(index_shuf)\n",
        "    x=x[index_shuf,:]\n",
        "    y=y[index_shuf]\n",
        "    return x,y\n",
        "\n",
        "def to_one_hot(a):\n",
        "    b = np.zeros((len(a), 2))\n",
        "    b[np.arange(len(a)), a] = 1\n",
        "    return b\n",
        "\n",
        "def split_data(d_s_ind,d_t_ind,x,y,offset,n_tr_samples,r_seed=0):\n",
        "\n",
        "    # x = normalize(x, axis=0, norm='max')\n",
        "    # x = np.log(1.+x)\n",
        "    np.random.seed(r_seed)\n",
        "    x_s_tr = x[offset[d_s_ind,0]:offset[d_s_ind,0]+n_tr_samples,:]\n",
        "    x_t_tr = x[offset[d_t_ind,0]:offset[d_t_ind,0]+n_tr_samples,:]\n",
        "    x_s_tst = x[offset[d_s_ind,0]+n_tr_samples:offset[d_s_ind+1,0],:]\n",
        "    x_t_tst = x[offset[d_t_ind,0]+n_tr_samples:offset[d_t_ind+1,0],:]\n",
        "    y_s_tr = y[offset[d_s_ind,0]:offset[d_s_ind,0]+n_tr_samples]\n",
        "    y_t_tr = y[offset[d_t_ind,0]:offset[d_t_ind,0]+n_tr_samples]\n",
        "    y_s_tst = y[offset[d_s_ind,0]+n_tr_samples:offset[d_s_ind+1,0]]\n",
        "    y_t_tst = y[offset[d_t_ind,0]+n_tr_samples:offset[d_t_ind+1,0]]\n",
        "    x_s_tr,y_s_tr=shuffle1(x_s_tr,y_s_tr)\n",
        "    x_t_tr,y_t_tr=shuffle1(x_t_tr,y_t_tr)\n",
        "    x_s_tst,y_s_tst=shuffle1(x_s_tst,y_s_tst)\n",
        "    x_t_tst,y_t_tst=shuffle1(x_t_tst,y_t_tst)\n",
        "    y_s_tr[y_s_tr==-1]=0\n",
        "    y_t_tr[y_t_tr==-1]=0\n",
        "    y_s_tst[y_s_tst==-1]=0\n",
        "    y_t_tst[y_t_tst==-1]=0\n",
        "\n",
        "    y_s_tr=to_one_hot(y_s_tr)\n",
        "    y_t_tr=to_one_hot(y_t_tr)\n",
        "    y_s_tst=to_one_hot(y_s_tst)\n",
        "    y_t_tst=to_one_hot(y_t_tst)\n",
        "\n",
        "    return x_s_tr,y_s_tr,x_t_tr,y_t_tr,x_s_tst,y_s_tst,x_t_tst,y_t_tst\n",
        "\n",
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.compat.v1.sqrt(in_dim / 2.)\n",
        "    print(size)\n",
        "    return tf.compat.v1.random_normal(shape=size, stddev=xavier_stddev)\n",
        "\n",
        "def turn_tfidf(x):\n",
        "    df = (x > 0.).sum(axis=0)\n",
        "    idf = np.log(1.* len(x)/(df+1))\n",
        "    return np.log(1.+x) * idf[None, :]\n",
        "\n",
        "def turn_one_hot(x):\n",
        "    return (x > 0.).astype('float32')\n",
        "\n",
        "def identity(x):\n",
        "    return x\n",
        "\n",
        "\n",
        "class MLP(object):\n",
        "    def __init__(self, name, dims, activations):\n",
        "        newdims = []\n",
        "        for dim in dims:\n",
        "            newdims.append(int(dim))\n",
        "        self.name = name\n",
        "        self.dims = newdims\n",
        "        self.activations = activations\n",
        "        self.weights = []\n",
        "        self.biases = []\n",
        "        self._initialize()\n",
        "\n",
        "    @property\n",
        "    def parameters(self):\n",
        "        return self.weights + self.biases\n",
        "\n",
        "    def _initialize(self):\n",
        "        for i in range(len(self.dims)-1):\n",
        "            w = tf.compat.v1.Variable(xavier_init([self.dims[i], self.dims[i+1]]), name=self.name+'_W_{0}'.format(i))\n",
        "            b = tf.compat.v1.Variable(xavier_init([self.dims[i+1]]), name=self.name+'_b_{0}'.format(i))\n",
        "            self.weights.append(w)\n",
        "            self.biases.append(b)\n",
        "\n",
        "    def apply(self, x):\n",
        "        out = x\n",
        "        for activation, weight, bias in zip(self.activations, self.weights, self.biases):\n",
        "            out = activation(tf.compat.v1.add(tf.compat.v1.matmul(out, weight), bias))\n",
        "        return out\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOyQSp3pp-Xx"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def xavier_init(size):\n",
        "    in_dim = size[0]\n",
        "    xavier_stddev = 1. / tf.compat.v1.sqrt(in_dim / 2.)\n",
        "    return tf.compat.v1.random_normal(shape=size, stddev=xavier_stddev)\n",
        "\n",
        "def shuffle2(arrays):\n",
        "    \"\"\"\n",
        "    shuffle data (used by split)\n",
        "    \"\"\"\n",
        "    index_shuf = np.arange(arrays[0].shape[0])\n",
        "    np.random.shuffle(index_shuf)\n",
        "    return [array[index_shuf] for array in arrays]\n",
        "\n",
        "\n",
        "class BaseAdaptation(object):\n",
        "    def __init__(self, source_domain=0, target_domain=3, **kwargs):\n",
        "        self.source_domain = source_domain\n",
        "        self.target_domain = target_domain\n",
        "        self.learning_rate = 1e-5\n",
        "        self.data_load_from = '/content/drive/My Drive/amazon.mat'\n",
        "        self.batch_size = 200\n",
        "        self.model_save_to = '/content/drive/My Drive/output/{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.model_load_from = self.model_save_to\n",
        "        self.n_input = 5000\n",
        "        self.n_hidden_1 = 50\n",
        "        self.n_classes = 2\n",
        "        self.d_hidden = 50\n",
        "        self.model_built = False\n",
        "        self.tolerate_time = 20\n",
        "        self.alpha = 1.\n",
        "        self.sess = None\n",
        "\n",
        "    def build_model(self):\n",
        "        # Extract information with autoencoder and train source domain classifier on extracted information\n",
        "        self.model_built = True\n",
        "        n_hidden_1 = self.n_hidden_1\n",
        "        n_classes = self.n_classes\n",
        "\n",
        "        def encoding(x, weight, bias):\n",
        "            layer_1 = tf.compat.v1.add(tf.compat.v1.matmul(x, weight), bias)\n",
        "            layer_1 = tf.compat.v1.nn.sigmoid(layer_1)\n",
        "            return layer_1\n",
        "\n",
        "        def decoding(x, weight, bias):\n",
        "            output = tf.compat.v1.nn.relu(tf.compat.v1.add(tf.compat.v1.matmul(x, weight), bias))\n",
        "            return output\n",
        "\n",
        "        def predict(x, weights, biases):\n",
        "            out_layer = tf.compat.v1.matmul(x, weights['out']) + biases['out']\n",
        "            return out_layer\n",
        "\n",
        "        def matchnorm(x1, x2):\n",
        "            return tf.compat.v1.sqrt(tf.compat.v1.reduce_sum(tf.compat.v1.pow(x1 - x2, 2)))\n",
        "            # return ((x1-x2)**2).sum().sqrt()\n",
        "\n",
        "        def scm(sx1, sx2, k):\n",
        "            ss1 = tf.compat.v1.reduce_mean(tf.compat.v1.pow(sx1, k), 0)\n",
        "            ss2 = tf.compat.v1.reduce_mean(tf.compat.v1.pow(sx2, k), 0)\n",
        "            return matchnorm(ss1, ss2)\n",
        "\n",
        "        def mmatch(x1, x2, n_moments):\n",
        "            mx1 = tf.compat.v1.reduce_mean(x1, 0)\n",
        "            mx2 = tf.compat.v1.reduce_mean(x2, 0)\n",
        "            sx1 = x1 - mx1\n",
        "            sx2 = x2 - mx2\n",
        "            dm = matchnorm(mx1, mx2)\n",
        "            scms = dm\n",
        "            for i in range(n_moments - 1):\n",
        "                scms += scm(sx1, sx2, i + 2)\n",
        "            return scms\n",
        "\n",
        "        # tf Graph input\n",
        "        self.X_s = tf.compat.v1.placeholder(\"float\", [None, self.n_input])\n",
        "        self.X_t = tf.compat.v1.placeholder(\"float\", [None, self.n_input])\n",
        "        self.Y_s = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "        self.Y_t = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "        # Store layers weight & bias\n",
        "        self.weights = {\n",
        "            'h_e': tf.compat.v1.Variable(xavier_init([self.n_input, n_hidden_1])),\n",
        "            'h_d': tf.compat.v1.Variable(xavier_init([self.n_hidden_1, self.n_input])),\n",
        "        }\n",
        "        self.biases = {\n",
        "            'b_e': tf.compat.v1.Variable(tf.compat.v1.zeros(shape=[n_hidden_1])),\n",
        "            'b_d': tf.compat.v1.Variable(tf.compat.v1.zeros(shape=[self.n_input])),\n",
        "        }\n",
        "\n",
        "        self.theta_A = [self.weights['h_e'], self.weights['h_d'], self.biases['b_e'], self.biases['b_d']]\n",
        "\n",
        "        # Autoencoder\n",
        "        self.encoding_s = encoding(self.X_s, self.weights['h_e'], self.biases['b_e'])\n",
        "        self.decoding_s = decoding(self.encoding_s, self.weights['h_d'], self.biases['b_d'])\n",
        "\n",
        "        self.encoding_t = encoding(self.X_t, self.weights['h_e'], self.biases['b_e'])\n",
        "        self.decoding_t = decoding(self.encoding_t, self.weights['h_d'], self.biases['b_d'])\n",
        "\n",
        "        self.R_loss = (tf.compat.v1.reduce_mean(tf.compat.v1.square(self.decoding_s - self.X_s)) +\n",
        "                       tf.compat.v1.reduce_mean(tf.compat.v1.square(self.decoding_t - self.X_t)))   # Reconstruction loss\n",
        "\n",
        "        self.D_loss = mmatch(self.encoding_s, self.encoding_t, 5)               # Distribution loss\n",
        "\n",
        "        self.A_loss = self.R_loss + self.alpha * self.D_loss                    # Auto-encode loss\n",
        "        self.A_solver = (tf.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate * 50)\n",
        "                       .minimize(self.A_loss, var_list=self.theta_A))\n",
        "        # Build classifier on encoded feature representation\n",
        "        self.mlp = MLP(name='output_mlp', dims=[self.n_hidden_1, self.n_hidden_1, n_classes],\n",
        "                  activations=[tf.compat.v1.nn.relu, identity])\n",
        "        self.theta_C = self.mlp.parameters\n",
        "        self.pred_s = self.mlp.apply(self.encoding_s)\n",
        "        self.pred_t = self.mlp.apply(self.encoding_t)\n",
        "        self.C_loss = tf.compat.v1.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits(logits=self.pred_s, labels=self.Y_s))\n",
        "        self.C_solver = (tf.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate * 50)\n",
        "                       .minimize(self.C_loss, var_list=self.theta_C))\n",
        "\n",
        "    def train(self):\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph)\n",
        "\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            batch_size = self.batch_size\n",
        "            x, y, offset = load_amazon(5000, self.data_load_from)\n",
        "\n",
        "            x_s_tr, y_s_tr, x_t_tr, y_t_tr, x_s_tst, y_s_tst, x_t_tst, y_t_tst = split_data(self.source_domain,\n",
        "                                                                                            self.target_domain,\n",
        "                                                                                            x, y, offset, 2000)\n",
        "            saver = tf.compat.v1.train.Saver()\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            # Do auto-encoding\n",
        "            for epoch in range(500):\n",
        "                A_loss_num = 0.\n",
        "                R_loss_num = 0.\n",
        "                D_loss_num = 0.\n",
        "                _, A_loss_curr, R_loss_curr, D_loss_curr = self.sess.run(\n",
        "                    [self.A_solver, self.A_loss, self.R_loss, self.D_loss],\n",
        "                    feed_dict={self.X_s: x_s_tr[i * batch_size:(i + 1) * batch_size, ],\n",
        "                               self.X_t: x_t_tr[i * batch_size:(i + 1) * batch_size, ],\n",
        "                               }\n",
        "                )\n",
        "                A_loss_num += A_loss_curr\n",
        "                R_loss_num += R_loss_curr\n",
        "                D_loss_num += D_loss_curr\n",
        "                x_s_tr, y_s_tr = shuffle2([x_s_tr, y_s_tr])\n",
        "                x_t_tr, y_t_tr = shuffle2([x_t_tr, y_t_tr])\n",
        "                batch_num = len(x_s_tr) / batch_size\n",
        "                print('A_loss:{0}'.format(A_loss_num / batch_num))\n",
        "                print('R_loss:{0}'.format(R_loss_num / batch_num))\n",
        "                print('D_loss:{0}'.format(D_loss_num / batch_num))\n",
        "            # Do classification\n",
        "            wait_times = 0\n",
        "            best_result = 0.\n",
        "            for epoch in range(500):\n",
        "                total_loss = 0.\n",
        "                C_loss_num = 0.\n",
        "                D_loss_num = 0.\n",
        "                accuracy_num = 0.\n",
        "\n",
        "                for i in range(len(x_s_tr) / batch_size):\n",
        "                    _, loss_curr, C_loss_curr, D_loss_curr, accuracy = self.sess.run(\n",
        "                        [self.solver, self.loss, self.C_loss, self.D_loss, self.accuracy_s],\n",
        "                        feed_dict={self.X_s: x_s_tr[i * batch_size:(i + 1) * batch_size, ],\n",
        "                                   self.X_t: x_t_tr[i * batch_size:(i + 1) * batch_size, ],\n",
        "                                   self.Y_s: y_s_tr[i * batch_size:(i + 1) * batch_size, ]}\n",
        "                    )\n",
        "                    total_loss += loss_curr\n",
        "                    D_loss_num += D_loss_curr\n",
        "                    C_loss_num += C_loss_curr\n",
        "                    accuracy_num += accuracy\n",
        "                x_s_tr, y_s_tr = shuffle2([x_s_tr, y_s_tr])\n",
        "                x_t_tr, y_t_tr = shuffle2([x_t_tr, y_t_tr])\n",
        "                batch_num = len(x_s_tr) / batch_size\n",
        "                print('total_loss:{0}'.format(total_loss / batch_num))\n",
        "                print('C_loss:{0}'.format(C_loss_num / batch_num))\n",
        "                print('D_loss:{0}'.format(D_loss_num / batch_num))\n",
        "                print('train_accuracy:{0}'.format(accuracy_num / batch_num))\n",
        "                # Temporarily valid on test set\n",
        "                test_accuracy = self.accuracy_t.eval({self.X_t: x_t_tst, self.Y_t: y_t_tst})\n",
        "                if test_accuracy > best_result:\n",
        "                    best_result = test_accuracy\n",
        "                    wait_times = 0\n",
        "                    print('save model...')\n",
        "                    saver.save(self.sess, self.model_save_to)\n",
        "                    print('done!')\n",
        "                else:\n",
        "                    wait_times += 1\n",
        "                if wait_times >= self.tolerate_time:\n",
        "                    print('best_result:{0}'.format(best_result))\n",
        "                    break\n",
        "                print(\"Test accuracy:\", test_accuracy)\n",
        "\n",
        "    def get_hidden_state(self, X):\n",
        "        if self.sess is None:\n",
        "            self.graph = tf.compat.v1.Graph()\n",
        "            self.sess = tf.compat.v1.Session(graph=self.graph)\n",
        "\n",
        "            with self.graph.as_default():\n",
        "                self.build_model()\n",
        "                saver = tf.compat.v1.train.Saver()\n",
        "                try:\n",
        "                    saver.restore(self.sess, self.model_load_from)\n",
        "                except:\n",
        "                    self.train()\n",
        "                    saver.restore(self.sess, self.model_save_to)\n",
        "        hidden, = self.sess.run([self.encoding_s], feed_dict={self.X_s: X})\n",
        "        return hidden\n",
        "\n",
        "    def get_prediction(self, X):\n",
        "        if self.sess is None:\n",
        "            self.graph = tf.compat.v1.Graph()\n",
        "            self.sess = tf.compat.v1.Session(graph=self.graph)\n",
        "\n",
        "            with self.graph.as_default():\n",
        "                self.build_model()\n",
        "                saver = tf.compat.v1.train.Saver()\n",
        "                try:\n",
        "                    saver.restore(self.sess, self.model_load_from)\n",
        "                except:\n",
        "                    self.train()\n",
        "                    saver.restore(self.sess, self.model_save_to)\n",
        "        prediction, = self.sess.run([self.pred_s], feed_dict={self.X_s: X})\n",
        "        return prediction\n",
        "\n",
        "\n",
        "class CMDAdaptation(object):\n",
        "    def __init__(self, source_domain=0, target_domain=3, **kwargs):\n",
        "        self.source_domain =source_domain\n",
        "        self.target_domain = target_domain\n",
        "        self.learning_rate = 1e-5\n",
        "        self.data_load_from = '/content/drive/My Drive/amazon.mat'\n",
        "        self.batch_size = 200\n",
        "        self.model_save_to = '/content/drive/My Drive/output/{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.model_load_from = self.model_save_to\n",
        "        self.n_input = 5000\n",
        "        self.n_hidden_1 = 50\n",
        "        self.n_classes = 2\n",
        "        self.d_hidden = 50\n",
        "        self.model_built = False\n",
        "        self.tolerate_time = 20\n",
        "        self.alpha = 1.\n",
        "        self.sess = None\n",
        "\n",
        "    def build_model(self):\n",
        "        # tf.compat.v1.reset_default_graph()\n",
        "        self.model_built = True\n",
        "        n_hidden_1 = self.n_hidden_1\n",
        "        n_classes = self.n_classes\n",
        "\n",
        "        def encoding(x, weights, biases):\n",
        "            layer_1 = tf.compat.v1.add(tf.compat.v1.matmul(x, weights['h1']), biases['b1'])\n",
        "            layer_1 = tf.compat.v1.nn.sigmoid(layer_1)\n",
        "            return layer_1\n",
        "\n",
        "        def predict(x, weights, biases):\n",
        "            out_layer = tf.compat.v1.matmul(x, weights['out']) + biases['out']\n",
        "            return out_layer\n",
        "\n",
        "        def matchnorm(x1, x2):\n",
        "            return tf.compat.v1.sqrt(tf.compat.v1.reduce_sum(tf.compat.v1.pow(x1 - x2, 2)))\n",
        "            # return ((x1-x2)**2).sum().sqrt()\n",
        "\n",
        "        def scm(sx1, sx2, k):\n",
        "            ss1 = tf.compat.v1.reduce_mean(tf.compat.v1.pow(sx1, k), 0)\n",
        "            ss2 = tf.compat.v1.reduce_mean(tf.compat.v1.pow(sx2, k), 0)\n",
        "            return matchnorm(ss1, ss2)\n",
        "\n",
        "        def mmatch(x1, x2, n_moments):\n",
        "            mx1 = tf.compat.v1.reduce_mean(x1, 0)\n",
        "            mx2 = tf.compat.v1.reduce_mean(x2, 0)\n",
        "            sx1 = x1 - mx1\n",
        "            sx2 = x2 - mx2\n",
        "            dm = matchnorm(mx1, mx2)\n",
        "            scms = dm\n",
        "            for i in range(n_moments - 1):\n",
        "                scms += scm(sx1, sx2, i + 2)\n",
        "            return scms\n",
        "\n",
        "        # tf Graph input\n",
        "        self.X_s = tf.compat.v1.placeholder(\"float\", [None, self.n_input])\n",
        "        self.X_t = tf.compat.v1.placeholder(\"float\", [None, self.n_input])\n",
        "        self.Y_s = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "        self.Y_t = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "        # Store layers weight & bias\n",
        "        self.weights = {\n",
        "            'h1': tf.compat.v1.Variable(xavier_init([self.n_input, n_hidden_1])),\n",
        "            'out': tf.compat.v1.Variable(xavier_init([n_hidden_1, n_classes])),\n",
        "        }\n",
        "        self.biases = {\n",
        "            'b1': tf.compat.v1.Variable(tf.compat.v1.zeros(shape=[n_hidden_1])),\n",
        "            'out': tf.compat.v1.Variable(tf.compat.v1.zeros(shape=[n_classes])),\n",
        "        }\n",
        "\n",
        "        self.theta = list(self.weights.values()) + list(self.biases.values())\n",
        "\n",
        "        # Construct model\n",
        "        self.encoding_s = encoding(self.X_s, self.weights, self.biases)\n",
        "        self.pred_s = predict(self.encoding_s, self.weights, self.biases)\n",
        "        self.accuracy_s = tf.compat.v1.reduce_mean(tf.compat.v1.cast(tf.compat.v1.equal(tf.compat.v1.argmax(self.pred_s, 1),\n",
        "                                                              tf.compat.v1.argmax(self.Y_s, 1)), 'float'))\n",
        "\n",
        "        self.encoding_t = encoding(self.X_t, self.weights, self.biases)\n",
        "        self.pred_t = predict(self.encoding_t, self.weights, self.biases)\n",
        "        self.accuracy_t = tf.compat.v1.reduce_mean(tf.compat.v1.cast(tf.compat.v1.equal(tf.compat.v1.argmax(self.pred_t, 1),\n",
        "                                                              tf.compat.v1.argmax(self.Y_t, 1)), 'float'))\n",
        "\n",
        "        self.C_loss = tf.compat.v1.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits(logits=self.pred_s,\n",
        "                                                                             labels=self.Y_s))\n",
        "        self.D_loss = mmatch(self.encoding_s, self.encoding_t, 5)\n",
        "        self.loss = self.C_loss + self.alpha * self.D_loss\n",
        "        self.solver = (tf.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate * 50)\n",
        "                  .minimize(self.loss, var_list=self.theta))\n",
        "\n",
        "    def train(self):\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph)\n",
        "\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            batch_size = self.batch_size\n",
        "            x, y, offset = load_amazon(5000, self.data_load_from)\n",
        "\n",
        "            # Launch the graph\n",
        "            x_s_tr, y_s_tr, x_t_tr, y_t_tr, x_s_tst, y_s_tst, x_t_tst, y_t_tst = split_data(self.source_domain,\n",
        "                                                                                            self.target_domain,\n",
        "                                                                                            x, y, offset, 2000)\n",
        "            # Try to initialize model\n",
        "            saver = tf.compat.v1.train.Saver()\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            wait_times = 0\n",
        "            best_result = 0.\n",
        "            while True:\n",
        "                total_loss = 0.\n",
        "                C_loss_num = 0.\n",
        "                D_loss_num = 0.\n",
        "                accuracy_num = 0.\n",
        "\n",
        "                for i in range(len(x_s_tr) / batch_size):\n",
        "                    _, loss_curr, C_loss_curr, D_loss_curr, accuracy = self.sess.run(\n",
        "                        [self.solver, self.loss, self.C_loss, self.D_loss, self.accuracy_s],\n",
        "                        feed_dict={self.X_s: x_s_tr[i * batch_size:(i + 1) * batch_size, ],\n",
        "                                   self.X_t: x_t_tr[i * batch_size:(i + 1) * batch_size, ],\n",
        "                                   self.Y_s: y_s_tr[i * batch_size:(i + 1) * batch_size, ]}\n",
        "                    )\n",
        "                    total_loss += loss_curr\n",
        "                    D_loss_num += D_loss_curr\n",
        "                    C_loss_num += C_loss_curr\n",
        "                    accuracy_num += accuracy\n",
        "                x_s_tr, y_s_tr = shuffle2([x_s_tr, y_s_tr])\n",
        "                x_t_tr, y_t_tr = shuffle2([x_t_tr, y_t_tr])\n",
        "                batch_num = len(x_s_tr) / batch_size\n",
        "                print('total_loss:{0}'.format(total_loss / batch_num))\n",
        "                print('C_loss:{0}'.format(C_loss_num / batch_num))\n",
        "                print('D_loss:{0}'.format(D_loss_num / batch_num))\n",
        "                print('train_accuracy:{0}'.format(accuracy_num / batch_num))\n",
        "                # Temporarily valid on test set\n",
        "                test_accuracy = self.accuracy_t.eval({self.X_t: x_t_tst, self.Y_t: y_t_tst},\n",
        "                                                     session=self.sess)\n",
        "                if test_accuracy > best_result:\n",
        "                    best_result = test_accuracy\n",
        "                    wait_times = 0\n",
        "                    print('save model...')\n",
        "                    saver.save(self.sess, self.model_save_to)\n",
        "                    print('done!')\n",
        "                else:\n",
        "                    wait_times += 1\n",
        "                if wait_times >= self.tolerate_time:\n",
        "                    print('best_result:{0}'.format(best_result))\n",
        "                    break\n",
        "                print(\"Test accuracy:\", test_accuracy)\n",
        "\n",
        "    def get_hidden_state(self, X):\n",
        "        if self.sess is None:\n",
        "            self.graph = tf.compat.v1.Graph()\n",
        "            self.sess = tf.compat.v1.Session(graph=self.graph)\n",
        "            with self.graph.as_default():\n",
        "                self.build_model()\n",
        "                saver = tf.compat.v1.train.Saver()\n",
        "                try:\n",
        "                    saver.restore(self.sess, self.model_load_from)\n",
        "                except:\n",
        "                    self.train()\n",
        "                    saver.restore(self.sess, self.model_save_to)\n",
        "        hidden, = self.sess.run([self.encoding_s], feed_dict={self.X_s: X})\n",
        "        return hidden\n",
        "\n",
        "    def get_prediction(self, X):\n",
        "        if self.sess is None:\n",
        "            self.graph = tf.compat.v1.Graph()\n",
        "            self.sess = tf.compat.v1.Session(graph=self.graph)\n",
        "\n",
        "            with self.graph.as_default():\n",
        "                self.build_model()\n",
        "                saver = tf.compat.v1.train.Saver()\n",
        "                try:\n",
        "                    saver.restore(self.sess, self.model_load_from)\n",
        "                except:\n",
        "                    self.train()\n",
        "                    saver.restore(self.sess, self.model_save_to)\n",
        "        prediction, = self.sess.run([self.pred_s], feed_dict={self.X_s: X})\n",
        "        # It is better to use non-softmax value\n",
        "        # prediction = np.exp(prediction-prediction.max(axis=1, keepdims=True))\n",
        "        # prediction /= prediction.sum(axis=1, keepdims=True)\n",
        "        return prediction\n",
        "\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "#    adaptation = CMDAdaptation()\n",
        "#    adaptation.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn2AcI4prDjm",
        "outputId": "bdca6fad-7e90-48eb-b475-d7920e7bdae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from numpy.linalg import matrix_rank\n",
        "from numpy.linalg import svd\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import average_precision_score\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def shuffle3(arrays):\n",
        "    \"\"\"\n",
        "    shuffle data (used by split)\n",
        "    \"\"\"\n",
        "    index_shuf = np.arange(arrays[0].shape[0])\n",
        "    np.random.shuffle(index_shuf)\n",
        "    return [array[index_shuf] for array in arrays]\n",
        "\n",
        "\n",
        "def plot_dist(x_s, x_t, save_to):\n",
        "    pca = PCA(n_components=2)\n",
        "    x = np.concatenate([x_s, x_t])\n",
        "    pca.fit(x)\n",
        "    x_s_hat = pca.transform(x_s)\n",
        "    x_t_hat = pca.transform(x_t)\n",
        "    plt.scatter(x_s_hat[:, 0], x_s_hat[:, 1], color='r', alpha=.4, s=1)\n",
        "    plt.scatter(x_t_hat[:, 0], x_t_hat[:, 1], color='b', alpha=.4, s=1)\n",
        "    plt.savefig(save_to, dpi=72)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "class SourceOnly(object):\n",
        "    def __init__(self, source_domain=0, target_domain=3, **kwargs):\n",
        "        self.source_domain = source_domain\n",
        "        self.target_domain = target_domain\n",
        "        self.learning_rate = 5e-3\n",
        "        self.data_load_from = '/content/drive/My Drive/amazon.mat'\n",
        "        self.batch_size = 200\n",
        "        self.model_save_to = '/content/drive/My Drive/output/SourceOnly_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.model_load_from = self.model_save_to\n",
        "        self.n_input = 5000\n",
        "        self.n_hidden_1 = 50\n",
        "        self.n_classes = 2\n",
        "        self.d_hidden = 50\n",
        "        self.model_built = False\n",
        "        self.tolerate_time = 20\n",
        "        self.alpha = 1.\n",
        "        self.sess = None\n",
        "\n",
        "    def build_model(self):\n",
        "        # tf.compat.v1.compat.v1.reset_default_graph()\n",
        "        self.model_built = True\n",
        "        n_hidden_1 = self.n_hidden_1\n",
        "        n_classes = self.n_classes\n",
        "\n",
        "        def encoding(x, weights, biases):\n",
        "            layer_1 = tf.compat.v1.compat.v1.add(tf.compat.v1.compat.v1.matmul(x, weights['h1']), biases['b1'])\n",
        "            layer_1 = tf.compat.v1.compat.v1.nn.sigmoid(layer_1)\n",
        "            return layer_1\n",
        "\n",
        "        def predict(x, weights, biases):\n",
        "            out_layer = tf.compat.v1.compat.v1.matmul(x, weights['out']) + biases['out']\n",
        "            return out_layer\n",
        "\n",
        "        # tf Graph input\n",
        "        self.X = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])\n",
        "        self.Y = tf.compat.v1.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "        # Store layers weight & bias\n",
        "        self.weights = {\n",
        "            'h1': tf.compat.v1.compat.v1.Variable(xavier_init([self.n_input, n_hidden_1])),\n",
        "            'out': tf.compat.v1.compat.v1.Variable(xavier_init([n_hidden_1, n_classes])),\n",
        "        }\n",
        "        self.biases = {\n",
        "            'b1': tf.compat.v1.compat.v1.Variable(tf.compat.v1.compat.v1.zeros(shape=[n_hidden_1])),\n",
        "            'out': tf.compat.v1.compat.v1.Variable(tf.compat.v1.compat.v1.zeros(shape=[n_classes])),\n",
        "        }\n",
        "\n",
        "        self.theta = list(self.weights.values()) + list(self.biases.values())\n",
        "\n",
        "        self.encoding = encoding(self.X, self.weights, self.biases)\n",
        "        self.pred = predict(self.encoding, self.weights, self.biases)\n",
        "        self.accuracy = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.cast(tf.compat.v1.compat.v1.equal(tf.compat.v1.compat.v1.argmax(self.pred, 1),\n",
        "                                                        tf.compat.v1.compat.v1.argmax(self.Y, 1)), 'float'))\n",
        "        self.C_loss = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.nn.softmax_cross_entropy_with_logits(logits=self.pred,\n",
        "                                                                             labels=self.Y))\n",
        "        l2_norm = 0.\n",
        "        for tensor in list(self.weights.values()):\n",
        "            l2_norm += tf.compat.v1.compat.v1.reduce_sum(tf.compat.v1.compat.v1.abs(tensor))\n",
        "        self.loss = self.C_loss + 0.0001 * l2_norm\n",
        "        self.solver = (tf.compat.v1.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                       .minimize(self.loss, var_list=self.theta))\n",
        "\n",
        "    def train(self, x_train, y_train, x_valid, y_valid, x_test, y_test, x_s_tst, x_t_tst):\n",
        "        self.graph = tf.compat.v1.compat.v1.Graph()\n",
        "        self.sess = tf.compat.v1.compat.v1.Session(graph=self.graph)\n",
        "\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            batch_size = self.batch_size\n",
        "            # Initialize model\n",
        "            saver = tf.compat.v1.compat.v1.train.Saver()\n",
        "            self.sess.run(tf.compat.v1.compat.v1.global_variables_initializer())\n",
        "            wait_times = 0\n",
        "            best_result = 0.\n",
        "            while True:\n",
        "                _, loss_curr, accuracy = self.sess.run(\n",
        "                [self.solver, self.loss, self.accuracy],\n",
        "                feed_dict={self.X: x_train,\n",
        "                           self.Y: y_train}\n",
        "                )\n",
        "                valid_accuracy = self.accuracy.eval({self.X: x_valid, self.Y: y_valid}, session=self.sess)\n",
        "                if valid_accuracy > best_result:\n",
        "                    best_result = valid_accuracy\n",
        "                    wait_times = 0\n",
        "                    print('save model...')\n",
        "                    saver.save(self.sess, self.model_save_to)\n",
        "                    # print('done!')\n",
        "                else:\n",
        "                    wait_times += 1\n",
        "                if wait_times >= self.tolerate_time:\n",
        "                    break\n",
        "            saver.restore(self.sess, self.model_save_to)\n",
        "            encoding_s, = self.sess.run(\n",
        "                [self.encoding],\n",
        "                feed_dict={self.X: x_s_tst,})\n",
        "            encoding_t, = self.sess.run(\n",
        "                [self.encoding],\n",
        "                feed_dict={self.X: x_t_tst,})\n",
        "            plot_dist(encoding_s, encoding_t, 'source_{0}_{1}.pdf'.format(self.source_domain, self.target_domain))\n",
        "\n",
        "\n",
        "class SCMD(object):\n",
        "    def __init__(self, source_domain=0, target_domain=3, **kwargs):\n",
        "        self.source_domain = source_domain\n",
        "        self.target_domain = target_domain\n",
        "        self.learning_rate = 5e-3\n",
        "        self.data_load_from = '/content/drive/My Drive/amazon.mat'\n",
        "        self.batch_size = 200\n",
        "        self.model_save_to = 'output_extend/SCMD_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.model_load_from = self.model_save_to\n",
        "        self.n_input = 5000\n",
        "        self.n_classes = 2\n",
        "        self.model_built = False\n",
        "        self.tolerate_time = 20\n",
        "        self.alpha = 1.\n",
        "        self.belta = 1.\n",
        "        self.gamma = 2.\n",
        "        self.n_hidden_c = 50\n",
        "        self.n_hidden_s = 50\n",
        "        self.n_hidden_t = 10\n",
        "\n",
        "    def build_model(self):\n",
        "        n_classes = self.n_classes\n",
        "\n",
        "        def matchnorm(x1, x2):\n",
        "            return tf.compat.v1.compat.v1.sqrt(tf.compat.v1.compat.v1.reduce_sum(tf.compat.v1.compat.v1.pow(x1 - x2, 2)))\n",
        "\n",
        "        def scm(sx1, sx2, k):\n",
        "            ss1 = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.pow(sx1, k), 0)\n",
        "            ss2 = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.pow(sx2, k), 0)\n",
        "            return matchnorm(ss1, ss2)\n",
        "\n",
        "        def mmatch(x1, x2, n_moments):\n",
        "            mx1 = tf.compat.v1.compat.v1.reduce_mean(x1, 0)\n",
        "            mx2 = tf.compat.v1.compat.v1.reduce_mean(x2, 0)\n",
        "            sx1 = x1 - mx1\n",
        "            sx2 = x2 - mx2\n",
        "            dm = matchnorm(mx1, mx2)\n",
        "            scms = dm\n",
        "            for i in range(n_moments - 1):\n",
        "                scms += scm(sx1, sx2, i + 2)\n",
        "            return scms\n",
        "\n",
        "        # tf Graph input\n",
        "        self.X_s_u = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])  # source unlabeled data\n",
        "        self.X_t_u = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])  # target unlabeled data\n",
        "        self.X_s = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])    # source labeled data\n",
        "        self.Y_s = tf.compat.v1.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "        self.X_t = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])    # target labeled data\n",
        "        self.Y_t = tf.compat.v1.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "        self.common_encode_mlp = MLP(name='common_encode_mlp', dims=[self.n_input, self.n_hidden_c],\n",
        "                                     activations=[tf.compat.v1.compat.v1.nn.sigmoid])\n",
        "        self.target_encode_mlp = MLP(name='target_encode_mlp', dims=[self.n_input, self.n_hidden_t],\n",
        "                                     activations=[tf.compat.v1.compat.v1.nn.sigmoid])\n",
        "        self.common_decode_mlp = MLP(name='common_decode_mlp',\n",
        "                                     dims=[self.n_hidden_c, (self.n_hidden_c + self.n_input) / 2, self.n_input],\n",
        "                              activations=[tf.compat.v1.compat.v1.nn.tanh, tf.compat.v1.compat.v1.nn.relu])\n",
        "        self.target_decode_mlp = MLP(name='target_decode_mlp',\n",
        "                                     dims=[self.n_hidden_t, (self.n_hidden_t + self.n_input) / 2, self.n_input],\n",
        "                                     activations=[tf.compat.v1.compat.v1.nn.tanh, tf.compat.v1.compat.v1.nn.relu])\n",
        "        self.common_output_mlp = MLP(name='common_output_mlp', dims=[self.n_hidden_c, n_classes],\n",
        "                              activations=[identity])\n",
        "\n",
        "        encoding_c_s_u = self.common_encode_mlp.apply(self.X_s_u)\n",
        "        encoding_c_t_u = self.common_encode_mlp.apply(self.X_t_u)\n",
        "        encoding_t_t_u = self.target_encode_mlp.apply(self.X_t_u)\n",
        "        # Get cmd loss\n",
        "        self.cmd_c_loss = mmatch(encoding_c_s_u, encoding_c_t_u, 3)\n",
        "        # Get reconstruction loss\n",
        "        decoding_c_t_u = self.common_decode_mlp.apply(encoding_c_t_u)\n",
        "        decoding_t_t_u = self.target_decode_mlp.apply(encoding_t_t_u)\n",
        "        decoding_t_u = decoding_c_t_u + decoding_t_t_u\n",
        "        self.R_loss = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.square(decoding_t_u - self.X_t_u))\n",
        "        # Get common classification loss\n",
        "        encoding_c_s = self.common_encode_mlp.apply(self.X_s)\n",
        "        pred_s = self.common_output_mlp.apply(encoding_c_s)\n",
        "        self.C_loss = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.nn.softmax_cross_entropy_with_logits(logits=pred_s, labels=self.Y_s))\n",
        "        correct_prediction = tf.compat.v1.compat.v1.equal(tf.compat.v1.compat.v1.argmax(pred_s, 1), tf.compat.v1.compat.v1.argmax(self.Y_s, 1))\n",
        "        self.accuracy_s = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.cast(correct_prediction, \"float\"))\n",
        "        # Build solver\n",
        "        self.theta = (self.common_encode_mlp.parameters +\n",
        "                      self.target_encode_mlp.parameters +\n",
        "                      self.common_decode_mlp.parameters +\n",
        "                      self.target_decode_mlp.parameters +\n",
        "                      self.common_output_mlp.parameters)\n",
        "        l2_norm = 0.\n",
        "        for tensor in self.theta:\n",
        "            if tensor.name.find('W') != 0:\n",
        "                l2_norm += tf.compat.v1.compat.v1.reduce_sum(tf.compat.v1.compat.v1.abs(tensor))\n",
        "        self.loss = (self.R_loss +\n",
        "                     self.alpha * self.C_loss +\n",
        "                     self.gamma * self.cmd_c_loss +\n",
        "                     0.0001 * l2_norm)\n",
        "        self.solver = (tf.compat.v1.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                       .minimize(self.loss, var_list=self.theta))\n",
        "\n",
        "    def train(self, x_s_u, x_t_u, x_s, y_s, x_valid, y_valid, x_test, y_test):\n",
        "        wait_times = 0\n",
        "        best_result = 0.\n",
        "        self.graph = tf.compat.v1.compat.v1.Graph()\n",
        "        self.sess = tf.compat.v1.compat.v1.Session(graph=self.graph)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.compat.v1.global_variables_initializer())\n",
        "            batch_num = len(x_s)/self.batch_size\n",
        "            while True:\n",
        "                (_, c_loss, r_loss, cmd_c_loss, accuracy) = self.sess.run(\n",
        "                    [self.solver, self.C_loss, self.R_loss, self.cmd_c_loss, self.accuracy_s],\n",
        "                    feed_dict={self.X_s_u: x_s_u,\n",
        "                               self.X_t_u: x_t_u,\n",
        "                               self.X_s: x_s,\n",
        "                               self.Y_s: y_s,\n",
        "                               }\n",
        "                )\n",
        "                print('c_loss:{0}'.format(c_loss))\n",
        "                print('r_loss:{0}'.format(r_loss))\n",
        "                print('cmd_c_loss:{0}'.format(cmd_c_loss))\n",
        "                print('accuracy_s:{0}'.format(accuracy))\n",
        "                if accuracy > 0.7:\n",
        "                    valid_accuracy, = \\\n",
        "                        self.sess.run([self.accuracy_s, ],\n",
        "                                      feed_dict={self.X_s: x_valid,\n",
        "                                                 self.Y_s: y_valid,\n",
        "                                                 }\n",
        "                                      )\n",
        "                    if valid_accuracy > best_result:\n",
        "                        best_result = valid_accuracy\n",
        "                        wait_times = 0\n",
        "                        print('Save model...')\n",
        "                        saver.save(self.sess, save_path=self.model_save_to)\n",
        "                        print('Done!')\n",
        "                    else:\n",
        "                        wait_times += 1\n",
        "                    if wait_times >= self.tolerate_time:\n",
        "                        print('best valid result :{0}'.format(best_result))\n",
        "                        break\n",
        "                    print('valid_accuracy:{0}'.format(valid_accuracy))\n",
        "            saver.restore(self.sess, self.model_save_to)\n",
        "            test_accuracy = self.accuracy_s.eval({self.X_s: x_test, self.Y_s: y_test}, session=self.sess)\n",
        "            print('Test accuracy:', test_accuracy)\n",
        "            return test_accuracy\n",
        "\n",
        "\n",
        "class DCMD(SCMD):\n",
        "    def __init__(self, source_domain=0, target_domain=3, **kwargs):\n",
        "        super(DCMD, self).__init__(source_domain, target_domain, **kwargs)\n",
        "        self.model_save_to = 'output_extend/DCMD_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.lamb = 1.\n",
        "\n",
        "    def build_model(self):\n",
        "        n_classes = self.n_classes\n",
        "\n",
        "        def matchnorm(x1, x2):\n",
        "            return tf.compat.v1.compat.v1.sqrt(tf.compat.v1.compat.v1.reduce_sum(tf.compat.v1.compat.v1.pow(x1 - x2, 2)))\n",
        "\n",
        "        def scm(sx1, sx2, k):\n",
        "            ss1 = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.pow(sx1, k), 0)\n",
        "            ss2 = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.pow(sx2, k), 0)\n",
        "            return matchnorm(ss1, ss2)\n",
        "\n",
        "        def mmatch(x1, x2, n_moments):\n",
        "            mx1 = tf.compat.v1.compat.v1.reduce_mean(x1, 0)\n",
        "            mx2 = tf.compat.v1.compat.v1.reduce_mean(x2, 0)\n",
        "            sx1 = x1 - mx1\n",
        "            sx2 = x2 - mx2\n",
        "            dm = matchnorm(mx1, mx2)\n",
        "            scms = dm\n",
        "            for i in range(n_moments - 1):\n",
        "                scms += scm(sx1, sx2, i + 2)\n",
        "            return scms\n",
        "\n",
        "        def get_correlation(mat_a, mat_b):\n",
        "            mat_a = mat_a - tf.compat.v1.compat.v1.reduce_mean(mat_a, axis=0)\n",
        "            mat_b = mat_b - tf.compat.v1.compat.v1.reduce_mean(mat_b, axis=0)\n",
        "            sigma = tf.compat.v1.compat.v1.matmul(tf.compat.v1.compat.v1.transpose(mat_a), mat_b)\n",
        "            mat_a_cov = tf.compat.v1.compat.v1.matmul(tf.compat.v1.compat.v1.transpose(mat_a), mat_a)\n",
        "            mat_b_cov = tf.compat.v1.compat.v1.matmul(tf.compat.v1.compat.v1.transpose(mat_b), mat_b)\n",
        "            return tf.compat.v1.compat.v1.matmul(tf.compat.v1.compat.v1.matmul(tf.compat.v1.compat.v1.diag(tf.compat.v1.compat.v1.pow(tf.compat.v1.compat.v1.diag_part(mat_a_cov), -0.5)), sigma),\n",
        "                             tf.compat.v1.compat.v1.diag(tf.compat.v1.compat.v1.pow(tf.compat.v1.compat.v1.diag_part(mat_b_cov), -0.5)))\n",
        "\n",
        "        # tf Graph input\n",
        "        self.X_s_u = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])  # source unlabeled data\n",
        "        self.X_t_u = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])  # target unlabeled data\n",
        "        self.X_s = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])    # source labeled data\n",
        "        self.Y_s = tf.compat.v1.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "        self.X_t = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])    # target labeled data\n",
        "        self.Y_t = tf.compat.v1.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "        self.common_encode_mlp = MLP(name='common_encode_mlp', dims=[self.n_input, self.n_hidden_c],\n",
        "                                     activations=[tf.compat.v1.compat.v1.nn.sigmoid])\n",
        "        self.target_encode_mlp = MLP(name='target_encode_mlp', dims=[self.n_input, self.n_hidden_t],\n",
        "                                     activations=[tf.compat.v1.compat.v1.nn.sigmoid])\n",
        "        self.common_decode_mlp = MLP(name='common_decode_mlp',\n",
        "                                     dims=[self.n_hidden_c, (self.n_hidden_c + self.n_input) / 2, self.n_input],\n",
        "                              activations=[tf.compat.v1.compat.v1.nn.tanh, tf.compat.v1.compat.v1.nn.relu])\n",
        "        self.target_decode_mlp = MLP(name='target_decode_mlp',\n",
        "                                     dims=[self.n_hidden_t, (self.n_hidden_t + self.n_input) / 2, self.n_input],\n",
        "                                     activations=[tf.compat.v1.compat.v1.nn.tanh, tf.compat.v1.compat.v1.nn.relu])\n",
        "        self.common_output_mlp = MLP(name='common_output_mlp', dims=[self.n_hidden_c, n_classes],\n",
        "                              activations=[identity])\n",
        "\n",
        "        encoding_c_s_u = self.common_encode_mlp.apply(self.X_s_u)\n",
        "        self.encoding_c_s_u = encoding_c_s_u\n",
        "        encoding_c_t_u = self.common_encode_mlp.apply(self.X_t_u)\n",
        "        self.encoding_c_t_u = encoding_c_t_u\n",
        "        encoding_t_t_u = self.target_encode_mlp.apply(self.X_t_u)\n",
        "        self.encoding_t_t_u = encoding_t_t_u\n",
        "        encoding_t_s_u = self.target_encode_mlp.apply(self.X_s_u)\n",
        "        self.encoding_t_s_u = encoding_t_s_u\n",
        "        # Get cmd loss\n",
        "        self.cmd_c_loss = mmatch(encoding_c_s_u, encoding_c_t_u, 3)\n",
        "        self.cmd_t_loss = -mmatch(encoding_t_s_u, encoding_t_t_u, 3)\n",
        "        self.corr_loss = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.abs(get_correlation(encoding_c_t_u, encoding_t_t_u)))\n",
        "        # Get reconstruction loss\n",
        "        decoding_c_t_u = self.common_decode_mlp.apply(encoding_c_t_u)\n",
        "        decoding_t_t_u = self.target_decode_mlp.apply(encoding_t_t_u)\n",
        "        decoding_t_u = decoding_c_t_u + decoding_t_t_u\n",
        "        self.R_loss = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.square(decoding_t_u - self.X_t_u))\n",
        "        # Get common classification loss\n",
        "        encoding_c_s = self.common_encode_mlp.apply(self.X_s)\n",
        "        pred_s = self.common_output_mlp.apply(encoding_c_s)\n",
        "        self.C_loss = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.nn.softmax_cross_entropy_with_logits(logits=pred_s, labels=self.Y_s))\n",
        "        correct_prediction = tf.compat.v1.compat.v1.equal(tf.compat.v1.compat.v1.argmax(pred_s, 1), tf.compat.v1.compat.v1.argmax(self.Y_s, 1))\n",
        "        self.accuracy_s = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.cast(correct_prediction, \"float\"))\n",
        "        # Build solver\n",
        "        self.theta = (self.common_encode_mlp.parameters +\n",
        "                      self.target_encode_mlp.parameters +\n",
        "                      self.common_decode_mlp.parameters +\n",
        "                      self.target_decode_mlp.parameters +\n",
        "                      self.common_output_mlp.parameters)\n",
        "        l2_norm = 0.\n",
        "        for tensor in self.theta:\n",
        "            if tensor.name.find('W') != 0:\n",
        "                l2_norm += tf.compat.v1.compat.v1.reduce_sum(tf.compat.v1.compat.v1.abs(tensor))\n",
        "        self.loss = (self.R_loss +\n",
        "                     self.alpha * self.C_loss +\n",
        "                     self.gamma * self.cmd_c_loss +\n",
        "                     self.lamb * self.cmd_t_loss +\n",
        "                     0.0001 * l2_norm)\n",
        "        self.solver = (tf.compat.v1.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                       .minimize(self.loss, var_list=self.theta))\n",
        "        self.l2_norm = l2_norm\n",
        "\n",
        "    def train(self, x_s_u, x_t_u, x_s, y_s, x_valid, y_valid, x_test, y_test, x_s_tst, x_t_tst):\n",
        "        wait_times = 0\n",
        "        best_result = 0.\n",
        "        self.graph = tf.compat.v1.compat.v1.Graph()\n",
        "        self.sess = tf.compat.v1.compat.v1.Session(graph=self.graph)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.compat.v1.global_variables_initializer())\n",
        "            while True:\n",
        "                (_, c_loss, r_loss, cmd_c_loss, cmd_t_loss, corr_loss, accuracy) = self.sess.run(\n",
        "                    [self.solver, self.C_loss, self.R_loss, self.cmd_c_loss, -self.cmd_t_loss, self.corr_loss,\n",
        "                     self.accuracy_s],\n",
        "                    feed_dict={self.X_s_u: x_s_u,\n",
        "                               self.X_t_u: x_t_u,\n",
        "                               self.X_s: x_s,\n",
        "                               self.Y_s: y_s,\n",
        "                               }\n",
        "                )\n",
        "                print('corr_loss', corr_loss)\n",
        "                if accuracy > 0.7:\n",
        "                    valid_accuracy, = \\\n",
        "                        self.sess.run([self.accuracy_s, ],\n",
        "                                      feed_dict={self.X_s: x_valid,\n",
        "                                                 self.Y_s: y_valid,\n",
        "                                                 }\n",
        "                                      )\n",
        "                    if valid_accuracy > best_result:\n",
        "                        best_result = valid_accuracy\n",
        "                        wait_times = 0\n",
        "                        print('Save model...')\n",
        "                        saver.save(self.sess, save_path=self.model_save_to)\n",
        "                        print('Done')\n",
        "                    else:\n",
        "                        wait_times += 1\n",
        "                    if wait_times >= self.tolerate_time:\n",
        "                        print('best valid result :{0}'.format(best_result))\n",
        "                        break\n",
        "                    print('valid_accuracy:{0}'.format(valid_accuracy))\n",
        "            saver.restore(self.sess, self.model_save_to)\n",
        "            test_accuracy = self.accuracy_s.eval({self.X_s: x_test, self.Y_s: y_test}, session=self.sess)\n",
        "            print('Test accuracy:', test_accuracy)\n",
        "            encoding_c_s_u, encoding_c_t_u, encoding_t_s_u, encoding_t_t_u = self.sess.run(\n",
        "                [self.encoding_c_s_u, self.encoding_c_t_u, self.encoding_t_s_u, self.encoding_t_t_u],\n",
        "            feed_dict={self.X_s_u: x_s_tst,\n",
        "                       self.X_t_u: x_t_tst})\n",
        "            plot_dist(encoding_c_s_u, encoding_c_t_u, 'common_{0}_{1}.pdf'.format(self.source_domain, self.target_domain))\n",
        "            plot_dist(encoding_t_s_u, encoding_t_t_u, 'target_{0}_{1}.pdf'.format(self.source_domain, self.target_domain))\n",
        "\n",
        "\n",
        "class TransferClassifier(object):\n",
        "    '''\n",
        "    Adapt from source domain to target domain with CMD regularizer\n",
        "    '''\n",
        "    def __init__(self, source_domain=0, target_domain=3, **kwargs):\n",
        "        self.source_domain = source_domain\n",
        "        self.target_domain = target_domain\n",
        "        self.learning_rate = 5e-3\n",
        "        self.data_load_from = '/content/drive/My Drive/amazon.mat'\n",
        "        self.model_save_to = '/content/drive/My Drive/output/CMD_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.model_load_from = self.model_save_to\n",
        "        self.n_input = 5000\n",
        "        self.n_hidden_1 = 50\n",
        "        self.n_classes = 2\n",
        "        self.d_hidden = 50\n",
        "        self.tolerate_time = 20\n",
        "        self.alpha = 2.\n",
        "\n",
        "    def build_model(self):\n",
        "\n",
        "        def encoding(x, weights, biases):\n",
        "            layer_1 = tf.compat.v1.compat.v1.add(tf.compat.v1.compat.v1.matmul(x, weights['h1']), biases['b1'])\n",
        "            layer_1 = tf.compat.v1.compat.v1.nn.sigmoid(layer_1)\n",
        "            return layer_1\n",
        "\n",
        "        def predict(x, weights, biases):\n",
        "            out_layer = tf.compat.v1.compat.v1.matmul(x, weights['out']) + biases['out']\n",
        "            return out_layer\n",
        "\n",
        "        def matchnorm(x1, x2):\n",
        "            return tf.compat.v1.compat.v1.sqrt(tf.compat.v1.compat.v1.reduce_sum(tf.compat.v1.compat.v1.pow(x1 - x2, 2)))\n",
        "            # return ((x1-x2)**2).sum().sqrt()\n",
        "\n",
        "        def scm(sx1, sx2, k):\n",
        "            ss1 = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.pow(sx1, k), 0)\n",
        "            ss2 = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.pow(sx2, k), 0)\n",
        "            return matchnorm(ss1, ss2)\n",
        "\n",
        "        def mmatch(x1, x2, n_moments):\n",
        "            mx1 = tf.compat.v1.compat.v1.reduce_mean(x1, 0)\n",
        "            mx2 = tf.compat.v1.compat.v1.reduce_mean(x2, 0)\n",
        "            sx1 = x1 - mx1\n",
        "            sx2 = x2 - mx2\n",
        "            dm = matchnorm(mx1, mx2)\n",
        "            scms = dm\n",
        "            for i in range(n_moments - 1):\n",
        "                scms += scm(sx1, sx2, i + 2)\n",
        "            return scms\n",
        "\n",
        "        # tf Graph input\n",
        "        self.X_s = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])\n",
        "        self.X_t = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])\n",
        "        self.Y_s = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_classes])\n",
        "        self.Y_t = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_classes])\n",
        "        self.X_s_u = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])\n",
        "        self.X_t_u = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])\n",
        "\n",
        "        # Store layers weight & bias\n",
        "        self.weights = {\n",
        "            'h1': tf.compat.v1.compat.v1.Variable(xavier_init([self.n_input, self.n_hidden_1])),\n",
        "            'out': tf.compat.v1.compat.v1.Variable(xavier_init([self.n_hidden_1, self.n_classes])),\n",
        "        }\n",
        "        self.biases = {\n",
        "            'b1': tf.compat.v1.compat.v1.Variable(tf.compat.v1.compat.v1.zeros(shape=[self.n_hidden_1])),\n",
        "            'out': tf.compat.v1.compat.v1.Variable(tf.compat.v1.compat.v1.zeros(shape=[self.n_classes])),\n",
        "        }\n",
        "\n",
        "        self.theta = list(self.weights.values()) + list(self.biases.values())\n",
        "\n",
        "        encoding_s = encoding(self.X_s, self.weights, self.biases)\n",
        "        self.encoding_s = encoding_s\n",
        "        self.pred_s = predict(encoding_s, self.weights, self.biases)\n",
        "        self.accuracy_s = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.cast(tf.compat.v1.compat.v1.equal(tf.compat.v1.compat.v1.argmax(self.pred_s, 1),\n",
        "                                                          tf.compat.v1.compat.v1.argmax(self.Y_s, 1)), 'float'))\n",
        "\n",
        "        encoding_t = encoding(self.X_t, self.weights, self.biases)\n",
        "        self.encoding_t = encoding_t\n",
        "        self.pred_t = predict(encoding_t, self.weights, self.biases)\n",
        "        self.accuracy_t = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.cast(tf.compat.v1.compat.v1.equal(tf.compat.v1.compat.v1.argmax(self.pred_t, 1),\n",
        "                                                          tf.compat.v1.compat.v1.argmax(self.Y_t, 1)), 'float'))\n",
        "\n",
        "        self.C_loss = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.nn.softmax_cross_entropy_with_logits(logits=self.pred_s,\n",
        "                                                                             labels=self.Y_s))\n",
        "        self.encoding_s_u = encoding(self.X_s_u, self.weights, self.biases)\n",
        "        self.encoding_t_u = encoding(self.X_t_u, self.weights, self.biases)\n",
        "        self.D_loss = -mmatch(self.encoding_s_u, self.encoding_t_u, 3)\n",
        "        self.l2_norm = 0.\n",
        "        for tensor in list(self.weights.values()):\n",
        "            self.l2_norm += tf.compat.v1.compat.v1.reduce_sum(tf.compat.v1.compat.v1.abs(tensor))\n",
        "        self.loss = self.C_loss + self.alpha * self.D_loss + 0.0001*self.l2_norm\n",
        "        self.solver = (tf.compat.v1.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                       .minimize(self.loss, var_list=self.theta))\n",
        "        self.C_solver = (tf.compat.v1.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                         .minimize(self.C_loss + .0001 * self.l2_norm, var_list=self.theta))\n",
        "\n",
        "    def train(self, x_s_u, x_t_u, x_s, y_s, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        self.graph = tf.compat.v1.compat.v1.Graph()\n",
        "        self.sess = tf.compat.v1.compat.v1.Session(graph=self.graph)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.compat.v1.train.Saver()\n",
        "            self.sess.run(tf.compat.v1.compat.v1.global_variables_initializer())\n",
        "            wait_times = 0\n",
        "            best_result = 0.\n",
        "            while True:\n",
        "                _, loss, C_loss, D_loss, accuracy = self.sess.run(\n",
        "                    [self.solver, self.loss, self.C_loss, self.D_loss, self.accuracy_s],\n",
        "                    feed_dict={self.X_s_u: x_s_u,\n",
        "                               self.X_t_u: x_t_u,\n",
        "                               self.X_s: x_s,\n",
        "                               self.Y_s: y_s,\n",
        "                               }\n",
        "                )\n",
        "                print('total_loss:{0}'.format(loss))\n",
        "                print('C_loss:{0}'.format(C_loss))\n",
        "                print('D_loss:{0}'.format(D_loss))\n",
        "                print('accuracy:{0}'.format(accuracy))\n",
        "                # Do validation\n",
        "                if accuracy > 0.7:\n",
        "                    test_accuracy = self.accuracy_t.eval({self.X_t: x_valid, self.Y_t: y_valid}, session=self.sess)\n",
        "                    if test_accuracy > best_result:\n",
        "                        best_result = test_accuracy\n",
        "                        wait_times = 0\n",
        "                        # print('save model...')\n",
        "                        saver.save(self.sess, self.model_save_to)\n",
        "                        # print('done!')\n",
        "                    else:\n",
        "                        wait_times += 1\n",
        "                    if wait_times >= self.tolerate_time:\n",
        "                        print('best_result:{0}'.format(best_result))\n",
        "                        break\n",
        "                    print(\"Valid accuracy:\", test_accuracy)\n",
        "            saver.restore(self.sess, self.model_save_to)\n",
        "            # test_accuracy = self.accuracy_t.eval({self.X_t: x_test, self.Y_t: y_test}, session=self.sess)\n",
        "            # print(\"Test accuracy:\", test_accuracy)\n",
        "            encoding_s, encoding_t = self.sess.run(\n",
        "                [self.encoding_s_u, self.encoding_t_u],\n",
        "                feed_dict={self.X_s_u: x_s_u,\n",
        "                           self.X_t_u: x_t_u})\n",
        "            print(encoding_s.shape)\n",
        "            common_a_distance = plot_dist(encoding_s, encoding_t, '{0}_{1}.pdf'.format(self.source_domain, self.target_domain))\n",
        "            print('common_a_distance', common_a_distance)\n",
        "            # return test_accuracy\n",
        "\n",
        "\n",
        "class CoTrainer(object):\n",
        "    def __init__(self, source_domain=0, target_domain=3, **kwargs):\n",
        "        self.source_domain = source_domain\n",
        "        self.target_domain = target_domain\n",
        "        self.learning_rate = 5e-3\n",
        "        self.data_load_from = '/content/drive/My Drive/amazon.mat'\n",
        "        self.batch_size = 200\n",
        "        self.model_save_to = 'output_extend/Cotrain_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.model_load_from = self.model_save_to\n",
        "        self.common_model_save_to = 'output_extend/Cotrain_common_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.common_tune_model_save_to = 'output_extend/Cotrain_common_tune_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.target_model_save_to = 'output_extend/Cotrain_target_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.combined_model_save_to = 'output_extend/Cotrain_combined_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.n_input = 5000\n",
        "        self.n_classes = 2\n",
        "        self.d_hidden = 50\n",
        "        self.tolerate_time = 20\n",
        "        self.alpha = 1.\n",
        "        self.belta = 1.\n",
        "        self.gamma = 1.\n",
        "        self.lamb = 1.\n",
        "        self.beta = 1.\n",
        "        self.n_hidden_c = 50\n",
        "        self.n_hidden_s = 50\n",
        "        self.n_hidden_t = 50\n",
        "\n",
        "    def build_model(self):\n",
        "        n_classes = self.n_classes\n",
        "\n",
        "        def matchnorm(x1, x2):\n",
        "            return tf.compat.v1.compat.v1.sqrt(tf.compat.v1.compat.v1.reduce_sum(tf.compat.v1.compat.v1.pow(x1 - x2, 2)))\n",
        "\n",
        "        def scm(sx1, sx2, k):\n",
        "            ss1 = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.pow(sx1, k), 0)\n",
        "            ss2 = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.pow(sx2, k), 0)\n",
        "            return matchnorm(ss1, ss2)\n",
        "\n",
        "        def mmatch(x1, x2, n_moments):\n",
        "            mx1 = tf.compat.v1.compat.v1.reduce_mean(x1, 0)\n",
        "            mx2 = tf.compat.v1.compat.v1.reduce_mean(x2, 0)\n",
        "            sx1 = x1 - mx1\n",
        "            sx2 = x2 - mx2\n",
        "            dm = matchnorm(mx1, mx2)\n",
        "            scms = dm\n",
        "            for i in range(n_moments - 1):\n",
        "                scms += scm(sx1, sx2, i + 2)\n",
        "            return scms\n",
        "\n",
        "        def get_correlation(mat_a, mat_b):\n",
        "            mat_a = mat_a - tf.compat.v1.compat.v1.reduce_mean(mat_a, axis=0)\n",
        "            mat_b = mat_b - tf.compat.v1.compat.v1.reduce_mean(mat_b, axis=0)\n",
        "            sigma = tf.compat.v1.compat.v1.matmul(tf.compat.v1.compat.v1.transpose(mat_a), mat_b)\n",
        "            mat_a_cov = tf.compat.v1.compat.v1.matmul(tf.compat.v1.compat.v1.transpose(mat_a), mat_a)\n",
        "            mat_b_cov = tf.compat.v1.compat.v1.matmul(tf.compat.v1.compat.v1.transpose(mat_b), mat_b)\n",
        "            return tf.compat.v1.compat.v1.matmul(tf.compat.v1.compat.v1.matmul(tf.compat.v1.compat.v1.diag(tf.compat.v1.compat.v1.pow(tf.compat.v1.compat.v1.diag_part(mat_a_cov), -0.5)), sigma),\n",
        "                             tf.compat.v1.compat.v1.diag(tf.compat.v1.compat.v1.pow(tf.compat.v1.compat.v1.diag_part(mat_b_cov), -0.5)))\n",
        "\n",
        "        # tf Graph input\n",
        "        self.X_s_u = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])  # source unlabeled data\n",
        "        self.X_t_u = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])  # target unlabeled data\n",
        "        self.X_s = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])    # source labeled data\n",
        "        self.Y_s = tf.compat.v1.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "        self.X_t = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])    # target labeled data\n",
        "        self.Y_t = tf.compat.v1.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "        self.common_encode_mlp = MLP(name='common_encode_mlp', dims=[self.n_input, self.n_hidden_c],\n",
        "                                     activations=[tf.compat.v1.compat.v1.nn.sigmoid])\n",
        "        self.target_encode_mlp = MLP(name='target_encode_mlp', dims=[self.n_input, self.n_hidden_t],\n",
        "                                     activations=[tf.compat.v1.compat.v1.nn.sigmoid])\n",
        "        self.common_decode_mlp = MLP(name='common_decode_mlp',\n",
        "                                     dims=[self.n_hidden_c, (self.n_hidden_c + self.n_input) / 2, self.n_input],\n",
        "                                     activations=[tf.compat.v1.compat.v1.nn.tanh, tf.compat.v1.compat.v1.nn.relu])\n",
        "        self.target_decode_mlp = MLP(name='target_decode_mlp',\n",
        "                                     dims=[self.n_hidden_t, (self.n_hidden_t + self.n_input) / 2, self.n_input],\n",
        "                                     activations=[tf.compat.v1.compat.v1.nn.tanh, tf.compat.v1.compat.v1.nn.relu])\n",
        "        self.common_output_mlp = MLP(name='common_output_mlp', dims=[self.n_hidden_c, n_classes],\n",
        "                                     activations=[identity])\n",
        "        self.target_output_mlp = MLP(name='target_output_mlp', dims=[self.n_hidden_t, n_classes],\n",
        "                                     activations=[identity])\n",
        "\n",
        "        encoding_c_s_u = self.common_encode_mlp.apply(self.X_s_u)\n",
        "        encoding_c_t_u = self.common_encode_mlp.apply(self.X_t_u)\n",
        "        encoding_t_t_u = self.target_encode_mlp.apply(self.X_t_u)\n",
        "        encoding_t_s_u = self.target_encode_mlp.apply(self.X_s_u)\n",
        "        # Get correlation loss\n",
        "        self.corr_loss = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.abs(get_correlation(encoding_c_t_u, encoding_t_t_u)))\n",
        "        # Get cmd loss\n",
        "        self.cmd_c_loss = mmatch(encoding_c_s_u, encoding_c_t_u, 5)\n",
        "        self.cmd_t_loss = -mmatch(encoding_t_s_u, encoding_t_t_u, 5)\n",
        "        # Get reconstruction loss\n",
        "        decoding_c_t_u = self.common_decode_mlp.apply(encoding_c_t_u)\n",
        "        decoding_t_t_u = self.target_decode_mlp.apply(encoding_t_t_u)\n",
        "        decoding_t_u = decoding_c_t_u + decoding_t_t_u\n",
        "        self.R_loss = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.square(decoding_t_u - self.X_t_u))\n",
        "        # Get common classification loss\n",
        "        encoding_c_s = self.common_encode_mlp.apply(self.X_s)\n",
        "        pred_s = self.common_output_mlp.apply(encoding_c_s)\n",
        "        self.pred_s = pred_s\n",
        "        self.prob_s = tf.compat.v1.compat.v1.nn.softmax(pred_s)\n",
        "        self.C_loss = (tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.nn.softmax_cross_entropy_with_logits(logits=pred_s, labels=self.Y_s)))\n",
        "        correct_prediction = tf.compat.v1.compat.v1.equal(tf.compat.v1.compat.v1.argmax(pred_s, 1), tf.compat.v1.compat.v1.argmax(self.Y_s, 1))\n",
        "        self.accuracy_s = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.cast(correct_prediction, \"float\"))\n",
        "        # Get target classification loss\n",
        "        encoding_t_t = self.target_encode_mlp.apply(self.X_t)\n",
        "        pred_t = self.target_output_mlp.apply(encoding_t_t)\n",
        "        self.pred_t = pred_t\n",
        "        self.prob_t = tf.compat.v1.compat.v1.nn.softmax(pred_t)\n",
        "        self.T_loss = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.nn.softmax_cross_entropy_with_logits(logits=pred_t, labels=self.Y_t))\n",
        "        correct_prediction = tf.compat.v1.compat.v1.equal(tf.compat.v1.compat.v1.argmax(pred_t, 1), tf.compat.v1.compat.v1.argmax(self.Y_t, 1))\n",
        "        self.accuracy_t = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.cast(correct_prediction, \"float\"))\n",
        "        # Build solver\n",
        "        self.theta = (self.common_encode_mlp.parameters +\n",
        "                      self.target_encode_mlp.parameters +\n",
        "                      self.common_decode_mlp.parameters +\n",
        "                      self.target_decode_mlp.parameters +\n",
        "                      self.common_output_mlp.parameters +\n",
        "                      self.target_output_mlp.parameters)\n",
        "        l2_norm = 0.\n",
        "        for tensor in self.theta:\n",
        "            if tensor.name.find('W') != 0:\n",
        "                l2_norm += tf.compat.v1.compat.v1.reduce_sum(tf.compat.v1.compat.v1.abs(tensor))\n",
        "        for tensor in self.target_output_mlp.parameters:\n",
        "            if tensor.name.find('W') != 0:\n",
        "                l2_norm += 4 * tf.compat.v1.compat.v1.reduce_sum(tf.compat.v1.compat.v1.abs(tensor))\n",
        "        self.loss = (self.R_loss +\n",
        "                     # self.alpha * self.C_loss +\n",
        "                     # self.belta * self.T_loss +\n",
        "                     self.gamma * self.cmd_c_loss +\n",
        "                     self.lamb * self.cmd_t_loss +\n",
        "                     0.0001 * l2_norm)\n",
        "        self.solver = (tf.compat.v1.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                       .minimize(self.loss, var_list=self.theta))\n",
        "\n",
        "        self.common_theta = (self.common_encode_mlp.parameters +\n",
        "                             self.common_decode_mlp.parameters +\n",
        "                             self.common_output_mlp.parameters)\n",
        "        self.common_loss = (self.R_loss +\n",
        "                            self.alpha * self.C_loss +\n",
        "                            self.gamma * self.cmd_c_loss +\n",
        "                            self.corr_loss +\n",
        "                            0.0001 * l2_norm)\n",
        "        self.common_solver = (tf.compat.v1.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                              .minimize(self.common_loss, var_list=self.common_theta))\n",
        "        self.target_theta = (self.target_encode_mlp.parameters +\n",
        "                             # self.target_decode_mlp.parameters +\n",
        "                             self.target_output_mlp.parameters)\n",
        "        self.target_loss = (self.R_loss +\n",
        "                            self.belta * self.T_loss +\n",
        "                            self.lamb * self.cmd_t_loss +\n",
        "                            self.corr_loss +\n",
        "                            0.0001 * l2_norm)\n",
        "        self.target_solver = (tf.compat.v1.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                              .minimize(self.target_loss, var_list=self.target_theta))\n",
        "        self.combined_loss = (self.C_loss + 0.0001 * l2_norm)\n",
        "        self.combined_solver = (tf.compat.v1.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                              .minimize(self.combined_loss, var_list=self.theta))\n",
        "\n",
        "    def initialize_model(self, x_s_u, x_t_u, x_s, y_s, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        wait_times = 0\n",
        "        best_result = 0.\n",
        "        self.graph = tf.compat.v1.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.compat.v1.global_variables_initializer())\n",
        "            for _ in range(150):\n",
        "                (_, c_loss, cmd_c_loss, cmd_t_loss, r_loss, accuracy) = self.sess.run(\n",
        "                    [self.solver, self.C_loss, self.cmd_c_loss, -self.cmd_t_loss, self.R_loss,\n",
        "                     self.accuracy_s],\n",
        "                    feed_dict={self.X_s: x_s,\n",
        "                               self.Y_s: y_s,\n",
        "                               self.X_t: x_t,\n",
        "                               self.Y_t: y_t,\n",
        "                               self.X_s_u: x_s_u,\n",
        "                               self.X_t_u: x_t_u,\n",
        "                               }\n",
        "                )\n",
        "                print('c_loss:{0}'.format(c_loss))\n",
        "                print('cmd_c_loss:{0}'.format(cmd_c_loss))\n",
        "                print('cmd_t_loss:{0}'.format(cmd_t_loss))\n",
        "                print('r_loss:{0}'.format(r_loss))\n",
        "                print('accuracy_s:{0}'.format(accuracy))\n",
        "                if accuracy > 0.7:\n",
        "                    valid_accuracy = self.accuracy_s.eval({self.X_s: x_valid,\n",
        "                                                           self.Y_s: y_valid},\n",
        "                                                          session=self.sess)\n",
        "                    if valid_accuracy > best_result:\n",
        "                        best_result = valid_accuracy\n",
        "                        wait_times = 0\n",
        "                        print('Save model...')\n",
        "                        saver.save(self.sess, save_path=self.target_model_save_to)\n",
        "                        print('Done!')\n",
        "                    else:\n",
        "                        wait_times += 1\n",
        "                    if wait_times >= self.tolerate_time:\n",
        "                        print('best_result:{0}'.format(best_result))\n",
        "                        break\n",
        "                    print(\"valid accuracy:\", valid_accuracy)\n",
        "            saver.save(self.sess, save_path=self.target_model_save_to)\n",
        "            return best_result\n",
        "\n",
        "    def train_common_model(self, x_s_u, x_t_u, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        wait_times = 0\n",
        "        best_result = 0.\n",
        "        self.graph = tf.compat.v1.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.compat.v1.train.Saver(var_list=self.target_theta)\n",
        "            self.sess.run(tf.compat.v1.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, self.target_model_save_to)\n",
        "            saver = tf.compat.v1.compat.v1.train.Saver(var_list=self.theta)\n",
        "            while True:\n",
        "                (_, c_loss, cmd_c_loss, r_loss, corr_loss, accuracy) = self.sess.run(\n",
        "                    [self.common_solver, self.C_loss, self.cmd_c_loss, self.R_loss, self.corr_loss,\n",
        "                     self.accuracy_s],\n",
        "                    feed_dict={self.X_s: x_t,\n",
        "                               self.Y_s: y_t,\n",
        "                               self.X_s_u: x_s_u,\n",
        "                               self.X_t_u: x_t_u,\n",
        "                               }\n",
        "                )\n",
        "                print('c_loss:{0}'.format(c_loss))\n",
        "                print('cmd_c_loss:{0}'.format(cmd_c_loss))\n",
        "                print('r_loss:{0}'.format(r_loss))\n",
        "                print('corr_loss:{0}'.format(corr_loss))\n",
        "                print('accuracy_s:{0}'.format(accuracy))\n",
        "                if accuracy > 0.7:\n",
        "                    valid_accuracy = self.accuracy_s.eval({self.X_s: x_valid,\n",
        "                                                         self.Y_s: y_valid},\n",
        "                                                        session=self.sess)\n",
        "                    if valid_accuracy > best_result:\n",
        "                        best_result = valid_accuracy\n",
        "                        wait_times = 0\n",
        "                        print('Save model...')\n",
        "                        saver.save(self.sess, save_path=self.common_model_save_to)\n",
        "                        print('Done!')\n",
        "                    else:\n",
        "                        wait_times += 1\n",
        "                    if wait_times >= self.tolerate_time:\n",
        "                        print('best_result:{0}'.format(best_result))\n",
        "                        break\n",
        "                    print(\"valid accuracy:\", valid_accuracy)\n",
        "            saver.restore(self.sess, self.common_model_save_to)\n",
        "            test_accuracy = self.accuracy_s.eval({self.X_s: x_test,\n",
        "                                                   self.Y_s: y_test},\n",
        "                                                  session=self.sess)\n",
        "            print('test_accuracy:{0}'.format(test_accuracy))\n",
        "            return best_result\n",
        "\n",
        "    def train_target_model(self, x_s_u, x_t_u, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        wait_times = 0\n",
        "        best_result = 0.\n",
        "        self.graph = tf.compat.v1.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.compat.v1.train.Saver(var_list=self.common_theta)\n",
        "            self.sess.run(tf.compat.v1.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, self.common_model_save_to)\n",
        "            saver = tf.compat.v1.compat.v1.train.Saver(var_list=self.theta)\n",
        "            while True:\n",
        "                (_, t_loss, cmd_c_loss, cmd_t_loss,\n",
        "                 r_loss, corr_loss, accuracy) = self.sess.run(\n",
        "                    [self.target_solver, self.T_loss, self.cmd_c_loss, -self.cmd_t_loss, self.R_loss, self.corr_loss, self.accuracy_t],\n",
        "                    feed_dict={self.X_t: x_t,\n",
        "                               self.Y_t: y_t,\n",
        "                               self.X_s_u: x_s_u,\n",
        "                               self.X_t_u: x_t_u,\n",
        "                    }\n",
        "                )\n",
        "                print('t_loss:{0}'.format(t_loss))\n",
        "                print('cmd_c_loss:{0}'.format(cmd_c_loss))\n",
        "                print('cmd_t_loss:{0}'.format(cmd_t_loss))\n",
        "                print('r_loss:{0}'.format(r_loss))\n",
        "                print('corr_loss:{0}'.format(corr_loss))\n",
        "                print('accuracy_t:{0}'.format(accuracy))\n",
        "                if accuracy > 0.7:\n",
        "                    valid_accuracy = self.accuracy_t.eval({self.X_t: x_valid,\n",
        "                                                           self.Y_t: y_valid},\n",
        "                                                          session=self.sess)\n",
        "                    if valid_accuracy > best_result:\n",
        "                        best_result = valid_accuracy\n",
        "                        wait_times = 0\n",
        "                        print('Save model...')\n",
        "                        saver.save(self.sess, save_path=self.target_model_save_to)\n",
        "                        print('Done!')\n",
        "                    else:\n",
        "                        wait_times += 1\n",
        "                    if wait_times >= self.tolerate_time:\n",
        "                        print('best_result:{0}'.format(best_result))\n",
        "                        break\n",
        "                    print(\"valid accuracy:\", valid_accuracy)\n",
        "            saver.restore(self.sess, self.target_model_save_to)\n",
        "            test_accuracy = self.accuracy_t.eval({self.X_t: x_test,\n",
        "                                                  self.Y_t: y_test},\n",
        "                                                 session=self.sess)\n",
        "            print('test_accuracy:{0}'.format(test_accuracy))\n",
        "            return best_result\n",
        "\n",
        "    def train_combined_model(self, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        self.graph = tf.compat.v1.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, self.common_model_save_to)\n",
        "            common_valid_probs, = self.sess.run([self.prob_s], feed_dict={self.X_s: x_valid})\n",
        "            common_test_probs, = self.sess.run([self.prob_s], feed_dict={self.X_s: x_test})\n",
        "            self.sess.run(tf.compat.v1.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, self.target_model_save_to)\n",
        "            target_valid_probs, = self.sess.run([self.prob_s], feed_dict={self.X_s: x_valid})\n",
        "            target_test_probs, = self.sess.run([self.prob_s], feed_dict={self.X_s: x_test})\n",
        "            best_result = 0.\n",
        "            best_beta = 0.\n",
        "            for beta in [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.]:\n",
        "                valid_probs = common_valid_probs + beta * target_valid_probs\n",
        "                valid_accuracy = np.equal(valid_probs.argmax(axis=1), y_valid.argmax(axis=1)).mean()\n",
        "                if valid_accuracy > best_result:\n",
        "                    best_result = valid_accuracy\n",
        "                    best_beta = beta\n",
        "            valid_accuracy = best_result\n",
        "            test_probs = common_test_probs + best_beta * target_test_probs\n",
        "            test_accuracy = np.equal(test_probs.argmax(axis=1), y_test.argmax(axis=1)).mean()\n",
        "            print('valid accuracy:', valid_accuracy)\n",
        "            print(\"test accuracy:\", test_accuracy)\n",
        "            return valid_accuracy, test_accuracy\n",
        "\n",
        "    def train(self, x_s_u, x_t_u, x_s, y_s, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        U = np.copy(x_t_u)\n",
        "        select_num = 5\n",
        "        best_result = 0.\n",
        "        final_test_accuracy = 0.\n",
        "        self.initialize_model(x_s_u, x_t_u, x_s, y_s, x_t, y_t,\n",
        "                              x_valid, y_valid, x_test, y_test)\n",
        "        wait_times = 0.\n",
        "        while len(U) > 0:\n",
        "            print('Train common model...')\n",
        "            self.train_common_model(x_s_u, x_t_u, np.concatenate([x_s, x_t]), np.concatenate([y_s, y_t]),\n",
        "                                    x_valid, y_valid, x_test, y_test)\n",
        "            # input = raw_input('Input andy character!'\n",
        "            print('Train target model...')\n",
        "            self.train_target_model(x_s_u, x_t_u, x_t, y_t, x_valid, y_valid, x_test, y_test)\n",
        "            # input = raw_input('Input andy character!')\n",
        "            # Select U from common view\n",
        "            probs = [self.get_common_prediction(U), self.get_target_prediction(U)]\n",
        "            x_hat, y_hat, U = self.select_sample(U, probs, select_num=select_num)\n",
        "            x_t = np.concatenate([x_t, x_hat], axis=0)\n",
        "            y_t = np.concatenate([y_t, y_hat], axis=0)\n",
        "            print('Train combined model...')\n",
        "            valid_accuracy, test_accuracy = self.train_combined_model(x_t, y_t, x_valid, y_valid, x_test, y_test)\n",
        "            # input = raw_input('Input andy character!')\n",
        "            if valid_accuracy > best_result:\n",
        "                best_result = valid_accuracy\n",
        "                final_test_accuracy = test_accuracy\n",
        "                wait_times = 0\n",
        "            else:\n",
        "                wait_times += 1\n",
        "            if wait_times >= self.tolerate_time:\n",
        "                print('best_result:{0}'.format(best_result))\n",
        "                break\n",
        "        print('Test accuracy:{0}'.format(final_test_accuracy))\n",
        "\n",
        "    def select_sample(self, U, probs, select_num):\n",
        "        neg_idxes = set()\n",
        "        pos_idxes = set()\n",
        "        left_idxes = set(range(len(U)))\n",
        "        for prob in probs:\n",
        "            idxes = np.argsort(prob[:, 0])\n",
        "            end_idx = min(select_num, (prob[:, 0][idxes[:select_num]] < 0.5).sum())\n",
        "            begin_idx = min(select_num, (prob[:, 0][idxes[-select_num:]] > 0.5).sum())\n",
        "            idx = min(begin_idx, end_idx)\n",
        "            if idx == 0:\n",
        "                idx = 1\n",
        "            begin_idx = idx\n",
        "            end_idx = idx\n",
        "            neg_idxes.update(idxes[:end_idx])\n",
        "            pos_idxes.update(idxes[-begin_idx:])\n",
        "            print('pos num:', len(pos_idxes))\n",
        "            print('neg num:', len(neg_idxes))\n",
        "            left_idxes = left_idxes.intersection(idxes[end_idx:-begin_idx])\n",
        "\n",
        "        pos_idxes = np.array(list(pos_idxes))\n",
        "        neg_idxes = np.array(list(neg_idxes))\n",
        "        left_idxes = np.array(list(left_idxes))\n",
        "        x_n = U[neg_idxes]\n",
        "        x_p = U[pos_idxes]\n",
        "        y_n = np.zeros(shape=(len(x_n), 2), dtype='float32')\n",
        "        y_n[:, 1] = 1.\n",
        "        y_p = np.zeros(shape=(len(x_p), 2), dtype='float32')\n",
        "        y_p[:, 0] = 1.\n",
        "        U = U[left_idxes]\n",
        "        x = np.concatenate([x_n, x_p], axis=0)\n",
        "        y = np.concatenate([y_n, y_p], axis=0)\n",
        "        x, y = shuffle3([x, y])\n",
        "        print('unlabelled num:', len(U))\n",
        "        print(len(left_idxes))\n",
        "        return x, y, U\n",
        "\n",
        "    def get_common_prediction(self, X):\n",
        "        self.graph = tf.compat.v1.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, self.common_model_save_to)\n",
        "            probs, = self.sess.run([self.prob_s], feed_dict={self.X_s: X})\n",
        "        return probs\n",
        "\n",
        "    def get_target_prediction(self, X):\n",
        "        self.graph = tf.compat.v1.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, self.target_model_save_to)\n",
        "            probs, = self.sess.run([self.prob_t], feed_dict={self.X_t: X})\n",
        "        return probs\n",
        "\n",
        "    def analysis(self, x_t_train, y_t_train):\n",
        "        self.graph = tf.compat.v1.compat.v1.Graph()\n",
        "        self.sess = tf.compat.v1.compat.v1.Session(graph=self.graph)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, '/content/drive/My Drive/output/combined.pkl')\n",
        "            H_t, = self.sess.run([self.encoding_t_t],\n",
        "                                 feed_dict={self.X_t: x_t_train})\n",
        "        pca = PCA(n_components=2)\n",
        "        H_t_hat = pca.fit_transform(H_t)\n",
        "        plt.scatter(H_t_hat[:, 0][y_t_train[:, 0]==0.], H_t_hat[:, 1][y_t_train[:, 0]==0.], color='r', alpha=.4, s=1)\n",
        "        plt.scatter(H_t_hat[:, 0][y_t_train[:, 0]==1.], H_t_hat[:, 1][y_t_train[:, 0]==1.], color='b', alpha=.4, s=1)\n",
        "        plt.savefig(\"h_t.pdf\", dpi=72)\n",
        "\n",
        "\n",
        "class Autoencoder(object):\n",
        "    def __init__(self, source_domain=0, target_domain=3, **kwargs):\n",
        "        self.source_domain = source_domain\n",
        "        self.target_domain = target_domain\n",
        "        self.learning_rate = 5e-3\n",
        "        self.data_load_from = '/content/drive/My Drive/amazon.mat'\n",
        "        self.batch_size = 200\n",
        "        self.model_save_to = 'output_extend/Auto_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.model_load_from = self.model_save_to\n",
        "        self.n_input = 5000\n",
        "        self.n_classes = 2\n",
        "        self.model_built = False\n",
        "        self.tolerate_time = 20\n",
        "        self.alpha = 1.\n",
        "        self.belta = 1.\n",
        "        self.gamma = 1.\n",
        "        self.n_hidden_c = 50\n",
        "        self.n_hidden_s = 50\n",
        "        self.n_hidden_t = 50\n",
        "\n",
        "    def build_model(self):\n",
        "        n_classes = self.n_classes\n",
        "\n",
        "        def matchnorm(x1, x2):\n",
        "            return tf.compat.v1.compat.v1.sqrt(tf.compat.v1.compat.v1.reduce_sum(tf.compat.v1.compat.v1.pow(x1 - x2, 2)))\n",
        "\n",
        "        def scm(sx1, sx2, k):\n",
        "            ss1 = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.pow(sx1, k), 0)\n",
        "            ss2 = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.pow(sx2, k), 0)\n",
        "            return matchnorm(ss1, ss2)\n",
        "\n",
        "        def mmatch(x1, x2, n_moments):\n",
        "            mx1 = tf.compat.v1.compat.v1.reduce_mean(x1, 0)\n",
        "            mx2 = tf.compat.v1.compat.v1.reduce_mean(x2, 0)\n",
        "            sx1 = x1 - mx1\n",
        "            sx2 = x2 - mx2\n",
        "            dm = matchnorm(mx1, mx2)\n",
        "            scms = dm\n",
        "            for i in range(n_moments - 1):\n",
        "                scms += scm(sx1, sx2, i + 2)\n",
        "            return scms\n",
        "\n",
        "        # tf Graph input\n",
        "        self.X_s_u = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])  # source unlabeled data\n",
        "        self.X_t_u = tf.compat.v1.compat.v1.placeholder(\"float\", [None, self.n_input])  # target unlabeled data\n",
        "\n",
        "        self.common_encode_mlp = MLP(name='common_encode_mlp', dims=[self.n_input, self.n_hidden_c],\n",
        "                                     activations=[tf.compat.v1.compat.v1.nn.sigmoid])\n",
        "        self.target_encode_mlp = MLP(name='target_encode_mlp', dims=[self.n_input, self.n_hidden_t],\n",
        "                                     activations=[tf.compat.v1.compat.v1.nn.sigmoid])\n",
        "        self.common_decode_mlp = MLP(name='common_decode_mlp',\n",
        "                                     dims=[self.n_hidden_c, (self.n_hidden_c + self.n_input) / 2, self.n_input],\n",
        "                                     activations=[tf.compat.v1.compat.v1.nn.tanh, tf.compat.v1.compat.v1.nn.relu])\n",
        "        self.target_decode_mlp = MLP(name='target_decode_mlp',\n",
        "                                     dims=[self.n_hidden_t, (self.n_hidden_t + self.n_input) / 2, self.n_input],\n",
        "                                     activations=[tf.compat.v1.compat.v1.nn.tanh, tf.compat.v1.compat.v1.nn.relu])\n",
        "\n",
        "        encoding_c_s_u = self.common_encode_mlp.apply(self.X_s_u)\n",
        "        self.encoding_c_s_u = encoding_c_s_u\n",
        "        encoding_c_t_u = self.common_encode_mlp.apply(self.X_t_u)\n",
        "        self.encoding_c_t_u = encoding_c_t_u\n",
        "        encoding_t_s_u = self.target_encode_mlp.apply(self.X_s_u)\n",
        "        self.encoding_t_s_u = encoding_t_s_u\n",
        "        encoding_t_t_u = self.target_encode_mlp.apply(self.X_t_u)\n",
        "        self.encoding_t_t_u = encoding_t_t_u\n",
        "        # Get cmd loss\n",
        "        self.cmd_c_loss = mmatch(encoding_c_s_u, encoding_c_t_u, 3)\n",
        "        self.cmd_t_loss = -mmatch(encoding_t_s_u, encoding_t_t_u, 3)\n",
        "        # Get reconstruction loss\n",
        "        decoding_c_t_u = self.common_decode_mlp.apply(encoding_c_t_u)\n",
        "        decoding_t_t_u = self.target_decode_mlp.apply(encoding_t_t_u)\n",
        "        decoding_c_s_u = self.common_decode_mlp.apply(encoding_c_s_u)\n",
        "        decoding_t_s_u = self.target_decode_mlp.apply(encoding_t_s_u)\n",
        "        decoding_t_u = decoding_c_t_u + decoding_t_t_u\n",
        "        decoding_s_u = decoding_c_s_u + decoding_t_s_u\n",
        "        self.R_loss = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.square(decoding_t_u - self.X_t_u)) + tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.square(decoding_s_u - self.X_s_u))\n",
        "        # Get classification loss\n",
        "        # encoding_c_s = self.common_encode_mlp.apply(self.X_s)\n",
        "        # pred_s = self.common_output_mlp.apply(encoding_c_s)\n",
        "        # self.C_loss = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.nn.softmax_cross_entropy_with_logits(logits=pred_s, labels=self.Y_s))\n",
        "        # correct_prediction = tf.compat.v1.compat.v1.equal(tf.compat.v1.compat.v1.argmax(pred_s, 1), tf.compat.v1.compat.v1.argmax(self.Y_s, 1))\n",
        "        # self.accuracy_s = tf.compat.v1.compat.v1.reduce_mean(tf.compat.v1.compat.v1.cast(correct_prediction, \"float\"))\n",
        "        # Build solver\n",
        "        # Build solver\n",
        "        self.theta = (self.common_encode_mlp.parameters +\n",
        "                      self.target_encode_mlp.parameters +\n",
        "                      self.common_decode_mlp.parameters +\n",
        "                      self.target_decode_mlp.parameters)\n",
        "        l2_norm = 0.\n",
        "        for tensor in self.theta:\n",
        "            if tensor.name.find('W') != 0:\n",
        "                l2_norm += tf.compat.v1.compat.v1.reduce_sum(tf.compat.v1.compat.v1.abs(tensor))\n",
        "        self.loss = (self.R_loss +\n",
        "                     self.gamma * (self.cmd_c_loss + self.cmd_t_loss) +\n",
        "                     0.0001 * l2_norm)\n",
        "        self.solver = (tf.compat.v1.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                       .minimize(self.loss, var_list=self.theta))\n",
        "\n",
        "    def train(self, x_s_u, x_t_u):\n",
        "        self.graph = tf.compat.v1.compat.v1.Graph()\n",
        "        self.sess = tf.compat.v1.compat.v1.Session(graph=self.graph)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.compat.v1.global_variables_initializer())\n",
        "            for _ in range(500):\n",
        "                (_, r_loss, cmd_c_loss, cmd_t_loss) = self.sess.run(\n",
        "                    [self.solver, self.R_loss, self.cmd_c_loss, -self.cmd_t_loss],\n",
        "                    feed_dict={self.X_s_u: x_s_u,\n",
        "                               self.X_t_u: x_t_u,\n",
        "                               }\n",
        "                )\n",
        "                print('r_loss:{0}'.format(r_loss))\n",
        "                print('cmd_c_loss:{0}'.format(cmd_c_loss))\n",
        "                print('cmd_t_loss:{0}'.format(cmd_t_loss))\n",
        "            # saver.save(self.sess, self.model_save_to)\n",
        "            encoding_s, encoding_t = self.sess.run(\n",
        "                [self.encoding_c_s_u, self.encoding_c_t_u],\n",
        "                feed_dict={self.X_s_u: x_s_u,\n",
        "                           self.X_t_u: x_t_u})\n",
        "            plot_dist(encoding_s, encoding_t,\n",
        "                                          'auto_{0}_{1}.pdf'.format(self.source_domain, self.target_domain))\n",
        "            return None\n",
        "\n",
        "'''\n",
        "if __name__ == '__main__':\n",
        "    data_load_from = '/content/drive/My Drive/amazon.mat'\n",
        "    import sys\n",
        "    mean_results = []\n",
        "    for source_domain in [0, 2]:\n",
        "        for target_domain in [1, 3]:\n",
        "            if source_domain == target_domain:\n",
        "                continue\n",
        "            x, y, offset = load_amazon(5000, data_load_from)\n",
        "            x_s_tr, y_s_tr, x_t_tr, y_t_tr, x_s_tst, y_s_tst, x_t_tst, y_t_tst = split_data(source_domain,\n",
        "                                                                                            target_domain,\n",
        "                                                                                            x, y, offset, 2000)\n",
        "            x = turn_tfidf(np.concatenate([x_s_tr, x_s_tst, x_t_tr, x_t_tst], axis=0))\n",
        "            x_s = x[:len(x_s_tr) + len(x_s_tst)]\n",
        "            x_t = x[len(x_s):]\n",
        "\n",
        "            x_s_tr = np.copy(x_s[:len(x_s_tr)])\n",
        "            x_s_tst = np.copy(x_s[len(x_s_tr):])\n",
        "\n",
        "            x_t_tr = np.copy(x_t[:len(x_t_tr)])\n",
        "            x_t_tst = np.copy(x_t[len(x_t_tr):])\n",
        "\n",
        "            x_t_tune = np.copy(x_t_tst[:50])\n",
        "            y_t_tune = np.copy(y_t_tst[:50])\n",
        "            x_t_tst = x_t_tst[50:]\n",
        "            y_t_tst = y_t_tst[50:]\n",
        "\n",
        "            x_t_valid = x_t_tst[:500]\n",
        "            y_t_valid = y_t_tst[:500]\n",
        "            x_t_tst = x_t_tst[500:]\n",
        "            y_t_tst = y_t_tst[500:]\n",
        "\n",
        "\n",
        "            classifier = SourceOnly(source_domain, target_domain)\n",
        "            classifier.train(x_s_tr, y_s_tr, x_t_valid, y_t_valid, x_t_tr, y_t_tr, x_s_tst, x_t_tst)\n",
        "            classifier = DCMD(source_domain, target_domain)\n",
        "            classifier.train(x_s_tr, x_t_tr, x_s_tr, y_s_tr,\n",
        "                      x_t_valid, y_t_valid, x_t_tst, y_t_tst, x_s_tst, x_t_tst)\n",
        "\n",
        "            # input = raw_input('Input to continue!')\n",
        "            # Fine-tune with tiny target domain samples on source domain model\n",
        "            # print('Fine-tune with tiny target domain samples on source domain model')\n",
        "            # cmd_results = []\n",
        "            # fine_tune_results = []\n",
        "            # cmd_classifier = TransferClassifier(source_domain, target_domain)\n",
        "            # classifier = FineTuneClassifier(source_domain, target_domain)\n",
        "            # for i in range(5):\n",
        "            #     cmd_result = cmd_classifier.train(x_s_tr, x_t_tr, x_s_tr, y_s_tr, x_t_tune, y_t_tune,\n",
        "            #           x_t_valid, y_t_valid, x_t_tst, y_t_tst)\n",
        "            #     # input = raw_input('Input any character!')\n",
        "            #     fine_tune_result = classifier.train(x_s_tr, x_t_tr, x_s_tr, y_s_tr, x_t_tune, y_t_tune,\n",
        "            #                                     x_t_valid, y_t_valid, x_t_tst, y_t_tst)\n",
        "            #     # input = raw_input('Input any character!')\n",
        "            #     cmd_results.append(cmd_result)\n",
        "            #     fine_tune_results.append(fine_tune_result)\n",
        "            # print('Source domain:{0}\\t Target domain:{1}'.format(source_domain, target_domain))\n",
        "            # print('cmd_result:', sum(cmd_results)/len(cmd_results))\n",
        "            # print('fine_tune_result:', sum(fine_tune_results)/len(fine_tune_results))\n",
        "\n",
        "\n",
        "    for result in mean_results:\n",
        "        print(result)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nif __name__ == '__main__':\\n    data_load_from = '/content/drive/My Drive/amazon.mat'\\n    import sys\\n    mean_results = []\\n    for source_domain in [0, 2]:\\n        for target_domain in [1, 3]:\\n            if source_domain == target_domain:\\n                continue\\n            x, y, offset = load_amazon(5000, data_load_from)\\n            x_s_tr, y_s_tr, x_t_tr, y_t_tr, x_s_tst, y_s_tst, x_t_tst, y_t_tst = split_data(source_domain,\\n                                                                                            target_domain,\\n                                                                                            x, y, offset, 2000)\\n            x = turn_tfidf(np.concatenate([x_s_tr, x_s_tst, x_t_tr, x_t_tst], axis=0))\\n            x_s = x[:len(x_s_tr) + len(x_s_tst)]\\n            x_t = x[len(x_s):]\\n\\n            x_s_tr = np.copy(x_s[:len(x_s_tr)])\\n            x_s_tst = np.copy(x_s[len(x_s_tr):])\\n\\n            x_t_tr = np.copy(x_t[:len(x_t_tr)])\\n            x_t_tst = np.copy(x_t[len(x_t_tr):])\\n\\n            x_t_tune = np.copy(x_t_tst[:50])\\n            y_t_tune = np.copy(y_t_tst[:50])\\n            x_t_tst = x_t_tst[50:]\\n            y_t_tst = y_t_tst[50:]\\n\\n            x_t_valid = x_t_tst[:500]\\n            y_t_valid = y_t_tst[:500]\\n            x_t_tst = x_t_tst[500:]\\n            y_t_tst = y_t_tst[500:]\\n\\n\\n            classifier = SourceOnly(source_domain, target_domain)\\n            classifier.train(x_s_tr, y_s_tr, x_t_valid, y_t_valid, x_t_tr, y_t_tr, x_s_tst, x_t_tst)\\n            classifier = DCMD(source_domain, target_domain)\\n            classifier.train(x_s_tr, x_t_tr, x_s_tr, y_s_tr,\\n                      x_t_valid, y_t_valid, x_t_tst, y_t_tst, x_s_tst, x_t_tst)\\n\\n            # input = raw_input('Input to continue!')\\n            # Fine-tune with tiny target domain samples on source domain model\\n            # print('Fine-tune with tiny target domain samples on source domain model')\\n            # cmd_results = []\\n            # fine_tune_results = []\\n            # cmd_classifier = TransferClassifier(source_domain, target_domain)\\n            # classifier = FineTuneClassifier(source_domain, target_domain)\\n            # for i in range(5):\\n            #     cmd_result = cmd_classifier.train(x_s_tr, x_t_tr, x_s_tr, y_s_tr, x_t_tune, y_t_tune,\\n            #           x_t_valid, y_t_valid, x_t_tst, y_t_tst)\\n            #     # input = raw_input('Input any character!')\\n            #     fine_tune_result = classifier.train(x_s_tr, x_t_tr, x_s_tr, y_s_tr, x_t_tune, y_t_tune,\\n            #                                     x_t_valid, y_t_valid, x_t_tst, y_t_tst)\\n            #     # input = raw_input('Input any character!')\\n            #     cmd_results.append(cmd_result)\\n            #     fine_tune_results.append(fine_tune_result)\\n            # print('Source domain:{0}\\t Target domain:{1}'.format(source_domain, target_domain))\\n            # print('cmd_result:', sum(cmd_results)/len(cmd_results))\\n            # print('fine_tune_result:', sum(fine_tune_results)/len(fine_tune_results))\\n\\n\\n    for result in mean_results:\\n        print(result)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEzjC3Q3vIJi",
        "outputId": "931637d0-4d41-4949-f265-c3caf754a40f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class CoTrainer(object):\n",
        "    def __init__(self, source_domain=0, target_domain=3, **kwargs):\n",
        "        self.source_domain = source_domain\n",
        "        self.target_domain = target_domain\n",
        "        self.learning_rate = 5e-3\n",
        "        self.data_load_from = '/content/drive/My Drive/amazon.mat'\n",
        "        self.batch_size = 200\n",
        "        self.model_save_to = '/content/drive/My Drive/output/Cotrain_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.model_load_from = self.model_save_to\n",
        "        self.common_model_save_to = '/content/drive/My Drive/output/Cotrain_common_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.target_model_save_to = '/content/drive/My Drive/output/Cotrain_target_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.combined_model_save_to = '/content/drive/My Drive/output/Cotrain_combined_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.n_input = 5000\n",
        "        self.n_classes = 2\n",
        "        self.d_hidden = 50\n",
        "        self.tolerate_time = 20\n",
        "        self.alpha = 1.\n",
        "        self.belta = 1.\n",
        "        self.gamma = 1.\n",
        "        self.lamb = 1.\n",
        "        self.beta = 1.\n",
        "        self.recon = 1.\n",
        "        self.n_hidden_c = 50\n",
        "        self.n_hidden_s = 50\n",
        "        self.n_hidden_t = 50\n",
        "\n",
        "    def build_model(self):\n",
        "        n_classes = self.n_classes\n",
        "\n",
        "        def matchnorm(x1, x2):\n",
        "            return tf.compat.v1.sqrt(tf.compat.v1.reduce_sum(tf.compat.v1.pow(x1 - x2, 2)))\n",
        "\n",
        "        def scm(sx1, sx2, k):\n",
        "            ss1 = tf.compat.v1.reduce_mean(tf.compat.v1.pow(sx1, k), 0)\n",
        "            ss2 = tf.compat.v1.reduce_mean(tf.compat.v1.pow(sx2, k), 0)\n",
        "            return matchnorm(ss1, ss2)\n",
        "\n",
        "        def mmatch(x1, x2, n_moments):\n",
        "            mx1 = tf.compat.v1.reduce_mean(x1, 0)\n",
        "            mx2 = tf.compat.v1.reduce_mean(x2, 0)\n",
        "            sx1 = x1 - mx1\n",
        "            sx2 = x2 - mx2\n",
        "            dm = matchnorm(mx1, mx2)\n",
        "            scms = dm\n",
        "            for i in range(n_moments - 1):\n",
        "                scms += scm(sx1, sx2, i + 2)\n",
        "            return scms\n",
        "\n",
        "        # tf Graph input\n",
        "        self.X_s_u = tf.compat.v1.placeholder(\"float\", [None, self.n_input])  # source unlabeled data\n",
        "        self.X_t_u = tf.compat.v1.placeholder(\"float\", [None, self.n_input])  # target unlabeled data\n",
        "        self.X_s = tf.compat.v1.placeholder(\"float\", [None, self.n_input])    # source labeled data\n",
        "        self.Y_s = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "        self.X_t = tf.compat.v1.placeholder(\"float\", [None, self.n_input])    # target labeled data\n",
        "        self.Y_t = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "        self.common_encode_mlp = MLP(name='common_encode_mlp', dims=[self.n_input, self.n_hidden_c],\n",
        "                                     activations=[tf.compat.v1.nn.sigmoid])\n",
        "        self.target_encode_mlp = MLP(name='target_encode_mlp', dims=[self.n_input, self.n_hidden_t],\n",
        "                                     activations=[tf.compat.v1.nn.sigmoid])\n",
        "        self.common_decode_mlp = MLP(name='common_decode_mlp',\n",
        "                                     dims=[self.n_hidden_c, (self.n_hidden_c + self.n_input) / 2, self.n_input],\n",
        "                                     activations=[tf.compat.v1.nn.tanh, tf.compat.v1.nn.relu])\n",
        "        self.target_decode_mlp = MLP(name='target_decode_mlp',\n",
        "                                     dims=[self.n_hidden_t, (self.n_hidden_t + self.n_input) / 2, self.n_input],\n",
        "                                     activations=[tf.compat.v1.nn.tanh, tf.compat.v1.nn.relu])\n",
        "        self.common_output_mlp = MLP(name='common_output_mlp', dims=[self.n_hidden_c, n_classes],\n",
        "                                     activations=[identity])\n",
        "        self.target_output_mlp = MLP(name='target_output_mlp', dims=[self.n_hidden_t, n_classes],\n",
        "                                     activations=[identity])\n",
        "\n",
        "        encoding_c_s_u = self.common_encode_mlp.apply(self.X_s_u)\n",
        "        encoding_c_t_u = self.common_encode_mlp.apply(self.X_t_u)\n",
        "        encoding_t_t_u = self.target_encode_mlp.apply(self.X_t_u)\n",
        "        encoding_t_s_u = self.target_encode_mlp.apply(self.X_s_u)\n",
        "        # Get cmd loss\n",
        "        self.cmd_c_loss = mmatch(encoding_c_s_u, encoding_c_t_u, 3)\n",
        "        self.cmd_t_loss = -mmatch(encoding_t_s_u, encoding_t_t_u, 3)\n",
        "        # Get reconstruction loss\n",
        "        decoding_c_t_u = self.common_decode_mlp.apply(encoding_c_t_u)\n",
        "        decoding_t_t_u = self.target_decode_mlp.apply(encoding_t_t_u)   # change to the common decode mlp\n",
        "        decoding_t_u = decoding_c_t_u + decoding_t_t_u\n",
        "        self.R_loss = tf.compat.v1.reduce_mean(tf.compat.v1.square(decoding_t_u - self.X_t_u))\n",
        "        # Get common classification loss\n",
        "        encoding_c_s = self.common_encode_mlp.apply(self.X_s)\n",
        "        pred_s = self.common_output_mlp.apply(encoding_c_s)\n",
        "        self.pred_s = pred_s\n",
        "        self.prob_s = tf.compat.v1.nn.softmax(pred_s)\n",
        "        self.C_loss = (tf.compat.v1.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits(logits=pred_s, labels=self.Y_s)))\n",
        "        correct_prediction = tf.compat.v1.equal(tf.compat.v1.argmax(pred_s, 1), tf.compat.v1.argmax(self.Y_s, 1))\n",
        "        self.accuracy_s = tf.compat.v1.reduce_mean(tf.compat.v1.cast(correct_prediction, \"float\"))\n",
        "        # Get target classification loss\n",
        "        encoding_t_t = self.target_encode_mlp.apply(self.X_t)\n",
        "        pred_t = self.target_output_mlp.apply(encoding_t_t)\n",
        "        self.pred_t = pred_t\n",
        "        self.prob_t = tf.compat.v1.nn.softmax(pred_t)\n",
        "        self.T_loss = tf.compat.v1.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits(logits=pred_t, labels=self.Y_t))\n",
        "        correct_prediction = tf.compat.v1.equal(tf.compat.v1.argmax(pred_t, 1), tf.compat.v1.argmax(self.Y_t, 1))\n",
        "        self.accuracy_t = tf.compat.v1.reduce_mean(tf.compat.v1.cast(correct_prediction, \"float\"))\n",
        "        # Build solver\n",
        "        self.theta = (self.common_encode_mlp.parameters +\n",
        "                      self.target_encode_mlp.parameters +\n",
        "                      self.common_decode_mlp.parameters +\n",
        "                      self.target_decode_mlp.parameters +\n",
        "                      self.common_output_mlp.parameters +\n",
        "                      self.target_output_mlp.parameters)\n",
        "        l2_norm = 0.\n",
        "        for tensor in self.theta:\n",
        "            if tensor.name.find('W') != 0:\n",
        "                l2_norm += tf.compat.v1.reduce_sum(tf.compat.v1.abs(tensor))\n",
        "        for tensor in self.target_output_mlp.parameters + self.target_encode_mlp.parameters:\n",
        "            if tensor.name.find('W') != 0:\n",
        "                l2_norm += 4 * tf.compat.v1.reduce_sum(tf.compat.v1.abs(tensor))\n",
        "        self.loss = (self.recon * self.R_loss +\n",
        "                     self.alpha * self.C_loss +\n",
        "                     self.belta * self.T_loss +\n",
        "                     self.gamma * self.cmd_c_loss +\n",
        "                     self.lamb * self.cmd_t_loss +\n",
        "                     0.0001 * l2_norm)\n",
        "        self.solver = (tf.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                       .minimize(self.loss, var_list=self.theta))\n",
        "        self.common_loss = (self.recon * self.R_loss +\n",
        "                            self.alpha * self.C_loss +\n",
        "                            self.gamma * self.cmd_c_loss +\n",
        "                            self.lamb * self.cmd_t_loss +\n",
        "                            0.0001 * l2_norm)\n",
        "        self.common_solver = (tf.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                              .minimize(self.common_loss, var_list=self.theta))\n",
        "        self.target_loss = (self.recon * self.R_loss +\n",
        "                            self.belta * self.T_loss +\n",
        "                            self.gamma * self.cmd_c_loss +\n",
        "                            self.lamb * self.cmd_t_loss +\n",
        "                            0.0001 * l2_norm)\n",
        "        self.target_solver = (tf.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                              .minimize(self.target_loss, var_list=self.theta))\n",
        "        self.combined_loss = (self.C_loss + 0.0001 * l2_norm)\n",
        "        self.combined_solver = (tf.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                              .minimize(self.combined_loss, var_list=self.theta))\n",
        "\n",
        "    def train_common_model(self, x_s_u, x_t_u, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        wait_times = 0\n",
        "        best_result = 0.\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            while True:\n",
        "                (_, c_loss, cmd_c_loss, cmd_t_loss, r_loss, accuracy) = self.sess.run(\n",
        "                    [self.common_solver, self.C_loss, self.cmd_c_loss, -self.cmd_t_loss, self.R_loss,\n",
        "                     self.accuracy_s],\n",
        "                    feed_dict={self.X_s: x_t,\n",
        "                               self.Y_s: y_t,\n",
        "                               self.X_s_u: x_s_u,\n",
        "                               self.X_t_u: x_t_u,\n",
        "                               }\n",
        "                )\n",
        "                print('c_loss:{0}'.format(c_loss))\n",
        "                print('cmd_c_loss:{0}'.format(cmd_c_loss))\n",
        "                print('cmd_t_loss:{0}'.format(cmd_t_loss))\n",
        "                print('r_loss:{0}'.format(r_loss))\n",
        "                print('accuracy_s:{0}'.format(accuracy))\n",
        "                if accuracy > 0.7:\n",
        "                    valid_accuracy = self.accuracy_s.eval({self.X_s: x_valid,\n",
        "                                                         self.Y_s: y_valid},\n",
        "                                                        session=self.sess)\n",
        "                    if valid_accuracy > best_result:\n",
        "                        best_result = valid_accuracy\n",
        "                        wait_times = 0\n",
        "                        print('Save model...')\n",
        "                        saver.save(self.sess, save_path=self.common_model_save_to)\n",
        "                        print('Done!')\n",
        "                    else:\n",
        "                        wait_times += 1\n",
        "                    if wait_times >= self.tolerate_time:\n",
        "                        print('best_result:{0}'.format(best_result))\n",
        "                        break\n",
        "                    print(\"valid accuracy:\", valid_accuracy)\n",
        "            saver.restore(self.sess, self.common_model_save_to)\n",
        "            test_accuracy = self.accuracy_s.eval({self.X_s: x_test,\n",
        "                                                   self.Y_s: y_test},\n",
        "                                                  session=self.sess)\n",
        "            print('test_accuracy:{0}'.format(test_accuracy))\n",
        "            return best_result\n",
        "\n",
        "    def train_target_model(self, x_s_u, x_t_u, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        wait_times = 0\n",
        "        best_result = 0.\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            while True:\n",
        "                (_, t_loss, cmd_c_loss, cmd_t_loss,\n",
        "                 r_loss, accuracy) = self.sess.run(\n",
        "                    [self.target_solver, self.T_loss, self.cmd_c_loss, -self.cmd_t_loss, self.R_loss, self.accuracy_t],\n",
        "                    feed_dict={self.X_t: x_t,\n",
        "                               self.Y_t: y_t,\n",
        "                               self.X_s_u: x_s_u,\n",
        "                               self.X_t_u: x_t_u,\n",
        "                    }\n",
        "                )\n",
        "                print('t_loss:{0}'.format(t_loss))\n",
        "                print('cmd_c_loss:{0}'.format(cmd_c_loss))\n",
        "                print('cmd_t_loss:{0}'.format(cmd_t_loss))\n",
        "                print('r_loss:{0}'.format(r_loss))\n",
        "                print('accuracy_t:{0}'.format(accuracy))\n",
        "                if accuracy > 0.7:\n",
        "                    valid_accuracy = self.accuracy_t.eval({self.X_t: x_valid,\n",
        "                                                           self.Y_t: y_valid},\n",
        "                                                          session=self.sess)\n",
        "                    if valid_accuracy > best_result:\n",
        "                        best_result = valid_accuracy\n",
        "                        wait_times = 0\n",
        "                        print('Save model...')\n",
        "                        saver.save(self.sess, save_path=self.target_model_save_to)\n",
        "                        print('Done!')\n",
        "                    else:\n",
        "                        wait_times += 1\n",
        "                    if wait_times >= self.tolerate_time:\n",
        "                        print('best_result:{0}'.format(best_result))\n",
        "                        break\n",
        "                    print(\"valid accuracy:\", valid_accuracy)\n",
        "            saver.restore(self.sess, self.target_model_save_to)\n",
        "            test_accuracy = self.accuracy_t.eval({self.X_t: x_test,\n",
        "                                                  self.Y_t: y_test},\n",
        "                                                 session=self.sess)\n",
        "            print('test_accuracy:{0}'.format(test_accuracy))\n",
        "            return best_result\n",
        "\n",
        "    def train_combined_model(self, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, self.common_model_save_to)\n",
        "            common_valid_probs, = self.sess.run([self.prob_s], feed_dict={self.X_s: x_valid})\n",
        "            common_test_probs, = self.sess.run([self.prob_s], feed_dict={self.X_s: x_test})\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, self.target_model_save_to)\n",
        "            target_valid_probs, = self.sess.run([self.prob_t], feed_dict={self.X_t: x_valid})\n",
        "            target_test_probs, = self.sess.run([self.prob_t], feed_dict={self.X_t: x_test})\n",
        "            best_result = 0.\n",
        "            best_beta = 0.\n",
        "            for beta in [0., 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.]:\n",
        "                valid_probs = common_valid_probs + beta * target_valid_probs\n",
        "                valid_accuracy = np.equal(valid_probs.argmax(axis=1), y_valid.argmax(axis=1)).mean()\n",
        "                if valid_accuracy > best_result:\n",
        "                    best_result = valid_accuracy\n",
        "                    best_beta = beta\n",
        "            valid_accuracy = best_result\n",
        "            test_probs = common_test_probs + best_beta * target_test_probs\n",
        "            test_accuracy = np.equal(test_probs.argmax(axis=1), y_test.argmax(axis=1)).mean()\n",
        "            print('valid accuracy:', valid_accuracy)\n",
        "            print(\"test accuracy:\", test_accuracy)\n",
        "            return valid_accuracy, test_accuracy\n",
        "\n",
        "    def train(self, x_s_u, x_t_u, x_s, y_s, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        U = np.copy(x_t_u)\n",
        "        select_num = 5\n",
        "        best_result = 0.\n",
        "        final_test_accuracy = 0.\n",
        "        wait_times = 0.\n",
        "        while len(U) > 0:\n",
        "            print('Train common model...')\n",
        "            self.train_common_model(x_s_u, x_t_u, np.concatenate([x_s, x_t]), np.concatenate([y_s, y_t]),\n",
        "                                    x_valid, y_valid, x_test, y_test)\n",
        "            print('Train target model...')\n",
        "            self.train_target_model(x_s_u, x_t_u, x_t, y_t, x_valid, y_valid, x_test, y_test)\n",
        "            # Select U\n",
        "            probs = [self.get_common_prediction(U), self.get_target_prediction(U)]\n",
        "            x_hat, y_hat, U = self.select_sample(U, probs, select_num=select_num)\n",
        "            x_t = np.concatenate([x_t, x_hat], axis=0)\n",
        "            y_t = np.concatenate([y_t, y_hat], axis=0)\n",
        "            print('Train combined model...')\n",
        "            valid_accuracy, test_accuracy = self.train_combined_model(x_t, y_t, x_valid, y_valid, x_test, y_test)\n",
        "            if valid_accuracy > best_result:\n",
        "                best_result = valid_accuracy\n",
        "                final_test_accuracy = test_accuracy\n",
        "                wait_times = 0\n",
        "            else:\n",
        "                wait_times += 1\n",
        "            if wait_times >= self.tolerate_time:\n",
        "                print('best_result:{0}'.format(best_result))\n",
        "                break\n",
        "        print('Test accuracy:{0}'.format(final_test_accuracy))\n",
        "\n",
        "    def select_sample(self, U, probs, select_num):\n",
        "        neg_idxes = set()\n",
        "        pos_idxes = set()\n",
        "        left_idxes = set(range(len(U)))\n",
        "        for prob in probs:\n",
        "            idxes = np.argsort(prob[:, 0])\n",
        "            end_idx = min(select_num, (prob[:, 0][idxes[:select_num]] < 0.5).sum())\n",
        "            begin_idx = min(select_num, (prob[:, 0][idxes[-select_num:]] > 0.5).sum())\n",
        "            idx = min(begin_idx, end_idx)\n",
        "            if idx == 0:\n",
        "                idx = 1\n",
        "            begin_idx = idx\n",
        "            end_idx = idx\n",
        "            neg_idxes.update(idxes[:end_idx])\n",
        "            pos_idxes.update(idxes[-begin_idx:])\n",
        "            print('pos num:', len(pos_idxes))\n",
        "            print('neg num:', len(neg_idxes))\n",
        "            left_idxes = left_idxes.intersection(idxes[end_idx:-begin_idx])\n",
        "\n",
        "        pos_idxes = np.array(list(pos_idxes))\n",
        "        neg_idxes = np.array(list(neg_idxes))\n",
        "        left_idxes = np.array(list(left_idxes))\n",
        "        x_n = U[neg_idxes]\n",
        "        x_p = U[pos_idxes]\n",
        "        y_n = np.zeros(shape=(len(x_n), 2), dtype='float32')\n",
        "        y_n[:, 1] = 1.\n",
        "        y_p = np.zeros(shape=(len(x_p), 2), dtype='float32')\n",
        "        y_p[:, 0] = 1.\n",
        "        U = U[left_idxes]\n",
        "        x = np.concatenate([x_n, x_p], axis=0)\n",
        "        y = np.concatenate([y_n, y_p], axis=0)\n",
        "        x, y = shuffle3([x, y])\n",
        "        print('unlabelled num:', len(U))\n",
        "        print(len(left_idxes))\n",
        "        return x, y, U\n",
        "\n",
        "    def get_common_prediction(self, X):\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, self.common_model_save_to)\n",
        "            probs, = self.sess.run([self.prob_s], feed_dict={self.X_s: X})\n",
        "        return probs\n",
        "\n",
        "    def get_target_prediction(self, X):\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, self.target_model_save_to)\n",
        "            probs, = self.sess.run([self.prob_t], feed_dict={self.X_t: X})\n",
        "        return probs\n",
        "\n",
        "    def analysis(self, x_t_train, y_t_train):\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, '/content/drive/My Drive/output/combined.pkl')\n",
        "            H_t, = self.sess.run([self.encoding_t_t],\n",
        "                                 feed_dict={self.X_t: x_t_train})\n",
        "        pca = PCA(n_components=2)\n",
        "        H_t_hat = pca.fit_transform(H_t)\n",
        "        plt.scatter(H_t_hat[:, 0][y_t_train[:, 0]==0.], H_t_hat[:, 1][y_t_train[:, 0]==0.], color='r', alpha=.4, s=1)\n",
        "        plt.scatter(H_t_hat[:, 0][y_t_train[:, 0]==1.], H_t_hat[:, 1][y_t_train[:, 0]==1.], color='b', alpha=.4, s=1)\n",
        "        plt.savefig(\"h_t.pdf\", dpi=72)\n",
        "\n",
        "\n",
        "class CoCMD(object):\n",
        "    def __init__(self, source_domain=0, target_domain=3, **kwargs):\n",
        "        self.classifier = CombinedClassifier()\n",
        "        self.source_domain = source_domain\n",
        "        self.target_domain = target_domain\n",
        "        self.learning_rate = 5e-3\n",
        "        self.data_load_from = '/content/drive/My Drive/amazon.mat'\n",
        "        self.batch_size = 200\n",
        "        self.model_save_to = '/content/drive/My Drive/output/Cotrain_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.model_load_from = self.model_save_to\n",
        "        self.common_model_save_to = '/content/drive/My Drive/output/Cotrain_common_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.target_model_save_to = '/content/drive/My Drive/output/Cotrain_target_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.combined_model_save_to = '/content/drive/My Drive/output/Cotrain_combined_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.n_input = 5000\n",
        "        self.n_classes = 2\n",
        "        self.d_hidden = 50\n",
        "        self.tolerate_time = 20\n",
        "        self.alpha = 1.\n",
        "        self.belta = 1.\n",
        "        self.gamma = 1.\n",
        "        self.lamb = 1.\n",
        "        self.beta = 1.\n",
        "        self.recon = 1.\n",
        "        self.n_hidden_c = 50\n",
        "        self.n_hidden_s = 50\n",
        "        self.n_hidden_t = 50\n",
        "\n",
        "    def build_model(self):\n",
        "        n_classes = self.n_classes\n",
        "\n",
        "        def matchnorm(x1, x2):\n",
        "            return tf.compat.v1.sqrt(tf.compat.v1.reduce_sum(tf.compat.v1.pow(x1 - x2, 2)))\n",
        "\n",
        "        def scm(sx1, sx2, k):\n",
        "            ss1 = tf.compat.v1.reduce_mean(tf.compat.v1.pow(sx1, k), 0)\n",
        "            ss2 = tf.compat.v1.reduce_mean(tf.compat.v1.pow(sx2, k), 0)\n",
        "            return matchnorm(ss1, ss2)\n",
        "\n",
        "        def mmatch(x1, x2, n_moments):\n",
        "            mx1 = tf.compat.v1.reduce_mean(x1, 0)\n",
        "            mx2 = tf.compat.v1.reduce_mean(x2, 0)\n",
        "            sx1 = x1 - mx1\n",
        "            sx2 = x2 - mx2\n",
        "            dm = matchnorm(mx1, mx2)\n",
        "            scms = dm\n",
        "            for i in range(n_moments - 1):\n",
        "                scms += scm(sx1, sx2, i + 2)\n",
        "            return scms\n",
        "\n",
        "        # tf Graph input\n",
        "        self.X_s_u = tf.compat.v1.placeholder(\"float\", [None, self.n_input])  # source unlabeled data\n",
        "        self.X_t_u = tf.compat.v1.placeholder(\"float\", [None, self.n_input])  # target unlabeled data\n",
        "        self.X_s = tf.compat.v1.placeholder(\"float\", [None, self.n_input])    # source labeled data\n",
        "        self.Y_s = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "        self.X_t = tf.compat.v1.placeholder(\"float\", [None, self.n_input])    # target labeled data\n",
        "        self.Y_t = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "        self.common_encode_mlp = MLP(name='common_encode_mlp', dims=[self.n_input, self.n_hidden_c],\n",
        "                                     activations=[tf.compat.v1.nn.sigmoid])\n",
        "        self.target_encode_mlp = MLP(name='target_encode_mlp', dims=[self.n_input, self.n_hidden_t],\n",
        "                                     activations=[tf.compat.v1.nn.sigmoid])\n",
        "        self.common_decode_mlp = MLP(name='common_decode_mlp',\n",
        "                                     dims=[self.n_hidden_c, (self.n_hidden_c + self.n_input) / 2, self.n_input],\n",
        "                                     activations=[tf.compat.v1.nn.tanh, tf.compat.v1.nn.relu])\n",
        "        self.target_decode_mlp = MLP(name='target_decode_mlp',\n",
        "                                     dims=[self.n_hidden_t, (self.n_hidden_t + self.n_input) / 2, self.n_input],\n",
        "                                     activations=[tf.compat.v1.nn.tanh, tf.compat.v1.nn.relu])\n",
        "        self.common_output_mlp = MLP(name='common_output_mlp', dims=[self.n_hidden_c, n_classes],\n",
        "                                     activations=[identity])\n",
        "        self.target_output_mlp = MLP(name='target_output_mlp', dims=[self.n_hidden_t, n_classes],\n",
        "                                     activations=[identity])\n",
        "\n",
        "        encoding_c_s_u = self.common_encode_mlp.apply(self.X_s_u)\n",
        "        encoding_c_t_u = self.common_encode_mlp.apply(self.X_t_u)\n",
        "        encoding_t_t_u = self.target_encode_mlp.apply(self.X_t_u)\n",
        "        encoding_t_s_u = self.target_encode_mlp.apply(self.X_s_u)\n",
        "        # Get cmd loss\n",
        "        self.cmd_c_loss = mmatch(encoding_c_s_u, encoding_c_t_u, 3)\n",
        "        self.cmd_t_loss = -mmatch(encoding_t_s_u, encoding_t_t_u, 3)\n",
        "        # Get reconstruction loss\n",
        "        decoding_c_t_u = self.common_decode_mlp.apply(encoding_c_t_u)\n",
        "        decoding_t_t_u = self.target_decode_mlp.apply(encoding_t_t_u)   # change to the common decode mlp\n",
        "        decoding_t_u = decoding_c_t_u + decoding_t_t_u\n",
        "        self.R_loss = tf.compat.v1.reduce_mean(tf.compat.v1.square(decoding_t_u - self.X_t_u))\n",
        "        # Get common classification loss\n",
        "        encoding_c_s = self.common_encode_mlp.apply(self.X_s)\n",
        "        pred_s = self.common_output_mlp.apply(encoding_c_s)\n",
        "        self.pred_s = pred_s\n",
        "        self.prob_s = tf.compat.v1.nn.softmax(pred_s)\n",
        "        self.C_loss = (tf.compat.v1.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits(logits=pred_s, labels=self.Y_s)))\n",
        "        correct_prediction = tf.compat.v1.equal(tf.compat.v1.argmax(pred_s, 1), tf.compat.v1.argmax(self.Y_s, 1))\n",
        "        self.accuracy_s = tf.compat.v1.reduce_mean(tf.compat.v1.cast(correct_prediction, \"float\"))\n",
        "        # Get target classification loss\n",
        "        encoding_t_t = self.target_encode_mlp.apply(self.X_t)\n",
        "        pred_t = self.target_output_mlp.apply(encoding_t_t)\n",
        "        self.pred_t = pred_t\n",
        "        self.prob_t = tf.compat.v1.nn.softmax(pred_t)\n",
        "        self.T_loss = tf.compat.v1.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits(logits=pred_t, labels=self.Y_t))\n",
        "        correct_prediction = tf.compat.v1.equal(tf.compat.v1.argmax(pred_t, 1), tf.compat.v1.argmax(self.Y_t, 1))\n",
        "        self.accuracy_t = tf.compat.v1.reduce_mean(tf.compat.v1.cast(correct_prediction, \"float\"))\n",
        "        # Build solver\n",
        "        self.theta = (self.common_encode_mlp.parameters +\n",
        "                      self.target_encode_mlp.parameters +\n",
        "                      self.common_decode_mlp.parameters +\n",
        "                      self.target_decode_mlp.parameters +\n",
        "                      self.common_output_mlp.parameters +\n",
        "                      self.target_output_mlp.parameters)\n",
        "        l2_norm = 0.\n",
        "        for tensor in self.theta:\n",
        "            if tensor.name.find('W') != 0:\n",
        "                l2_norm += tf.compat.v1.reduce_sum(tf.compat.v1.abs(tensor))\n",
        "        for tensor in self.target_output_mlp.parameters + self.target_encode_mlp.parameters:\n",
        "            if tensor.name.find('W') != 0:\n",
        "                l2_norm += 4 * tf.compat.v1.reduce_sum(tf.compat.v1.abs(tensor))\n",
        "        self.loss = (self.recon * self.R_loss +\n",
        "                     self.alpha * self.C_loss +\n",
        "                     self.belta * self.T_loss +\n",
        "                     self.gamma * self.cmd_c_loss +\n",
        "                     self.lamb * self.cmd_t_loss +\n",
        "                     0.0001 * l2_norm)\n",
        "        self.solver = (tf.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                       .minimize(self.loss, var_list=self.theta))\n",
        "\n",
        "    def train_model(self, x_s_u, x_t_u, x_s, y_s, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        wait_times = 0\n",
        "        best_result = 0.\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            while True:\n",
        "                (_, c_loss, t_loss, cmd_c_loss, cmd_t_loss,\n",
        "                 r_loss, accuracy_s, accuracy_t) = self.sess.run(\n",
        "                    [self.solver, self.C_loss, self.T_loss, self.cmd_c_loss, -self.cmd_t_loss,\n",
        "                     self.R_loss, self.accuracy_s, self.accuracy_t],\n",
        "                    feed_dict={self.X_t: x_t,\n",
        "                               self.Y_t: y_t,\n",
        "                               self.X_s: x_s,\n",
        "                               self.Y_s: y_s,\n",
        "                               self.X_s_u: x_s_u,\n",
        "                               self.X_t_u: x_t_u,\n",
        "                               }\n",
        "                )\n",
        "                print('t_loss:{0}'.format(t_loss))\n",
        "                print('cmd_c_loss:{0}'.format(cmd_c_loss))\n",
        "                print('cmd_t_loss:{0}'.format(cmd_t_loss))\n",
        "                print('r_loss:{0}'.format(r_loss))\n",
        "                print('accuracy_s:{0}'.format(accuracy_s))\n",
        "                print('accuracy_t:{0}'.format(accuracy_t))\n",
        "                if accuracy_t > 0.7:\n",
        "                    common_valid_preds, target_valid_preds = self.sess.run([self.prob_s, self.prob_t],\n",
        "                                                        feed_dict={self.X_s: x_valid, self.X_t: x_valid})\n",
        "                    valid_preds = common_valid_preds + target_valid_preds\n",
        "                    valid_accuracy = np.equal(np.argmax(valid_preds, axis=1), np.argmax(y_valid, axis=1)).mean()\n",
        "                    if valid_accuracy > best_result:\n",
        "                        best_result = valid_accuracy\n",
        "                        wait_times = 0\n",
        "                        print('Save model...')\n",
        "                        saver.save(self.sess, save_path=self.model_save_to)\n",
        "                        print('Done!')\n",
        "                    else:\n",
        "                        wait_times += 1\n",
        "                    if wait_times >= self.tolerate_time:\n",
        "                        print('best_result:{0}'.format(best_result))\n",
        "                        break\n",
        "                    print(\"valid accuracy:\", valid_accuracy)\n",
        "            saver.restore(self.sess, self.model_save_to)\n",
        "            common_test_preds, target_test_preds = self.sess.run([self.prob_s, self.prob_t],\n",
        "                                                                   feed_dict={self.X_s: x_test, self.X_t: x_test})\n",
        "            test_preds = common_test_preds + target_test_preds\n",
        "            test_accuracy = np.equal(np.argmax(test_preds, axis=1), np.argmax(y_test, axis=1)).mean()\n",
        "            print('test_accuracy:{0}'.format(test_accuracy))\n",
        "            return best_result, test_accuracy\n",
        "\n",
        "    def train(self, x_s_u, x_t_u, x_s, y_s, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        U = np.copy(x_t_u)\n",
        "        select_num = 5\n",
        "        best_result = 0.\n",
        "        final_test_accuracy = 0.\n",
        "        wait_times = 0.\n",
        "        while len(U) > 0:\n",
        "            print('Train model...')\n",
        "            valid_accuracy, test_accuracy = self.train_model(x_s_u, x_t_u,\n",
        "                                                             np.concatenate([x_s, x_t]), np.concatenate([y_s, y_t]),\n",
        "                                                             x_t, y_t, x_valid, y_valid, x_test, y_test)\n",
        "            # Select unlabeled data\n",
        "            probs = self.get_prediction(U)\n",
        "            x_hat, y_hat, U = self.select_sample(U, probs, select_num=select_num)\n",
        "            x_t = np.concatenate([x_t, x_hat], axis=0)\n",
        "            y_t = np.concatenate([y_t, y_hat], axis=0)\n",
        "            print('Train combined model...')\n",
        "            if valid_accuracy > best_result:\n",
        "                best_result = valid_accuracy\n",
        "                final_test_accuracy = test_accuracy\n",
        "                wait_times = 0\n",
        "            else:\n",
        "                wait_times += 1\n",
        "            if wait_times >= self.tolerate_time:\n",
        "                print('best_result:{0}'.format(best_result))\n",
        "                break\n",
        "        print('Test accuracy:{0}'.format(final_test_accuracy))\n",
        "\n",
        "    def select_sample(self, U, probs, select_num):\n",
        "        neg_idxes = set()\n",
        "        pos_idxes = set()\n",
        "        left_idxes = set(range(len(U)))\n",
        "        for prob in probs:\n",
        "            idxes = np.argsort(prob[:, 0])\n",
        "            end_idx = min(select_num, (prob[:, 0][idxes[:select_num]] < 0.5).sum())\n",
        "            begin_idx = min(select_num, (prob[:, 0][idxes[-select_num:]] > 0.5).sum())\n",
        "            idx = min(begin_idx, end_idx)\n",
        "            if idx == 0:\n",
        "                idx = 1\n",
        "            begin_idx = idx\n",
        "            end_idx = idx\n",
        "            neg_idxes.update(idxes[:end_idx])\n",
        "            pos_idxes.update(idxes[-begin_idx:])\n",
        "            print('pos num:', len(pos_idxes))\n",
        "            print('neg num:', len(neg_idxes))\n",
        "            left_idxes = left_idxes.intersection(idxes[end_idx:-begin_idx])\n",
        "\n",
        "        pos_idxes = np.array(list(pos_idxes))\n",
        "        neg_idxes = np.array(list(neg_idxes))\n",
        "        left_idxes = np.array(list(left_idxes))\n",
        "        x_n = U[neg_idxes]\n",
        "        x_p = U[pos_idxes]\n",
        "        y_n = np.zeros(shape=(len(x_n), 2), dtype='float32')\n",
        "        y_n[:, 1] = 1.\n",
        "        print(probs[0][neg_idxes])\n",
        "        print(y_n)\n",
        "        # raw_input('Input any character!')\n",
        "        y_p = np.zeros(shape=(len(x_p), 2), dtype='float32')\n",
        "        y_p[:, 0] = 1.\n",
        "        U = U[left_idxes]\n",
        "        x = np.concatenate([x_n, x_p], axis=0)\n",
        "        y = np.concatenate([y_n, y_p], axis=0)\n",
        "        print('unlabelled num:', len(U))\n",
        "        print(len(left_idxes))\n",
        "        return x, y, U\n",
        "\n",
        "    def get_prediction(self, X):\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, self.model_save_to)\n",
        "            prob_s, prob_t = self.sess.run([self.prob_s, self.prob_t], feed_dict={self.X_s: X, self.X_t: X})\n",
        "        return [prob_s, prob_t]\n",
        "\n",
        "    def analysis(self, x_t_train, y_t_train):\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, '/content/drive/My Drive/output/combined.pkl')\n",
        "            H_t, = self.sess.run([self.encoding_t_t],\n",
        "                                 feed_dict={self.X_t: x_t_train})\n",
        "        pca = PCA(n_components=2)\n",
        "        H_t_hat = pca.fit_transform(H_t)\n",
        "        plt.scatter(H_t_hat[:, 0][y_t_train[:, 0]==0.], H_t_hat[:, 1][y_t_train[:, 0]==0.], color='r', alpha=.4, s=1)\n",
        "        plt.scatter(H_t_hat[:, 0][y_t_train[:, 0]==1.], H_t_hat[:, 1][y_t_train[:, 0]==1.], color='b', alpha=.4, s=1)\n",
        "        plt.savefig(\"h_t.pdf\", dpi=72)\n",
        "\n",
        "\n",
        "class CoDSN(object):\n",
        "    def __init__(self, source_domain=0, target_domain=3, **kwargs):\n",
        "        self.source_domain = source_domain\n",
        "        self.target_domain = target_domain\n",
        "        self.learning_rate = 5e-3\n",
        "        self.data_load_from = '/content/drive/My Drive/amazon.mat'\n",
        "        self.batch_size = 200\n",
        "        self.model_save_to = '/content/drive/My Drive/output/Cotrain_{0}_to_{1}.pkl'.format(source_domain, target_domain)\n",
        "        self.model_load_from = self.model_save_to\n",
        "        self.common_model_save_to = '/content/drive/My Drive/output/Cotrain_common_{0}_to_{1}.pkl'.format(source_domain,\n",
        "                                                                                                   target_domain)\n",
        "        self.common_tune_model_save_to = '/content/drive/My Drive/output/Cotrain_common_tune_{0}_to_{1}.pkl'.format(\n",
        "            source_domain, target_domain)\n",
        "        self.target_model_save_to = '/content/drive/My Drive/output/Cotrain_target_{0}_to_{1}.pkl'.format(source_domain,\n",
        "                                                                                                   target_domain)\n",
        "        self.combined_model_save_to = '/content/drive/My Drive/output/Cotrain_combined_{0}_to_{1}.pkl'.format(source_domain,\n",
        "                                                                                                       target_domain)\n",
        "        self.n_input = 5000\n",
        "        self.n_classes = 2\n",
        "        self.d_hidden = 50\n",
        "        self.tolerate_time = 20\n",
        "        self.alpha = 1.\n",
        "        self.belta = 1.\n",
        "        self.gamma = 1.\n",
        "        self.lamb = 1.\n",
        "        self.beta = 1.\n",
        "        self.n_hidden_c = 50\n",
        "        self.n_hidden_s = 50\n",
        "        self.n_hidden_t = 50\n",
        "\n",
        "    def build_model(self):\n",
        "        n_classes = self.n_classes\n",
        "\n",
        "        def matchnorm(x1, x2):\n",
        "            return tf.compat.v1.sqrt(tf.compat.v1.reduce_sum(tf.compat.v1.pow(x1 - x2, 2)))\n",
        "\n",
        "        def scm(sx1, sx2, k):\n",
        "            ss1 = tf.compat.v1.reduce_mean(tf.compat.v1.pow(sx1, k), 0)\n",
        "            ss2 = tf.compat.v1.reduce_mean(tf.compat.v1.pow(sx2, k), 0)\n",
        "            return matchnorm(ss1, ss2)\n",
        "\n",
        "        def mmatch(x1, x2, n_moments):\n",
        "            mx1 = tf.compat.v1.reduce_mean(x1, 0)\n",
        "            mx2 = tf.compat.v1.reduce_mean(x2, 0)\n",
        "            sx1 = x1 - mx1\n",
        "            sx2 = x2 - mx2\n",
        "            dm = matchnorm(mx1, mx2)\n",
        "            scms = dm\n",
        "            for i in range(n_moments - 1):\n",
        "                scms += scm(sx1, sx2, i + 2)\n",
        "            return scms\n",
        "\n",
        "        # tf Graph input\n",
        "        self.X_s_u = tf.compat.v1.placeholder(\"float\", [None, self.n_input])  # source unlabeled data\n",
        "        self.X_t_u = tf.compat.v1.placeholder(\"float\", [None, self.n_input])  # target unlabeled data\n",
        "        self.X_s = tf.compat.v1.placeholder(\"float\", [None, self.n_input])  # source labeled data\n",
        "        self.Y_s = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "        self.X_t = tf.compat.v1.placeholder(\"float\", [None, self.n_input])  # target labeled data\n",
        "        self.Y_t = tf.compat.v1.placeholder(\"float\", [None, n_classes])\n",
        "\n",
        "        self.common_encode_mlp = MLP(name='common_encode_mlp', dims=[self.n_input, self.n_hidden_c],\n",
        "                                     activations=[tf.compat.v1.nn.sigmoid])\n",
        "        self.target_encode_mlp = MLP(name='target_encode_mlp', dims=[self.n_input, self.n_hidden_t],\n",
        "                                     activations=[tf.compat.v1.nn.sigmoid])\n",
        "        self.common_decode_mlp = MLP(name='common_decode_mlp',\n",
        "                                     dims=[self.n_hidden_c, (self.n_hidden_c + self.n_input) / 2, self.n_input],\n",
        "                                     activations=[tf.compat.v1.nn.tanh, tf.compat.v1.nn.relu])\n",
        "        self.target_decode_mlp = MLP(name='target_decode_mlp',\n",
        "                                     dims=[self.n_hidden_t, (self.n_hidden_t + self.n_input) / 2, self.n_input],\n",
        "                                     activations=[tf.compat.v1.nn.tanh, tf.compat.v1.nn.relu])\n",
        "        self.common_output_mlp = MLP(name='common_output_mlp', dims=[self.n_hidden_c, n_classes],\n",
        "                                     activations=[identity])\n",
        "        self.target_output_mlp = MLP(name='target_output_mlp', dims=[self.n_hidden_t, n_classes],\n",
        "                                     activations=[identity])\n",
        "\n",
        "        encoding_c_s_u = self.common_encode_mlp.apply(self.X_s_u)\n",
        "        encoding_c_t_u = self.common_encode_mlp.apply(self.X_t_u)\n",
        "        encoding_t_t_u = self.target_encode_mlp.apply(self.X_t_u)\n",
        "        encoding_t_s_u = self.target_encode_mlp.apply(self.X_s_u)\n",
        "        # Get cmd loss\n",
        "        self.cmd_c_loss = mmatch(encoding_c_s_u, encoding_c_t_u, 5)\n",
        "        self.cmd_t_loss = -mmatch(encoding_t_s_u, encoding_t_t_u, 5)\n",
        "        # Get reconstruction loss\n",
        "        decoding_c_t_u = self.common_decode_mlp.apply(encoding_c_t_u)\n",
        "        decoding_t_t_u = self.target_decode_mlp.apply(encoding_t_t_u)\n",
        "        decoding_t_u = decoding_c_t_u + decoding_t_t_u\n",
        "        self.R_loss = tf.compat.v1.reduce_mean(tf.compat.v1.square(decoding_t_u - self.X_t_u))\n",
        "        # Get common classification loss\n",
        "        encoding_c_s = self.common_encode_mlp.apply(self.X_s)\n",
        "        pred_s = self.common_output_mlp.apply(encoding_c_s)\n",
        "        self.pred_s = pred_s\n",
        "        self.prob_s = tf.compat.v1.nn.softmax(pred_s)\n",
        "        self.C_loss = (tf.compat.v1.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits(logits=pred_s, labels=self.Y_s)))\n",
        "        correct_prediction = tf.compat.v1.equal(tf.compat.v1.argmax(pred_s, 1), tf.compat.v1.argmax(self.Y_s, 1))\n",
        "        self.accuracy_s = tf.compat.v1.reduce_mean(tf.compat.v1.cast(correct_prediction, \"float\"))\n",
        "        # Get target classification loss\n",
        "        encoding_t_t = self.target_encode_mlp.apply(self.X_t)\n",
        "        pred_t = self.target_output_mlp.apply(encoding_t_t)\n",
        "        self.pred_t = pred_t\n",
        "        self.prob_t = tf.compat.v1.nn.softmax(pred_t)\n",
        "        self.T_loss = tf.compat.v1.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits(logits=pred_t, labels=self.Y_t))\n",
        "        correct_prediction = tf.compat.v1.equal(tf.compat.v1.argmax(pred_t, 1), tf.compat.v1.argmax(self.Y_t, 1))\n",
        "        self.accuracy_t = tf.compat.v1.reduce_mean(tf.compat.v1.cast(correct_prediction, \"float\"))\n",
        "        # Build solver\n",
        "        self.theta = (self.common_encode_mlp.parameters +\n",
        "                      self.target_encode_mlp.parameters +\n",
        "                      self.common_decode_mlp.parameters +\n",
        "                      self.target_decode_mlp.parameters +\n",
        "                      self.common_output_mlp.parameters +\n",
        "                      self.target_output_mlp.parameters)\n",
        "        l2_norm = 0.\n",
        "        for tensor in self.theta:\n",
        "            if tensor.name.find('W') != 0:\n",
        "                l2_norm += tf.compat.v1.reduce_sum(tf.compat.v1.abs(tensor))\n",
        "        for tensor in self.target_output_mlp.parameters:\n",
        "            if tensor.name.find('W') != 0:\n",
        "                l2_norm += 4 * tf.compat.v1.reduce_sum(tf.compat.v1.abs(tensor))\n",
        "        self.loss = (self.R_loss +\n",
        "                     self.alpha * self.C_loss +\n",
        "                     self.belta * self.T_loss +\n",
        "                     self.gamma * self.cmd_c_loss +\n",
        "                     self.lamb * self.cmd_t_loss +\n",
        "                     0.0001 * l2_norm)\n",
        "        self.solver = (tf.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                       .minimize(self.loss, var_list=self.theta))\n",
        "        self.common_loss = (self.R_loss +\n",
        "                            self.alpha * self.C_loss +\n",
        "                            self.gamma * self.cmd_c_loss +\n",
        "                            self.lamb * self.cmd_t_loss +\n",
        "                            0.0001 * l2_norm)\n",
        "        self.common_solver = (tf.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                              .minimize(self.common_loss, var_list=self.theta))\n",
        "        self.target_loss = (self.R_loss +\n",
        "                            self.belta * self.T_loss +\n",
        "                            self.gamma * self.cmd_c_loss +\n",
        "                            self.lamb * self.cmd_t_loss +\n",
        "                            0.0001 * l2_norm)\n",
        "        self.target_solver = (tf.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                              .minimize(self.target_loss, var_list=self.theta))\n",
        "        self.combined_loss = (self.C_loss + 0.0001 * l2_norm)\n",
        "        self.combined_solver = (tf.compat.v1.train.RMSPropOptimizer(learning_rate=self.learning_rate)\n",
        "                                .minimize(self.combined_loss, var_list=self.theta))\n",
        "\n",
        "    def train_common_model(self, x_s_u, x_t_u, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        wait_times = 0\n",
        "        best_result = 0.\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            while True:\n",
        "                (_, c_loss, cmd_c_loss, cmd_t_loss, r_loss, accuracy) = self.sess.run(\n",
        "                    [self.common_solver, self.C_loss, self.cmd_c_loss, -self.cmd_t_loss, self.R_loss,\n",
        "                     self.accuracy_s],\n",
        "                    feed_dict={self.X_s: x_t,\n",
        "                               self.Y_s: y_t,\n",
        "                               self.X_s_u: x_s_u,\n",
        "                               self.X_t_u: x_t_u,\n",
        "                               }\n",
        "                )\n",
        "                print('c_loss:{0}'.format(c_loss))\n",
        "                print('cmd_c_loss:{0}'.format(cmd_c_loss))\n",
        "                print('cmd_t_loss:{0}'.format(cmd_t_loss))\n",
        "                print('r_loss:{0}'.format(r_loss))\n",
        "                print('accuracy_s:{0}'.format(accuracy))\n",
        "                if accuracy > 0.7:\n",
        "                    valid_accuracy = self.accuracy_s.eval({self.X_s: x_valid,\n",
        "                                                           self.Y_s: y_valid},\n",
        "                                                          session=self.sess)\n",
        "                    if valid_accuracy > best_result:\n",
        "                        best_result = valid_accuracy\n",
        "                        wait_times = 0\n",
        "                        print('Save model...')\n",
        "                        saver.save(self.sess, save_path=self.common_model_save_to)\n",
        "                        print('Done!')\n",
        "                    else:\n",
        "                        wait_times += 1\n",
        "                    if wait_times >= self.tolerate_time:\n",
        "                        print('best_result:{0}'.format(best_result))\n",
        "                        break\n",
        "                    print(\"valid accuracy:\", valid_accuracy)\n",
        "            saver.restore(self.sess, self.common_model_save_to)\n",
        "            test_accuracy = self.accuracy_s.eval({self.X_s: x_test,\n",
        "                                                  self.Y_s: y_test},\n",
        "                                                 session=self.sess)\n",
        "            print('test_accuracy:{0}'.format(test_accuracy))\n",
        "            return best_result\n",
        "\n",
        "    def train_target_model(self, x_s_u, x_t_u, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        wait_times = 0\n",
        "        best_result = 0.\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            while True:\n",
        "                (_, t_loss, cmd_c_loss, cmd_t_loss,\n",
        "                 r_loss, accuracy) = self.sess.run(\n",
        "                    [self.target_solver, self.T_loss, self.cmd_c_loss, -self.cmd_t_loss, self.R_loss, self.accuracy_t],\n",
        "                    feed_dict={self.X_t: x_t,\n",
        "                               self.Y_t: y_t,\n",
        "                               self.X_s_u: x_s_u,\n",
        "                               self.X_t_u: x_t_u,\n",
        "                               }\n",
        "                )\n",
        "                print('t_loss:{0}'.format(t_loss))\n",
        "                print('cmd_c_loss:{0}'.format(cmd_c_loss))\n",
        "                print('cmd_t_loss:{0}'.format(cmd_t_loss))\n",
        "                print('r_loss:{0}'.format(r_loss))\n",
        "                print('accuracy_t:{0}'.format(accuracy))\n",
        "                if accuracy > 0.7:\n",
        "                    valid_accuracy = self.accuracy_t.eval({self.X_t: x_valid,\n",
        "                                                           self.Y_t: y_valid},\n",
        "                                                          session=self.sess)\n",
        "                    if valid_accuracy > best_result:\n",
        "                        best_result = valid_accuracy\n",
        "                        wait_times = 0\n",
        "                        print('Save model...')\n",
        "                        saver.save(self.sess, save_path=self.target_model_save_to)\n",
        "                        print('Done!')\n",
        "                    else:\n",
        "                        wait_times += 1\n",
        "                    if wait_times >= self.tolerate_time:\n",
        "                        print('best_result:{0}'.format(best_result))\n",
        "                        break\n",
        "                    print(\"valid accuracy:\", valid_accuracy)\n",
        "            saver.restore(self.sess, self.target_model_save_to)\n",
        "            test_accuracy = self.accuracy_t.eval({self.X_t: x_test,\n",
        "                                                  self.Y_t: y_test},\n",
        "                                                 session=self.sess)\n",
        "            print('test_accuracy:{0}'.format(test_accuracy))\n",
        "            return best_result\n",
        "\n",
        "    def train_combined_model(self, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, self.common_model_save_to)\n",
        "            common_valid_probs, = self.sess.run([self.prob_s], feed_dict={self.X_s: x_valid})\n",
        "            common_test_probs, = self.sess.run([self.prob_s], feed_dict={self.X_s: x_test})\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, self.target_model_save_to)\n",
        "            target_valid_probs, = self.sess.run([self.prob_s], feed_dict={self.X_s: x_valid})\n",
        "            target_test_probs, = self.sess.run([self.prob_s], feed_dict={self.X_s: x_test})\n",
        "            best_result = 0.\n",
        "            best_beta = 0.\n",
        "            for beta in [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.]:\n",
        "                valid_probs = common_valid_probs + beta * target_valid_probs\n",
        "                valid_accuracy = np.equal(valid_probs.argmax(axis=1), y_valid.argmax(axis=1)).mean()\n",
        "                if valid_accuracy > best_result:\n",
        "                    best_result = valid_accuracy\n",
        "                    best_beta = beta\n",
        "            valid_accuracy = best_result\n",
        "            test_probs = common_test_probs + best_beta * target_test_probs\n",
        "            test_accuracy = np.equal(test_probs.argmax(axis=1), y_test.argmax(axis=1)).mean()\n",
        "            print('valid accuracy:', valid_accuracy)\n",
        "            print(\"test accuracy:\", test_accuracy)\n",
        "            return valid_accuracy, test_accuracy\n",
        "\n",
        "    def train(self, x_s_u, x_t_u, x_s, y_s, x_t, y_t, x_valid, y_valid, x_test, y_test):\n",
        "        U = np.copy(x_t_u)\n",
        "        select_num = 5\n",
        "        best_result = 0.\n",
        "        final_test_accuracy = 0.\n",
        "        wait_times = 0.\n",
        "        while len(U) > 0:\n",
        "            print('Train common model...')\n",
        "            self.train_common_model(x_s_u, x_t_u, np.concatenate([x_s, x_t]), np.concatenate([y_s, y_t]),\n",
        "                                    x_valid, y_valid, x_test, y_test)\n",
        "            # input = raw_input('Input andy character!')\n",
        "            print('Train target model...')\n",
        "            self.train_target_model(x_s_u, x_t_u, x_t, y_t, x_valid, y_valid, x_test, y_test)\n",
        "            # input = raw_input('Input andy character!')\n",
        "            # Select U from common view\n",
        "            probs = [self.get_common_prediction(U), self.get_target_prediction(U)]\n",
        "            x_hat, y_hat, U = self.select_sample(U, probs, select_num=select_num)\n",
        "            x_t = np.concatenate([x_t, x_hat], axis=0)\n",
        "            y_t = np.concatenate([y_t, y_hat], axis=0)\n",
        "            print('Train combined model...')\n",
        "            valid_accuracy, test_accuracy = self.train_combined_model(x_t, y_t, x_valid, y_valid, x_test, y_test)\n",
        "            # input = raw_input('Input andy character!')\n",
        "            if valid_accuracy > best_result:\n",
        "                best_result = valid_accuracy\n",
        "                final_test_accuracy = test_accuracy\n",
        "                wait_times = 0\n",
        "            else:\n",
        "                wait_times += 1\n",
        "            if wait_times >= self.tolerate_time:\n",
        "                print('best_result:{0}'.format(best_result))\n",
        "                break\n",
        "        print('Test accuracy:{0}'.format(final_test_accuracy))\n",
        "\n",
        "    def select_sample(self, U, probs, select_num):\n",
        "        neg_idxes = set()\n",
        "        pos_idxes = set()\n",
        "        left_idxes = set(range(len(U)))\n",
        "        for prob in probs:\n",
        "            idxes = np.argsort(prob[:, 0])\n",
        "            end_idx = min(select_num, (prob[:, 0][idxes[:select_num]] < 0.5).sum())\n",
        "            begin_idx = min(select_num, (prob[:, 0][idxes[-select_num:]] > 0.5).sum())\n",
        "            idx = min(begin_idx, end_idx)\n",
        "            if idx == 0:\n",
        "                idx = 1\n",
        "            begin_idx = idx\n",
        "            end_idx = idx\n",
        "            neg_idxes.update(idxes[:end_idx])\n",
        "            pos_idxes.update(idxes[-begin_idx:])\n",
        "            print('pos num:', len(pos_idxes))\n",
        "            print('neg num:', len(neg_idxes))\n",
        "            left_idxes = left_idxes.intersection(idxes[end_idx:-begin_idx])\n",
        "\n",
        "        pos_idxes = np.array(list(pos_idxes))\n",
        "        neg_idxes = np.array(list(neg_idxes))\n",
        "        left_idxes = np.array(list(left_idxes))\n",
        "        x_n = U[neg_idxes]\n",
        "        x_p = U[pos_idxes]\n",
        "        y_n = np.zeros(shape=(len(x_n), 2), dtype='float32')\n",
        "        y_n[:, 1] = 1.\n",
        "        y_p = np.zeros(shape=(len(x_p), 2), dtype='float32')\n",
        "        y_p[:, 0] = 1.\n",
        "        U = U[left_idxes]\n",
        "        x = np.concatenate([x_n, x_p], axis=0)\n",
        "        y = np.concatenate([y_n, y_p], axis=0)\n",
        "        x, y = shuffle3([x, y])\n",
        "        print('unlabelled num:', len(U))\n",
        "        print(len(left_idxes))\n",
        "        return x, y, U\n",
        "\n",
        "    def get_common_prediction(self, X):\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, self.common_model_save_to)\n",
        "            probs, = self.sess.run([self.prob_s], feed_dict={self.X_s: X})\n",
        "        return probs\n",
        "\n",
        "    def get_target_prediction(self, X):\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        tfConfig = tf.compat.v1.ConfigProto()\n",
        "        tfConfig.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph, config=tfConfig)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, self.target_model_save_to)\n",
        "            probs, = self.sess.run([self.prob_t], feed_dict={self.X_t: X})\n",
        "        return probs\n",
        "\n",
        "    def analysis(self, x_t_train, y_t_train):\n",
        "        self.graph = tf.compat.v1.Graph()\n",
        "        self.sess = tf.compat.v1.Session(graph=self.graph)\n",
        "        with self.graph.as_default():\n",
        "            self.build_model()\n",
        "            saver = tf.compat.v1.train.Saver(var_list=self.theta)\n",
        "            self.sess.run(tf.compat.v1.global_variables_initializer())\n",
        "            saver.restore(self.sess, '/content/drive/My Drive/output/combined.pkl')\n",
        "            H_t, = self.sess.run([self.encoding_t_t],\n",
        "                                 feed_dict={self.X_t: x_t_train})\n",
        "        pca = PCA(n_components=2)\n",
        "        H_t_hat = pca.fit_transform(H_t)\n",
        "        plt.scatter(H_t_hat[:, 0][y_t_train[:, 0] == 0.], H_t_hat[:, 1][y_t_train[:, 0] == 0.], color='r', alpha=.4,\n",
        "                    s=1)\n",
        "        plt.scatter(H_t_hat[:, 0][y_t_train[:, 0] == 1.], H_t_hat[:, 1][y_t_train[:, 0] == 1.], color='b', alpha=.4,\n",
        "                    s=1)\n",
        "        plt.savefig(\"h_t.pdf\", dpi=72)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "    tf.debugging.set_log_device_placement(True)\n",
        "\n",
        "    data_load_from = '/content/drive/My Drive/amazon.mat'\n",
        "    import sys\n",
        "    source_domain = 0\n",
        "    target_domain = 1\n",
        "    x, y, offset = load_amazon(5000, data_load_from)\n",
        "    x_s_tr, y_s_tr, x_t_tr, y_t_tr, x_s_tst, y_s_tst, x_t_tst, y_t_tst = split_data(source_domain,\n",
        "                                                                                    target_domain,\n",
        "                                                                                    x, y, offset, 2000)\n",
        "    x = turn_tfidf(np.concatenate([x_s_tr, x_s_tst, x_t_tr, x_t_tst], axis=0))\n",
        "    x_s = x[:len(x_s_tr) + len(x_s_tst)]\n",
        "    x_t = x[len(x_s):]\n",
        "\n",
        "    x_s_tr = np.copy(x_s[:len(x_s_tr)])\n",
        "    x_s_tst = np.copy(x_s[len(x_s_tr):])\n",
        "\n",
        "    x_t_tr = np.copy(x_t[:len(x_t_tr)])\n",
        "    x_t_tst = np.copy(x_t[len(x_t_tr):])\n",
        "\n",
        "    x_t_tune = np.copy(x_t_tst[:5])\n",
        "    y_t_tune = np.copy(y_t_tst[:5])\n",
        "    x_t_tst = x_t_tst[50:]\n",
        "    y_t_tst = y_t_tst[50:]\n",
        "\n",
        "    x_t_valid = x_t_tst[:500]\n",
        "    y_t_valid = y_t_tst[:500]\n",
        "    x_t_tst = x_t_tst[500:]\n",
        "    y_t_tst = y_t_tst[500:]\n",
        "\n",
        "    trainer = CoTrainer(source_domain, target_domain)\n",
        "    trainer.recon = 1.\n",
        "    results = []\n",
        "    results.append(trainer.train(x_s_tr, x_t_tr, np.copy(x_s_tr), y_s_tr, x_t_tune, y_t_tune, x_t_valid, y_t_valid, x_t_tst, y_t_tst))\n",
        "    print('Result from {0} domain to {1} domain:{2}'.format(source_domain, target_domain, results[-1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "c_loss:0.7139719128608704\n",
            "cmd_c_loss:0.08423875272274017\n",
            "cmd_t_loss:0.1395254284143448\n",
            "r_loss:0.7842882871627808\n",
            "accuracy_s:0.4996156692504883\n",
            "c_loss:0.7121888995170593\n",
            "cmd_c_loss:0.08058144152164459\n",
            "cmd_t_loss:0.14309927821159363\n",
            "r_loss:0.7801036238670349\n",
            "accuracy_s:0.49730977416038513\n",
            "c_loss:0.7104577422142029\n",
            "cmd_c_loss:0.07672955095767975\n",
            "cmd_t_loss:0.14686743915081024\n",
            "r_loss:0.7757306098937988\n",
            "accuracy_s:0.4969254434108734\n",
            "c_loss:0.7087796330451965\n",
            "cmd_c_loss:0.07267287373542786\n",
            "cmd_t_loss:0.15084055066108704\n",
            "r_loss:0.7711631059646606\n",
            "accuracy_s:0.4996156692504883\n",
            "c_loss:0.7071545124053955\n",
            "cmd_c_loss:0.06840112060308456\n",
            "cmd_t_loss:0.15502969920635223\n",
            "r_loss:0.7663944959640503\n",
            "accuracy_s:0.4996156692504883\n",
            "c_loss:0.7055819630622864\n",
            "cmd_c_loss:0.06390306353569031\n",
            "cmd_t_loss:0.1594468206167221\n",
            "r_loss:0.7614185810089111\n",
            "accuracy_s:0.503074586391449\n",
            "c_loss:0.7040599584579468\n",
            "cmd_c_loss:0.05916721746325493\n",
            "cmd_t_loss:0.16410422325134277\n",
            "r_loss:0.7562291026115417\n",
            "accuracy_s:0.5019215941429138\n",
            "c_loss:0.7025858759880066\n",
            "cmd_c_loss:0.054181717336177826\n",
            "cmd_t_loss:0.16901394724845886\n",
            "r_loss:0.7508198022842407\n",
            "accuracy_s:0.4996156692504883\n",
            "c_loss:0.7011561393737793\n",
            "cmd_c_loss:0.04893413931131363\n",
            "cmd_t_loss:0.1741907149553299\n",
            "r_loss:0.7451848983764648\n",
            "accuracy_s:0.4984627068042755\n",
            "c_loss:0.6997664570808411\n",
            "cmd_c_loss:0.04341167211532593\n",
            "cmd_t_loss:0.17964830994606018\n",
            "r_loss:0.7393187284469604\n",
            "accuracy_s:0.49730977416038513\n",
            "c_loss:0.6984114646911621\n",
            "cmd_c_loss:0.03760145232081413\n",
            "cmd_t_loss:0.18540167808532715\n",
            "r_loss:0.7332159876823425\n",
            "accuracy_s:0.5\n",
            "c_loss:0.6970853805541992\n",
            "cmd_c_loss:0.03149000182747841\n",
            "cmd_t_loss:0.19146762788295746\n",
            "r_loss:0.7268718481063843\n",
            "accuracy_s:0.4980784058570862\n",
            "c_loss:0.6957820653915405\n",
            "cmd_c_loss:0.02506471425294876\n",
            "cmd_t_loss:0.1978621482849121\n",
            "r_loss:0.7202823162078857\n",
            "accuracy_s:0.5023059248924255\n",
            "c_loss:0.694494903087616\n",
            "cmd_c_loss:0.018315186724066734\n",
            "cmd_t_loss:0.20460407435894012\n",
            "r_loss:0.71344393491745\n",
            "accuracy_s:0.511145293712616\n",
            "c_loss:0.6932182312011719\n",
            "cmd_c_loss:0.011240105144679546\n",
            "cmd_t_loss:0.2117110788822174\n",
            "r_loss:0.7063562870025635\n",
            "accuracy_s:0.5142198204994202\n",
            "c_loss:0.6919506192207336\n",
            "cmd_c_loss:0.006783138960599899\n",
            "cmd_t_loss:0.21920262277126312\n",
            "r_loss:0.6990278363227844\n",
            "accuracy_s:0.5219061970710754\n",
            "c_loss:0.6907360553741455\n",
            "cmd_c_loss:0.011566459201276302\n",
            "cmd_t_loss:0.22709864377975464\n",
            "r_loss:0.6913896203041077\n",
            "accuracy_s:0.5257494449615479\n",
            "c_loss:0.6894003748893738\n",
            "cmd_c_loss:0.007260869722813368\n",
            "cmd_t_loss:0.23542051017284393\n",
            "r_loss:0.683457612991333\n",
            "accuracy_s:0.5322828888893127\n",
            "c_loss:0.6881685256958008\n",
            "cmd_c_loss:0.011720431968569756\n",
            "cmd_t_loss:0.24419084191322327\n",
            "r_loss:0.6753329038619995\n",
            "accuracy_s:0.5357417464256287\n",
            "c_loss:0.6867445707321167\n",
            "cmd_c_loss:0.00795217789709568\n",
            "cmd_t_loss:0.2534315586090088\n",
            "r_loss:0.6667940020561218\n",
            "accuracy_s:0.5434281229972839\n",
            "c_loss:0.6854601502418518\n",
            "cmd_c_loss:0.011746509000658989\n",
            "cmd_t_loss:0.2631675899028778\n",
            "r_loss:0.6581666469573975\n",
            "accuracy_s:0.5453497171401978\n",
            "c_loss:0.6839303970336914\n",
            "cmd_c_loss:0.00882010255008936\n",
            "cmd_t_loss:0.27342116832733154\n",
            "r_loss:0.6490322351455688\n",
            "accuracy_s:0.5522674918174744\n",
            "c_loss:0.682563304901123\n",
            "cmd_c_loss:0.011691818945109844\n",
            "cmd_t_loss:0.28422245383262634\n",
            "r_loss:0.6398940086364746\n",
            "accuracy_s:0.5588009357452393\n",
            "c_loss:0.6809098720550537\n",
            "cmd_c_loss:0.009835113771259785\n",
            "cmd_t_loss:0.29559698700904846\n",
            "r_loss:0.6301843523979187\n",
            "accuracy_s:0.5607225298881531\n",
            "c_loss:0.6794357299804688\n",
            "cmd_c_loss:0.011594145558774471\n",
            "cmd_t_loss:0.3075707256793976\n",
            "r_loss:0.6205378770828247\n",
            "accuracy_s:0.5680245757102966\n",
            "c_loss:0.6776418685913086\n",
            "cmd_c_loss:0.010975608602166176\n",
            "cmd_t_loss:0.3201734125614166\n",
            "r_loss:0.6102796792984009\n",
            "accuracy_s:0.5730207562446594\n",
            "c_loss:0.6760404706001282\n",
            "cmd_c_loss:0.011484391987323761\n",
            "cmd_t_loss:0.33343300223350525\n",
            "r_loss:0.6001385450363159\n",
            "accuracy_s:0.5853189826011658\n",
            "c_loss:0.6740913391113281\n",
            "cmd_c_loss:0.012223884463310242\n",
            "cmd_t_loss:0.347380667924881\n",
            "r_loss:0.5893684029579163\n",
            "accuracy_s:0.5926210880279541\n",
            "c_loss:0.6723451614379883\n",
            "cmd_c_loss:0.011391369625926018\n",
            "cmd_t_loss:0.36204665899276733\n",
            "r_loss:0.578758180141449\n",
            "accuracy_s:0.6014603972434998\n",
            "c_loss:0.6702277660369873\n",
            "cmd_c_loss:0.013564062304794788\n",
            "cmd_t_loss:0.377458393573761\n",
            "r_loss:0.5675246715545654\n",
            "accuracy_s:0.6076095104217529\n",
            "c_loss:0.6683210730552673\n",
            "cmd_c_loss:0.011343569494783878\n",
            "cmd_t_loss:0.39365071058273315\n",
            "r_loss:0.5564842224121094\n",
            "accuracy_s:0.615295946598053\n",
            "c_loss:0.6660237312316895\n",
            "cmd_c_loss:0.01498041395097971\n",
            "cmd_t_loss:0.4106524586677551\n",
            "r_loss:0.5448483228683472\n",
            "accuracy_s:0.6191391348838806\n",
            "c_loss:0.6639413237571716\n",
            "cmd_c_loss:0.011371200904250145\n",
            "cmd_t_loss:0.4284915030002594\n",
            "r_loss:0.5334281921386719\n",
            "accuracy_s:0.6268255114555359\n",
            "c_loss:0.661453127861023\n",
            "cmd_c_loss:0.016457632184028625\n",
            "cmd_t_loss:0.4472027122974396\n",
            "r_loss:0.521462082862854\n",
            "accuracy_s:0.6372021436691284\n",
            "c_loss:0.6591792106628418\n",
            "cmd_c_loss:0.011505931615829468\n",
            "cmd_t_loss:0.46681883931159973\n",
            "r_loss:0.5097262263298035\n",
            "accuracy_s:0.6452728509902954\n",
            "c_loss:0.6564900875091553\n",
            "cmd_c_loss:0.017978837713599205\n",
            "cmd_t_loss:0.48736807703971863\n",
            "r_loss:0.4975152015686035\n",
            "accuracy_s:0.6518062949180603\n",
            "c_loss:0.6540082097053528\n",
            "cmd_c_loss:0.01178194023668766\n",
            "cmd_t_loss:0.5088812112808228\n",
            "r_loss:0.48553675413131714\n",
            "accuracy_s:0.6625672578811646\n",
            "c_loss:0.6511077880859375\n",
            "cmd_c_loss:0.01953033357858658\n",
            "cmd_t_loss:0.5313868522644043\n",
            "r_loss:0.47317254543304443\n",
            "accuracy_s:0.6687163710594177\n",
            "c_loss:0.6483999490737915\n",
            "cmd_c_loss:0.012231606990098953\n",
            "cmd_t_loss:0.5549141764640808\n",
            "r_loss:0.4610370099544525\n",
            "accuracy_s:0.676018476486206\n",
            "c_loss:0.6452775597572327\n",
            "cmd_c_loss:0.02110043168067932\n",
            "cmd_t_loss:0.5794939398765564\n",
            "r_loss:0.4486202001571655\n",
            "accuracy_s:0.68447345495224\n",
            "c_loss:0.642323911190033\n",
            "cmd_c_loss:0.012886598706245422\n",
            "cmd_t_loss:0.6051560640335083\n",
            "r_loss:0.4364234507083893\n",
            "accuracy_s:0.6967717409133911\n",
            "c_loss:0.6389679312705994\n",
            "cmd_c_loss:0.02268161252140999\n",
            "cmd_t_loss:0.6319283843040466\n",
            "r_loss:0.4240565896034241\n",
            "accuracy_s:0.7048424482345581\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.642\n",
            "c_loss:0.6357476115226746\n",
            "cmd_c_loss:0.013778839260339737\n",
            "cmd_t_loss:0.6598396897315979\n",
            "r_loss:0.4118993282318115\n",
            "accuracy_s:0.716372013092041\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.644\n",
            "c_loss:0.6321463584899902\n",
            "cmd_c_loss:0.02427191473543644\n",
            "cmd_t_loss:0.6889168620109558\n",
            "r_loss:0.39968419075012207\n",
            "accuracy_s:0.7232897877693176\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.654\n",
            "c_loss:0.6286356449127197\n",
            "cmd_c_loss:0.014942090027034283\n",
            "cmd_t_loss:0.7191896438598633\n",
            "r_loss:0.3876734673976898\n",
            "accuracy_s:0.7290545701980591\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.66\n",
            "c_loss:0.6247758269309998\n",
            "cmd_c_loss:0.025879541411995888\n",
            "cmd_t_loss:0.7506740689277649\n",
            "r_loss:0.3757123053073883\n",
            "accuracy_s:0.7352036833763123\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.666\n",
            "c_loss:0.6209501624107361\n",
            "cmd_c_loss:0.016412915661931038\n",
            "cmd_t_loss:0.7833946347236633\n",
            "r_loss:0.3639542758464813\n",
            "accuracy_s:0.7425057888031006\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.672\n",
            "c_loss:0.6168156862258911\n",
            "cmd_c_loss:0.02752932533621788\n",
            "cmd_t_loss:0.8173695802688599\n",
            "r_loss:0.3523379862308502\n",
            "accuracy_s:0.7494235038757324\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.68\n",
            "c_loss:0.6126486659049988\n",
            "cmd_c_loss:0.018238402903079987\n",
            "cmd_t_loss:0.8526197671890259\n",
            "r_loss:0.34092977643013\n",
            "accuracy_s:0.7582628726959229\n",
            "valid accuracy: 0.678\n",
            "c_loss:0.6082196235656738\n",
            "cmd_c_loss:0.029303962364792824\n",
            "cmd_t_loss:0.8891475200653076\n",
            "r_loss:0.3297416567802429\n",
            "accuracy_s:0.7663335800170898\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.69\n",
            "c_loss:0.6036829948425293\n",
            "cmd_c_loss:0.02048170007765293\n",
            "cmd_t_loss:0.9269644618034363\n",
            "r_loss:0.31877294182777405\n",
            "accuracy_s:0.7744042873382568\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.696\n",
            "c_loss:0.5989301800727844\n",
            "cmd_c_loss:0.03140558302402496\n",
            "cmd_t_loss:0.9660705924034119\n",
            "r_loss:0.3080822229385376\n",
            "accuracy_s:0.7774788737297058\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.7\n",
            "c_loss:0.5939909815788269\n",
            "cmd_c_loss:0.023116301745176315\n",
            "cmd_t_loss:1.0064748525619507\n",
            "r_loss:0.2976275682449341\n",
            "accuracy_s:0.7828593254089355\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.704\n",
            "c_loss:0.5888766646385193\n",
            "cmd_c_loss:0.033886972814798355\n",
            "cmd_t_loss:1.0481805801391602\n",
            "r_loss:0.28749150037765503\n",
            "accuracy_s:0.7855495810508728\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.71\n",
            "c_loss:0.5835025906562805\n",
            "cmd_c_loss:0.02596331015229225\n",
            "cmd_t_loss:1.0912036895751953\n",
            "r_loss:0.2776172459125519\n",
            "accuracy_s:0.7959262132644653\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.712\n",
            "c_loss:0.5779974460601807\n",
            "cmd_c_loss:0.03660424426198006\n",
            "cmd_t_loss:1.135524868965149\n",
            "r_loss:0.2680916488170624\n",
            "accuracy_s:0.8013066649436951\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.72\n",
            "c_loss:0.5721617937088013\n",
            "cmd_c_loss:0.029077822342514992\n",
            "cmd_t_loss:1.1811439990997314\n",
            "r_loss:0.258852481842041\n",
            "accuracy_s:0.8059185147285461\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.724\n",
            "c_loss:0.5662387013435364\n",
            "cmd_c_loss:0.03950624540448189\n",
            "cmd_t_loss:1.2280430793762207\n",
            "r_loss:0.24998252093791962\n",
            "accuracy_s:0.8116832971572876\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.728\n",
            "c_loss:0.5599126219749451\n",
            "cmd_c_loss:0.03246837854385376\n",
            "cmd_t_loss:1.2762231826782227\n",
            "r_loss:0.24142369627952576\n",
            "accuracy_s:0.8170638084411621\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.73\n",
            "c_loss:0.5535452961921692\n",
            "cmd_c_loss:0.04252307862043381\n",
            "cmd_t_loss:1.3256721496582031\n",
            "r_loss:0.23324894905090332\n",
            "accuracy_s:0.8255188465118408\n",
            "valid accuracy: 0.728\n",
            "c_loss:0.5467016100883484\n",
            "cmd_c_loss:0.03609774261713028\n",
            "cmd_t_loss:1.3763717412948608\n",
            "r_loss:0.22540442645549774\n",
            "accuracy_s:0.8282090425491333\n",
            "valid accuracy: 0.726\n",
            "c_loss:0.5398614406585693\n",
            "cmd_c_loss:0.04565143957734108\n",
            "cmd_t_loss:1.4283207654953003\n",
            "r_loss:0.21795126795768738\n",
            "accuracy_s:0.8339738845825195\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.736\n",
            "c_loss:0.5324870944023132\n",
            "cmd_c_loss:0.04000040888786316\n",
            "cmd_t_loss:1.4815170764923096\n",
            "r_loss:0.21084320545196533\n",
            "accuracy_s:0.8385856747627258\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.738\n",
            "c_loss:0.5251463651657104\n",
            "cmd_c_loss:0.04902377352118492\n",
            "cmd_t_loss:1.5359227657318115\n",
            "r_loss:0.20413117110729218\n",
            "accuracy_s:0.8431975245475769\n",
            "valid accuracy: 0.738\n",
            "c_loss:0.5172472596168518\n",
            "cmd_c_loss:0.04429472237825394\n",
            "cmd_t_loss:1.5915372371673584\n",
            "r_loss:0.19777384400367737\n",
            "accuracy_s:0.8466564416885376\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.742\n",
            "c_loss:0.5093832612037659\n",
            "cmd_c_loss:0.05283430218696594\n",
            "cmd_t_loss:1.6483616828918457\n",
            "r_loss:0.19181224703788757\n",
            "accuracy_s:0.8528055548667908\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.746\n",
            "c_loss:0.5009865164756775\n",
            "cmd_c_loss:0.0490599162876606\n",
            "cmd_t_loss:1.7063584327697754\n",
            "r_loss:0.18620936572551727\n",
            "accuracy_s:0.855880081653595\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.75\n",
            "c_loss:0.4925893545150757\n",
            "cmd_c_loss:0.05709606781601906\n",
            "cmd_t_loss:1.765519618988037\n",
            "r_loss:0.18099455535411835\n",
            "accuracy_s:0.8666410446166992\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.752\n",
            "c_loss:0.48373639583587646\n",
            "cmd_c_loss:0.05402364209294319\n",
            "cmd_t_loss:1.8258280754089355\n",
            "r_loss:0.17613708972930908\n",
            "accuracy_s:0.868562638759613\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.762\n",
            "c_loss:0.4748273491859436\n",
            "cmd_c_loss:0.06137928366661072\n",
            "cmd_t_loss:1.8872476816177368\n",
            "r_loss:0.17165407538414001\n",
            "accuracy_s:0.8747117519378662\n",
            "valid accuracy: 0.762\n",
            "c_loss:0.46557241678237915\n",
            "cmd_c_loss:0.05894644558429718\n",
            "cmd_t_loss:1.949769377708435\n",
            "r_loss:0.16751785576343536\n",
            "accuracy_s:0.8762490153312683\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.766\n",
            "c_loss:0.45620986819267273\n",
            "cmd_c_loss:0.06602079421281815\n",
            "cmd_t_loss:2.013387680053711\n",
            "r_loss:0.16372697055339813\n",
            "accuracy_s:0.8843197822570801\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.768\n",
            "c_loss:0.4466022253036499\n",
            "cmd_c_loss:0.06461147218942642\n",
            "cmd_t_loss:2.0780556201934814\n",
            "r_loss:0.16027045249938965\n",
            "accuracy_s:0.8850883841514587\n",
            "valid accuracy: 0.764\n",
            "c_loss:0.4368813931941986\n",
            "cmd_c_loss:0.07177726179361343\n",
            "cmd_t_loss:2.143735647201538\n",
            "r_loss:0.1571168452501297\n",
            "accuracy_s:0.8920061588287354\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.77\n",
            "c_loss:0.4269745945930481\n",
            "cmd_c_loss:0.07094204425811768\n",
            "cmd_t_loss:2.2103676795959473\n",
            "r_loss:0.15427890419960022\n",
            "accuracy_s:0.8923904895782471\n",
            "valid accuracy: 0.768\n",
            "c_loss:0.4170273244380951\n",
            "cmd_c_loss:0.07771014422178268\n",
            "cmd_t_loss:2.2779083251953125\n",
            "r_loss:0.15169194340705872\n",
            "accuracy_s:0.8996925354003906\n",
            "valid accuracy: 0.768\n",
            "c_loss:0.406881183385849\n",
            "cmd_c_loss:0.07682714611291885\n",
            "cmd_t_loss:2.346299886703491\n",
            "r_loss:0.14939889311790466\n",
            "accuracy_s:0.898923933506012\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.778\n",
            "c_loss:0.39689141511917114\n",
            "cmd_c_loss:0.08324791491031647\n",
            "cmd_t_loss:2.4154481887817383\n",
            "r_loss:0.1472993940114975\n",
            "accuracy_s:0.9081475734710693\n",
            "valid accuracy: 0.768\n",
            "c_loss:0.3866350054740906\n",
            "cmd_c_loss:0.0828590914607048\n",
            "cmd_t_loss:2.485276699066162\n",
            "r_loss:0.14546386897563934\n",
            "accuracy_s:0.90392005443573\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.788\n",
            "c_loss:0.37702450156211853\n",
            "cmd_c_loss:0.08904390782117844\n",
            "cmd_t_loss:2.555708646774292\n",
            "r_loss:0.1437722146511078\n",
            "accuracy_s:0.9131437540054321\n",
            "valid accuracy: 0.768\n",
            "c_loss:0.36730632185935974\n",
            "cmd_c_loss:0.0897950828075409\n",
            "cmd_t_loss:2.6266355514526367\n",
            "r_loss:0.1423044502735138\n",
            "accuracy_s:0.9027671217918396\n",
            "valid accuracy: 0.788\n",
            "c_loss:0.35979244112968445\n",
            "cmd_c_loss:0.09525737911462784\n",
            "cmd_t_loss:2.6979546546936035\n",
            "r_loss:0.1409587860107422\n",
            "accuracy_s:0.9212144613265991\n",
            "valid accuracy: 0.756\n",
            "c_loss:0.35329410433769226\n",
            "cmd_c_loss:0.09792991727590561\n",
            "cmd_t_loss:2.769543409347534\n",
            "r_loss:0.13976243138313293\n",
            "accuracy_s:0.8916218280792236\n",
            "valid accuracy: 0.782\n",
            "c_loss:0.35078051686286926\n",
            "cmd_c_loss:0.1015544980764389\n",
            "cmd_t_loss:2.8413267135620117\n",
            "r_loss:0.13873428106307983\n",
            "accuracy_s:0.9093005657196045\n",
            "valid accuracy: 0.748\n",
            "c_loss:0.34582921862602234\n",
            "cmd_c_loss:0.1071966215968132\n",
            "cmd_t_loss:2.9131438732147217\n",
            "r_loss:0.13773272931575775\n",
            "accuracy_s:0.8785549402236938\n",
            "valid accuracy: 0.788\n",
            "c_loss:0.3429107666015625\n",
            "cmd_c_loss:0.1072409525513649\n",
            "cmd_t_loss:2.984884738922119\n",
            "r_loss:0.13695764541625977\n",
            "accuracy_s:0.9004611968994141\n",
            "valid accuracy: 0.746\n",
            "c_loss:0.3331364095211029\n",
            "cmd_c_loss:0.11802831292152405\n",
            "cmd_t_loss:3.0564262866973877\n",
            "r_loss:0.13610871136188507\n",
            "accuracy_s:0.8793236017227173\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.792\n",
            "c_loss:0.32895320653915405\n",
            "cmd_c_loss:0.11189857125282288\n",
            "cmd_t_loss:3.127624988555908\n",
            "r_loss:0.1354808360338211\n",
            "accuracy_s:0.9031513929367065\n",
            "valid accuracy: 0.754\n",
            "c_loss:0.31684452295303345\n",
            "cmd_c_loss:0.12855367362499237\n",
            "cmd_t_loss:3.1983327865600586\n",
            "r_loss:0.1347886025905609\n",
            "accuracy_s:0.8885472416877747\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.8\n",
            "c_loss:0.3131542205810547\n",
            "cmd_c_loss:0.1160610169172287\n",
            "cmd_t_loss:3.2684805393218994\n",
            "r_loss:0.1342540681362152\n",
            "accuracy_s:0.9100691676139832\n",
            "valid accuracy: 0.752\n",
            "c_loss:0.3006957769393921\n",
            "cmd_c_loss:0.1392696350812912\n",
            "cmd_t_loss:3.3378896713256836\n",
            "r_loss:0.13371124863624573\n",
            "accuracy_s:0.8943120837211609\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.806\n",
            "c_loss:0.29742008447647095\n",
            "cmd_c_loss:0.12107189744710922\n",
            "cmd_t_loss:3.406449794769287\n",
            "r_loss:0.13323405385017395\n",
            "accuracy_s:0.9162182807922363\n",
            "valid accuracy: 0.758\n",
            "c_loss:0.2852528393268585\n",
            "cmd_c_loss:0.15025503933429718\n",
            "cmd_t_loss:3.4740443229675293\n",
            "r_loss:0.13282915949821472\n",
            "accuracy_s:0.9046887159347534\n",
            "valid accuracy: 0.804\n",
            "c_loss:0.28215086460113525\n",
            "cmd_c_loss:0.1268881857395172\n",
            "cmd_t_loss:3.5405921936035156\n",
            "r_loss:0.13238662481307983\n",
            "accuracy_s:0.9242889881134033\n",
            "valid accuracy: 0.764\n",
            "c_loss:0.2704280614852905\n",
            "cmd_c_loss:0.1602998971939087\n",
            "cmd_t_loss:3.605945110321045\n",
            "r_loss:0.13210585713386536\n",
            "accuracy_s:0.9139123558998108\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.81\n",
            "c_loss:0.2678230404853821\n",
            "cmd_c_loss:0.13197441399097443\n",
            "cmd_t_loss:3.670118570327759\n",
            "r_loss:0.13169176876544952\n",
            "accuracy_s:0.9319754242897034\n",
            "valid accuracy: 0.764\n",
            "c_loss:0.2569783926010132\n",
            "cmd_c_loss:0.17037321627140045\n",
            "cmd_t_loss:3.7330453395843506\n",
            "r_loss:0.13150618970394135\n",
            "accuracy_s:0.9215987920761108\n",
            "valid accuracy: 0.806\n",
            "c_loss:0.2550550699234009\n",
            "cmd_c_loss:0.13749746978282928\n",
            "cmd_t_loss:3.7946298122406006\n",
            "r_loss:0.1311376541852951\n",
            "accuracy_s:0.9354342818260193\n",
            "valid accuracy: 0.768\n",
            "c_loss:0.24557068943977356\n",
            "cmd_c_loss:0.1791125386953354\n",
            "cmd_t_loss:3.8547847270965576\n",
            "r_loss:0.13100194931030273\n",
            "accuracy_s:0.9239047169685364\n",
            "valid accuracy: 0.806\n",
            "c_loss:0.24433022737503052\n",
            "cmd_c_loss:0.14286042749881744\n",
            "cmd_t_loss:3.9135313034057617\n",
            "r_loss:0.13070857524871826\n",
            "accuracy_s:0.9369715452194214\n",
            "valid accuracy: 0.772\n",
            "c_loss:0.2357889860868454\n",
            "cmd_c_loss:0.19053734838962555\n",
            "cmd_t_loss:3.9708399772644043\n",
            "r_loss:0.13059855997562408\n",
            "accuracy_s:0.9285165071487427\n",
            "valid accuracy: 0.806\n",
            "c_loss:0.23526862263679504\n",
            "cmd_c_loss:0.14605601131916046\n",
            "cmd_t_loss:4.026621341705322\n",
            "r_loss:0.13037481904029846\n",
            "accuracy_s:0.9385088682174683\n",
            "valid accuracy: 0.774\n",
            "c_loss:0.22702090442180634\n",
            "cmd_c_loss:0.19379211962223053\n",
            "cmd_t_loss:4.0809807777404785\n",
            "r_loss:0.13026684522628784\n",
            "accuracy_s:0.9312067627906799\n",
            "valid accuracy: 0.804\n",
            "c_loss:0.2268287092447281\n",
            "cmd_c_loss:0.14533576369285583\n",
            "cmd_t_loss:4.1339850425720215\n",
            "r_loss:0.13012346625328064\n",
            "accuracy_s:0.940814733505249\n",
            "valid accuracy: 0.78\n",
            "c_loss:0.21842160820960999\n",
            "cmd_c_loss:0.20188269019126892\n",
            "cmd_t_loss:4.185449123382568\n",
            "r_loss:0.1300206035375595\n",
            "accuracy_s:0.932744026184082\n",
            "valid accuracy: 0.804\n",
            "c_loss:0.21842700242996216\n",
            "cmd_c_loss:0.1489851325750351\n",
            "cmd_t_loss:4.235495090484619\n",
            "r_loss:0.1298665553331375\n",
            "accuracy_s:0.9431206583976746\n",
            "valid accuracy: 0.788\n",
            "c_loss:0.20841684937477112\n",
            "cmd_c_loss:0.20628303289413452\n",
            "cmd_t_loss:4.284091949462891\n",
            "r_loss:0.12981338798999786\n",
            "accuracy_s:0.9373558759689331\n",
            "valid accuracy: 0.81\n",
            "c_loss:0.20702341198921204\n",
            "cmd_c_loss:0.14956143498420715\n",
            "cmd_t_loss:4.331150531768799\n",
            "r_loss:0.12961885333061218\n",
            "accuracy_s:0.9465795755386353\n",
            "valid accuracy: 0.79\n",
            "c_loss:0.1950780600309372\n",
            "cmd_c_loss:0.20841263234615326\n",
            "cmd_t_loss:4.376862525939941\n",
            "r_loss:0.1296023279428482\n",
            "accuracy_s:0.9465795755386353\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.818\n",
            "c_loss:0.19172775745391846\n",
            "cmd_c_loss:0.1508370041847229\n",
            "cmd_t_loss:4.421189308166504\n",
            "r_loss:0.12938746809959412\n",
            "accuracy_s:0.9546502828598022\n",
            "valid accuracy: 0.788\n",
            "c_loss:0.17837977409362793\n",
            "cmd_c_loss:0.20909380912780762\n",
            "cmd_t_loss:4.464197158813477\n",
            "r_loss:0.12936712801456451\n",
            "accuracy_s:0.955034613609314\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.82\n",
            "c_loss:0.17430782318115234\n",
            "cmd_c_loss:0.15394245088100433\n",
            "cmd_t_loss:4.505880355834961\n",
            "r_loss:0.12912508845329285\n",
            "accuracy_s:0.9592621326446533\n",
            "valid accuracy: 0.796\n",
            "c_loss:0.16212736070156097\n",
            "cmd_c_loss:0.21153026819229126\n",
            "cmd_t_loss:4.5462117195129395\n",
            "r_loss:0.1290673315525055\n",
            "accuracy_s:0.9634896516799927\n",
            "valid accuracy: 0.818\n",
            "c_loss:0.15809287130832672\n",
            "cmd_c_loss:0.15659357607364655\n",
            "cmd_t_loss:4.585446357727051\n",
            "r_loss:0.12885107100009918\n",
            "accuracy_s:0.9700230360031128\n",
            "valid accuracy: 0.804\n",
            "c_loss:0.14896361529827118\n",
            "cmd_c_loss:0.21040502190589905\n",
            "cmd_t_loss:4.6232686042785645\n",
            "r_loss:0.1287766695022583\n",
            "accuracy_s:0.9715603590011597\n",
            "valid accuracy: 0.82\n",
            "c_loss:0.14567731320858002\n",
            "cmd_c_loss:0.1611766666173935\n",
            "cmd_t_loss:4.660268783569336\n",
            "r_loss:0.1285700500011444\n",
            "accuracy_s:0.976172149181366\n",
            "valid accuracy: 0.814\n",
            "c_loss:0.13848046958446503\n",
            "cmd_c_loss:0.21979539096355438\n",
            "cmd_t_loss:4.696142673492432\n",
            "r_loss:0.12852774560451508\n",
            "accuracy_s:0.9765564799308777\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.826\n",
            "c_loss:0.1345677524805069\n",
            "cmd_c_loss:0.1635163128376007\n",
            "cmd_t_loss:4.7310404777526855\n",
            "r_loss:0.12832745909690857\n",
            "accuracy_s:0.9846271872520447\n",
            "valid accuracy: 0.818\n",
            "c_loss:0.1295357346534729\n",
            "cmd_c_loss:0.2080562561750412\n",
            "cmd_t_loss:4.765148639678955\n",
            "r_loss:0.12836524844169617\n",
            "accuracy_s:0.9815526604652405\n",
            "valid accuracy: 0.82\n",
            "c_loss:0.12747961282730103\n",
            "cmd_c_loss:0.16998417675495148\n",
            "cmd_t_loss:4.798264026641846\n",
            "r_loss:0.12813830375671387\n",
            "accuracy_s:0.9869331121444702\n",
            "valid accuracy: 0.818\n",
            "c_loss:0.12389148026704788\n",
            "cmd_c_loss:0.220526322722435\n",
            "cmd_t_loss:4.830845832824707\n",
            "r_loss:0.1281074434518814\n",
            "accuracy_s:0.9834742546081543\n",
            "valid accuracy: 0.826\n",
            "c_loss:0.12715938687324524\n",
            "cmd_c_loss:0.16706740856170654\n",
            "cmd_t_loss:4.862660884857178\n",
            "r_loss:0.1278803050518036\n",
            "accuracy_s:0.9834742546081543\n",
            "valid accuracy: 0.816\n",
            "c_loss:0.12136062234640121\n",
            "cmd_c_loss:0.22645951807498932\n",
            "cmd_t_loss:4.8936944007873535\n",
            "r_loss:0.12781104445457458\n",
            "accuracy_s:0.9811683297157288\n",
            "valid accuracy: 0.822\n",
            "c_loss:0.13003210723400116\n",
            "cmd_c_loss:0.16685903072357178\n",
            "cmd_t_loss:4.924762725830078\n",
            "r_loss:0.1276293247938156\n",
            "accuracy_s:0.9777094721794128\n",
            "valid accuracy: 0.806\n",
            "c_loss:0.13210082054138184\n",
            "cmd_c_loss:0.2233065813779831\n",
            "cmd_t_loss:4.955033779144287\n",
            "r_loss:0.12753437459468842\n",
            "accuracy_s:0.9707916975021362\n",
            "valid accuracy: 0.8\n",
            "c_loss:0.15865877270698547\n",
            "cmd_c_loss:0.1655770093202591\n",
            "cmd_t_loss:4.985212802886963\n",
            "r_loss:0.12739650905132294\n",
            "accuracy_s:0.9523443579673767\n",
            "valid accuracy: 0.764\n",
            "c_loss:0.2028391808271408\n",
            "cmd_c_loss:0.21843348443508148\n",
            "cmd_t_loss:5.014703750610352\n",
            "r_loss:0.12754027545452118\n",
            "accuracy_s:0.920061469078064\n",
            "valid accuracy: 0.734\n",
            "c_loss:0.31364184617996216\n",
            "cmd_c_loss:0.14702244102954865\n",
            "cmd_t_loss:5.044126510620117\n",
            "r_loss:0.1275072544813156\n",
            "accuracy_s:0.8539584875106812\n",
            "valid accuracy: 0.716\n",
            "c_loss:0.34268078207969666\n",
            "cmd_c_loss:0.1926589012145996\n",
            "cmd_t_loss:5.0726423263549805\n",
            "r_loss:0.12787894904613495\n",
            "accuracy_s:0.8259031772613525\n",
            "valid accuracy: 0.734\n",
            "c_loss:0.24102935194969177\n",
            "cmd_c_loss:0.14216922223567963\n",
            "cmd_t_loss:5.1009416580200195\n",
            "r_loss:0.1277291178703308\n",
            "accuracy_s:0.8889315724372864\n",
            "valid accuracy: 0.78\n",
            "c_loss:0.10904112458229065\n",
            "cmd_c_loss:0.16297626495361328\n",
            "cmd_t_loss:5.128557205200195\n",
            "r_loss:0.1277594268321991\n",
            "accuracy_s:0.980783998966217\n",
            "valid accuracy: 0.826\n",
            "c_loss:0.08700220286846161\n",
            "cmd_c_loss:0.15191499888896942\n",
            "cmd_t_loss:5.155773639678955\n",
            "r_loss:0.1275036782026291\n",
            "accuracy_s:0.9934665560722351\n",
            "valid accuracy: 0.822\n",
            "c_loss:0.08525609225034714\n",
            "cmd_c_loss:0.17748183012008667\n",
            "cmd_t_loss:5.181239128112793\n",
            "r_loss:0.12752003967761993\n",
            "accuracy_s:0.9934665560722351\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.828\n",
            "c_loss:0.08205051720142365\n",
            "cmd_c_loss:0.16422101855278015\n",
            "cmd_t_loss:5.206109523773193\n",
            "r_loss:0.12744024395942688\n",
            "accuracy_s:0.9938508868217468\n",
            "valid accuracy: 0.82\n",
            "c_loss:0.08047480881214142\n",
            "cmd_c_loss:0.18743182718753815\n",
            "cmd_t_loss:5.229814052581787\n",
            "r_loss:0.12767983973026276\n",
            "accuracy_s:0.9942352175712585\n",
            "valid accuracy: 0.822\n",
            "c_loss:0.07825898379087448\n",
            "cmd_c_loss:0.17823748290538788\n",
            "cmd_t_loss:5.2538628578186035\n",
            "r_loss:0.1275370717048645\n",
            "accuracy_s:0.9942352175712585\n",
            "valid accuracy: 0.818\n",
            "c_loss:0.07704957574605942\n",
            "cmd_c_loss:0.19153906404972076\n",
            "cmd_t_loss:5.276761531829834\n",
            "r_loss:0.12747105956077576\n",
            "accuracy_s:0.9946195483207703\n",
            "valid accuracy: 0.824\n",
            "c_loss:0.07619406282901764\n",
            "cmd_c_loss:0.17391681671142578\n",
            "cmd_t_loss:5.296433925628662\n",
            "r_loss:0.12753744423389435\n",
            "accuracy_s:0.9950038194656372\n",
            "valid accuracy: 0.814\n",
            "c_loss:0.07467341423034668\n",
            "cmd_c_loss:0.1888488233089447\n",
            "cmd_t_loss:5.319223403930664\n",
            "r_loss:0.12749871611595154\n",
            "accuracy_s:0.9946195483207703\n",
            "valid accuracy: 0.81\n",
            "c_loss:0.07386051118373871\n",
            "cmd_c_loss:0.17785342037677765\n",
            "cmd_t_loss:5.337105751037598\n",
            "r_loss:0.12755423784255981\n",
            "accuracy_s:0.9953881502151489\n",
            "valid accuracy: 0.814\n",
            "c_loss:0.0733441561460495\n",
            "cmd_c_loss:0.207915797829628\n",
            "cmd_t_loss:5.359711170196533\n",
            "r_loss:0.1276719719171524\n",
            "accuracy_s:0.9950038194656372\n",
            "valid accuracy: 0.824\n",
            "c_loss:0.07283920794725418\n",
            "cmd_c_loss:0.1722193956375122\n",
            "cmd_t_loss:5.371268272399902\n",
            "r_loss:0.12780749797821045\n",
            "accuracy_s:0.9961568117141724\n",
            "valid accuracy: 0.808\n",
            "c_loss:0.07134751975536346\n",
            "cmd_c_loss:0.19699984788894653\n",
            "cmd_t_loss:5.395312786102295\n",
            "r_loss:0.12778663635253906\n",
            "accuracy_s:0.9953881502151489\n",
            "valid accuracy: 0.822\n",
            "c_loss:0.07041499018669128\n",
            "cmd_c_loss:0.1787528395652771\n",
            "cmd_t_loss:5.404628276824951\n",
            "r_loss:0.1277541071176529\n",
            "accuracy_s:0.9965411424636841\n",
            "valid accuracy: 0.814\n",
            "c_loss:0.06978636234998703\n",
            "cmd_c_loss:0.2158873975276947\n",
            "cmd_t_loss:5.431486129760742\n",
            "r_loss:0.1281009018421173\n",
            "accuracy_s:0.9961568117141724\n",
            "valid accuracy: 0.822\n",
            "c_loss:0.0674409344792366\n",
            "cmd_c_loss:0.18673957884311676\n",
            "cmd_t_loss:5.440685272216797\n",
            "r_loss:0.12799608707427979\n",
            "accuracy_s:0.9961568117141724\n",
            "valid accuracy: 0.82\n",
            "c_loss:0.06855238974094391\n",
            "cmd_c_loss:0.20610147714614868\n",
            "cmd_t_loss:5.470347881317139\n",
            "r_loss:0.12781569361686707\n",
            "accuracy_s:0.9965411424636841\n",
            "valid accuracy: 0.812\n",
            "c_loss:0.06749851256608963\n",
            "cmd_c_loss:0.1876305341720581\n",
            "cmd_t_loss:5.478245735168457\n",
            "r_loss:0.12816515564918518\n",
            "accuracy_s:0.996925413608551\n",
            "valid accuracy: 0.826\n",
            "c_loss:0.07081352919340134\n",
            "cmd_c_loss:0.2203601598739624\n",
            "cmd_t_loss:5.507260799407959\n",
            "r_loss:0.12885782122612\n",
            "accuracy_s:0.9961568117141724\n",
            "valid accuracy: 0.804\n",
            "c_loss:0.06767017394304276\n",
            "cmd_c_loss:0.1886182576417923\n",
            "cmd_t_loss:5.513199329376221\n",
            "r_loss:0.1285673975944519\n",
            "accuracy_s:0.9976940751075745\n",
            "valid accuracy: 0.824\n",
            "c_loss:0.06890548765659332\n",
            "cmd_c_loss:0.22819510102272034\n",
            "cmd_t_loss:5.540565490722656\n",
            "r_loss:0.12908071279525757\n",
            "accuracy_s:0.9961568117141724\n",
            "valid accuracy: 0.806\n",
            "c_loss:0.06357897818088531\n",
            "cmd_c_loss:0.17915122210979462\n",
            "cmd_t_loss:5.54582405090332\n",
            "r_loss:0.12893874943256378\n",
            "accuracy_s:0.9980784058570862\n",
            "valid accuracy: 0.82\n",
            "c_loss:0.06368155777454376\n",
            "cmd_c_loss:0.22506439685821533\n",
            "cmd_t_loss:5.57179594039917\n",
            "r_loss:0.12956100702285767\n",
            "accuracy_s:0.9976940751075745\n",
            "best_result:0.828000009059906\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_common_0_to_1.pkl\n",
            "test_accuracy:0.8066534996032715\n",
            "Train target model...\n",
            "t_loss:0.7628871202468872\n",
            "cmd_c_loss:0.10737033188343048\n",
            "cmd_t_loss:0.11703744530677795\n",
            "r_loss:0.8219575881958008\n",
            "accuracy_t:0.48671096563339233\n",
            "t_loss:0.7553327679634094\n",
            "cmd_c_loss:0.10469543933868408\n",
            "cmd_t_loss:0.11969059705734253\n",
            "r_loss:0.8186132907867432\n",
            "accuracy_t:0.485049843788147\n",
            "t_loss:0.7479103803634644\n",
            "cmd_c_loss:0.10187693685293198\n",
            "cmd_t_loss:0.12248743325471878\n",
            "r_loss:0.8151094913482666\n",
            "accuracy_t:0.485049843788147\n",
            "t_loss:0.7406360507011414\n",
            "cmd_c_loss:0.0989069864153862\n",
            "cmd_t_loss:0.1254357099533081\n",
            "r_loss:0.8114398717880249\n",
            "accuracy_t:0.48671096563339233\n",
            "t_loss:0.7335230708122253\n",
            "cmd_c_loss:0.09577780961990356\n",
            "cmd_t_loss:0.12854352593421936\n",
            "r_loss:0.8075975179672241\n",
            "accuracy_t:0.48671096563339233\n",
            "t_loss:0.7265816330909729\n",
            "cmd_c_loss:0.09248086810112\n",
            "cmd_t_loss:0.13181865215301514\n",
            "r_loss:0.8035756945610046\n",
            "accuracy_t:0.49003320932388306\n",
            "t_loss:0.719818115234375\n",
            "cmd_c_loss:0.08900739997625351\n",
            "cmd_t_loss:0.13527008891105652\n",
            "r_loss:0.7993677258491516\n",
            "accuracy_t:0.4916943609714508\n",
            "t_loss:0.7132346034049988\n",
            "cmd_c_loss:0.08534801751375198\n",
            "cmd_t_loss:0.13890673220157623\n",
            "r_loss:0.7949665784835815\n",
            "accuracy_t:0.49501660466194153\n",
            "t_loss:0.7068284749984741\n",
            "cmd_c_loss:0.08149296045303345\n",
            "cmd_t_loss:0.1427379548549652\n",
            "r_loss:0.7903652787208557\n",
            "accuracy_t:0.5049833655357361\n",
            "t_loss:0.7005931735038757\n",
            "cmd_c_loss:0.07743199169635773\n",
            "cmd_t_loss:0.14677388966083527\n",
            "r_loss:0.7855570912361145\n",
            "accuracy_t:0.5083056688308716\n",
            "t_loss:0.6945169568061829\n",
            "cmd_c_loss:0.07315453886985779\n",
            "cmd_t_loss:0.15102553367614746\n",
            "r_loss:0.7805350422859192\n",
            "accuracy_t:0.5166112780570984\n",
            "t_loss:0.688584566116333\n",
            "cmd_c_loss:0.06864943355321884\n",
            "cmd_t_loss:0.15550415217876434\n",
            "r_loss:0.7752920985221863\n",
            "accuracy_t:0.5199335813522339\n",
            "t_loss:0.682777464389801\n",
            "cmd_c_loss:0.0639047622680664\n",
            "cmd_t_loss:0.16022169589996338\n",
            "r_loss:0.7698220014572144\n",
            "accuracy_t:0.5465116500854492\n",
            "t_loss:0.677074134349823\n",
            "cmd_c_loss:0.058908261358737946\n",
            "cmd_t_loss:0.16519059240818024\n",
            "r_loss:0.7641177177429199\n",
            "accuracy_t:0.5531561374664307\n",
            "t_loss:0.6714489459991455\n",
            "cmd_c_loss:0.05364716425538063\n",
            "cmd_t_loss:0.17042404413223267\n",
            "r_loss:0.7581730484962463\n",
            "accuracy_t:0.5564783811569214\n",
            "t_loss:0.6658748388290405\n",
            "cmd_c_loss:0.0481082908809185\n",
            "cmd_t_loss:0.17593662440776825\n",
            "r_loss:0.7519823908805847\n",
            "accuracy_t:0.5780730843544006\n",
            "t_loss:0.6603241562843323\n",
            "cmd_c_loss:0.04227777197957039\n",
            "cmd_t_loss:0.18174225091934204\n",
            "r_loss:0.745540201663971\n",
            "accuracy_t:0.5930232405662537\n",
            "t_loss:0.6547676920890808\n",
            "cmd_c_loss:0.036141689866781235\n",
            "cmd_t_loss:0.1878565549850464\n",
            "r_loss:0.7388414740562439\n",
            "accuracy_t:0.6029900312423706\n",
            "t_loss:0.6491780877113342\n",
            "cmd_c_loss:0.029686175286769867\n",
            "cmd_t_loss:0.1942954659461975\n",
            "r_loss:0.7318820953369141\n",
            "accuracy_t:0.6229236125946045\n",
            "t_loss:0.6435268521308899\n",
            "cmd_c_loss:0.022897658869624138\n",
            "cmd_t_loss:0.20107758045196533\n",
            "r_loss:0.7246590256690979\n",
            "accuracy_t:0.6362126469612122\n",
            "t_loss:0.6377876400947571\n",
            "cmd_c_loss:0.015766233205795288\n",
            "cmd_t_loss:0.2082206755876541\n",
            "r_loss:0.7171708941459656\n",
            "accuracy_t:0.6428571343421936\n",
            "t_loss:0.6319361925125122\n",
            "cmd_c_loss:0.008318165317177773\n",
            "cmd_t_loss:0.21574372053146362\n",
            "r_loss:0.7094221115112305\n",
            "accuracy_t:0.6777408719062805\n",
            "t_loss:0.625950276851654\n",
            "cmd_c_loss:0.011707687750458717\n",
            "cmd_t_loss:0.2236664891242981\n",
            "r_loss:0.7014683485031128\n",
            "accuracy_t:0.6926910281181335\n",
            "t_loss:0.6198102235794067\n",
            "cmd_c_loss:0.00889839231967926\n",
            "cmd_t_loss:0.23201000690460205\n",
            "r_loss:0.6930732727050781\n",
            "accuracy_t:0.7192690968513489\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.54\n",
            "t_loss:0.6134998798370361\n",
            "cmd_c_loss:0.011815967969596386\n",
            "cmd_t_loss:0.2407945841550827\n",
            "r_loss:0.6845998167991638\n",
            "accuracy_t:0.7392026782035828\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.55\n",
            "t_loss:0.6070049405097961\n",
            "cmd_c_loss:0.009611040353775024\n",
            "cmd_t_loss:0.2500429153442383\n",
            "r_loss:0.6755939722061157\n",
            "accuracy_t:0.7541528344154358\n",
            "valid accuracy: 0.542\n",
            "t_loss:0.600313663482666\n",
            "cmd_c_loss:0.011865238659083843\n",
            "cmd_t_loss:0.2597796618938446\n",
            "r_loss:0.6665910482406616\n",
            "accuracy_t:0.7724252343177795\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.558\n",
            "t_loss:0.5934165120124817\n",
            "cmd_c_loss:0.010440624319016933\n",
            "cmd_t_loss:0.2700263261795044\n",
            "r_loss:0.6569899916648865\n",
            "accuracy_t:0.7940199375152588\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.566\n",
            "t_loss:0.5863062739372253\n",
            "cmd_c_loss:0.0118867764249444\n",
            "cmd_t_loss:0.2808084487915039\n",
            "r_loss:0.6474579572677612\n",
            "accuracy_t:0.8122923374176025\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.572\n",
            "t_loss:0.5789775252342224\n",
            "cmd_c_loss:0.011372804641723633\n",
            "cmd_t_loss:0.29215192794799805\n",
            "r_loss:0.6372841000556946\n",
            "accuracy_t:0.8239202499389648\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.58\n",
            "t_loss:0.5714282393455505\n",
            "cmd_c_loss:0.011906403116881847\n",
            "cmd_t_loss:0.3040834665298462\n",
            "r_loss:0.6272342205047607\n",
            "accuracy_t:0.8455149531364441\n",
            "valid accuracy: 0.576\n",
            "t_loss:0.5636564493179321\n",
            "cmd_c_loss:0.012395314872264862\n",
            "cmd_t_loss:0.316630095243454\n",
            "r_loss:0.6165199875831604\n",
            "accuracy_t:0.8621262311935425\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.582\n",
            "t_loss:0.5556622743606567\n",
            "cmd_c_loss:0.01194783952087164\n",
            "cmd_t_loss:0.3298192620277405\n",
            "r_loss:0.6059752106666565\n",
            "accuracy_t:0.8720930218696594\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.594\n",
            "t_loss:0.5474458932876587\n",
            "cmd_c_loss:0.013496597297489643\n",
            "cmd_t_loss:0.3436809480190277\n",
            "r_loss:0.5947644710540771\n",
            "accuracy_t:0.8870431780815125\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.604\n",
            "t_loss:0.5390110611915588\n",
            "cmd_c_loss:0.01203412376344204\n",
            "cmd_t_loss:0.358242005109787\n",
            "r_loss:0.5837591290473938\n",
            "accuracy_t:0.895348846912384\n",
            "valid accuracy: 0.604\n",
            "t_loss:0.5303605794906616\n",
            "cmd_c_loss:0.01466564554721117\n",
            "cmd_t_loss:0.3735294044017792\n",
            "r_loss:0.5721055865287781\n",
            "accuracy_t:0.9019933342933655\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.61\n",
            "t_loss:0.5214979648590088\n",
            "cmd_c_loss:0.012187479995191097\n",
            "cmd_t_loss:0.3895736336708069\n",
            "r_loss:0.5606858730316162\n",
            "accuracy_t:0.9119601249694824\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.622\n",
            "t_loss:0.5124275088310242\n",
            "cmd_c_loss:0.015891430899500847\n",
            "cmd_t_loss:0.40640291571617126\n",
            "r_loss:0.5486553311347961\n",
            "accuracy_t:0.9219269156455994\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.628\n",
            "t_loss:0.5031567811965942\n",
            "cmd_c_loss:0.012430324219167233\n",
            "cmd_t_loss:0.42405226826667786\n",
            "r_loss:0.536881148815155\n",
            "accuracy_t:0.9252491593360901\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.64\n",
            "t_loss:0.49369293451309204\n",
            "cmd_c_loss:0.01716499961912632\n",
            "cmd_t_loss:0.44254639744758606\n",
            "r_loss:0.5245499014854431\n",
            "accuracy_t:0.9318937063217163\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.648\n",
            "t_loss:0.4840393662452698\n",
            "cmd_c_loss:0.012783064506947994\n",
            "cmd_t_loss:0.4619143009185791\n",
            "r_loss:0.5124931335449219\n",
            "accuracy_t:0.9435216188430786\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.66\n",
            "t_loss:0.47420579195022583\n",
            "cmd_c_loss:0.018479082733392715\n",
            "cmd_t_loss:0.4821854829788208\n",
            "r_loss:0.49994951486587524\n",
            "accuracy_t:0.9501661062240601\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.664\n",
            "t_loss:0.46420449018478394\n",
            "cmd_c_loss:0.013265752233564854\n",
            "cmd_t_loss:0.5033935904502869\n",
            "r_loss:0.48769325017929077\n",
            "accuracy_t:0.9551495313644409\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.67\n",
            "t_loss:0.4540458023548126\n",
            "cmd_c_loss:0.019828418269753456\n",
            "cmd_t_loss:0.5255685448646545\n",
            "r_loss:0.4750317633152008\n",
            "accuracy_t:0.9584717750549316\n",
            "valid accuracy: 0.668\n",
            "t_loss:0.44373926520347595\n",
            "cmd_c_loss:0.013894503004848957\n",
            "cmd_t_loss:0.5487390756607056\n",
            "r_loss:0.4626697897911072\n",
            "accuracy_t:0.9617940187454224\n",
            "valid accuracy: 0.666\n",
            "t_loss:0.43329501152038574\n",
            "cmd_c_loss:0.02121553011238575\n",
            "cmd_t_loss:0.5729345083236694\n",
            "r_loss:0.4499939978122711\n",
            "accuracy_t:0.9684385657310486\n",
            "valid accuracy: 0.666\n",
            "t_loss:0.42272594571113586\n",
            "cmd_c_loss:0.01468297466635704\n",
            "cmd_t_loss:0.5981832146644592\n",
            "r_loss:0.43762850761413574\n",
            "accuracy_t:0.9734219312667847\n",
            "valid accuracy: 0.66\n",
            "t_loss:0.41204512119293213\n",
            "cmd_c_loss:0.02264835685491562\n",
            "cmd_t_loss:0.6245128512382507\n",
            "r_loss:0.42504364252090454\n",
            "accuracy_t:0.97508305311203\n",
            "valid accuracy: 0.664\n",
            "t_loss:0.40126538276672363\n",
            "cmd_c_loss:0.015644483268260956\n",
            "cmd_t_loss:0.651945948600769\n",
            "r_loss:0.4127771854400635\n",
            "accuracy_t:0.9767441749572754\n",
            "valid accuracy: 0.67\n",
            "t_loss:0.39040306210517883\n",
            "cmd_c_loss:0.024139268323779106\n",
            "cmd_t_loss:0.6805218458175659\n",
            "r_loss:0.4003865718841553\n",
            "accuracy_t:0.9800664186477661\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.678\n",
            "t_loss:0.3794727921485901\n",
            "cmd_c_loss:0.0167922955006361\n",
            "cmd_t_loss:0.7102660536766052\n",
            "r_loss:0.38832247257232666\n",
            "accuracy_t:0.9800664186477661\n",
            "valid accuracy: 0.676\n",
            "t_loss:0.36849620938301086\n",
            "cmd_c_loss:0.025707794353365898\n",
            "cmd_t_loss:0.7411896586418152\n",
            "r_loss:0.3762281537055969\n",
            "accuracy_t:0.9817276000976562\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.68\n",
            "t_loss:0.3574865460395813\n",
            "cmd_c_loss:0.018141085281968117\n",
            "cmd_t_loss:0.7733154296875\n",
            "r_loss:0.3644667863845825\n",
            "accuracy_t:0.9833887219429016\n",
            "valid accuracy: 0.68\n",
            "t_loss:0.34646522998809814\n",
            "cmd_c_loss:0.027378743514418602\n",
            "cmd_t_loss:0.806667149066925\n",
            "r_loss:0.35276395082473755\n",
            "accuracy_t:0.9833887219429016\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.682\n",
            "t_loss:0.33545440435409546\n",
            "cmd_c_loss:0.01970912516117096\n",
            "cmd_t_loss:0.8412628769874573\n",
            "r_loss:0.3413989245891571\n",
            "accuracy_t:0.9833887219429016\n",
            "valid accuracy: 0.682\n",
            "t_loss:0.3244748115539551\n",
            "cmd_c_loss:0.029189519584178925\n",
            "cmd_t_loss:0.8771134614944458\n",
            "r_loss:0.330172598361969\n",
            "accuracy_t:0.9833887219429016\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.684\n",
            "t_loss:0.31354808807373047\n",
            "cmd_c_loss:0.021527526900172234\n",
            "cmd_t_loss:0.9142338037490845\n",
            "r_loss:0.31928834319114685\n",
            "accuracy_t:0.985049843788147\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.686\n",
            "t_loss:0.30269643664360046\n",
            "cmd_c_loss:0.031208233907818794\n",
            "cmd_t_loss:0.9526187777519226\n",
            "r_loss:0.3086121678352356\n",
            "accuracy_t:0.9867109656333923\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.688\n",
            "t_loss:0.29195016622543335\n",
            "cmd_c_loss:0.023678062483668327\n",
            "cmd_t_loss:0.9922926425933838\n",
            "r_loss:0.2982836365699768\n",
            "accuracy_t:0.9883720874786377\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.69\n",
            "t_loss:0.281332790851593\n",
            "cmd_c_loss:0.03363225236535072\n",
            "cmd_t_loss:1.0332697629928589\n",
            "r_loss:0.2882164716720581\n",
            "accuracy_t:0.9916943311691284\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.692\n",
            "t_loss:0.270858496427536\n",
            "cmd_c_loss:0.02632077969610691\n",
            "cmd_t_loss:1.0755457878112793\n",
            "r_loss:0.2785068154335022\n",
            "accuracy_t:0.9916943311691284\n",
            "valid accuracy: 0.69\n",
            "t_loss:0.2605544328689575\n",
            "cmd_c_loss:0.036653488874435425\n",
            "cmd_t_loss:1.1191339492797852\n",
            "r_loss:0.2690897583961487\n",
            "accuracy_t:0.9916943311691284\n",
            "valid accuracy: 0.69\n",
            "t_loss:0.2504428029060364\n",
            "cmd_c_loss:0.029261993244290352\n",
            "cmd_t_loss:1.1640249490737915\n",
            "r_loss:0.26004794239997864\n",
            "accuracy_t:0.9916943311691284\n",
            "valid accuracy: 0.692\n",
            "t_loss:0.24055024981498718\n",
            "cmd_c_loss:0.04001671448349953\n",
            "cmd_t_loss:1.210210919380188\n",
            "r_loss:0.25131577253341675\n",
            "accuracy_t:0.9916943311691284\n",
            "valid accuracy: 0.692\n",
            "t_loss:0.23089368641376495\n",
            "cmd_c_loss:0.03242868185043335\n",
            "cmd_t_loss:1.2576807737350464\n",
            "r_loss:0.24297063052654266\n",
            "accuracy_t:0.9916943311691284\n",
            "valid accuracy: 0.692\n",
            "t_loss:0.22149458527565002\n",
            "cmd_c_loss:0.043638527393341064\n",
            "cmd_t_loss:1.306433081626892\n",
            "r_loss:0.2349568009376526\n",
            "accuracy_t:0.9933554530143738\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.696\n",
            "t_loss:0.2123698741197586\n",
            "cmd_c_loss:0.03585490584373474\n",
            "cmd_t_loss:1.3564404249191284\n",
            "r_loss:0.22732435166835785\n",
            "accuracy_t:0.9933554530143738\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.698\n",
            "t_loss:0.2035360485315323\n",
            "cmd_c_loss:0.04749302193522453\n",
            "cmd_t_loss:1.4076828956604004\n",
            "r_loss:0.22005219757556915\n",
            "accuracy_t:0.9950166344642639\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.704\n",
            "t_loss:0.19499920308589935\n",
            "cmd_c_loss:0.039591170847415924\n",
            "cmd_t_loss:1.460127592086792\n",
            "r_loss:0.213139146566391\n",
            "accuracy_t:0.9950166344642639\n",
            "valid accuracy: 0.702\n",
            "t_loss:0.18677210807800293\n",
            "cmd_c_loss:0.051605768501758575\n",
            "cmd_t_loss:1.5137455463409424\n",
            "r_loss:0.2066170573234558\n",
            "accuracy_t:0.9966777563095093\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.706\n",
            "t_loss:0.1788654774427414\n",
            "cmd_c_loss:0.0436641089618206\n",
            "cmd_t_loss:1.5685237646102905\n",
            "r_loss:0.2004222571849823\n",
            "accuracy_t:0.9983388781547546\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.17128175497055054\n",
            "cmd_c_loss:0.05594979599118233\n",
            "cmd_t_loss:1.624450922012329\n",
            "r_loss:0.19464725255966187\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.1640278697013855\n",
            "cmd_c_loss:0.048016663640737534\n",
            "cmd_t_loss:1.6814881563186646\n",
            "r_loss:0.18916524946689606\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.15710484981536865\n",
            "cmd_c_loss:0.06049598753452301\n",
            "cmd_t_loss:1.7395838499069214\n",
            "r_loss:0.18411660194396973\n",
            "accuracy_t:1.0\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.712\n",
            "t_loss:0.15051144361495972\n",
            "cmd_c_loss:0.05267517268657684\n",
            "cmd_t_loss:1.7987130880355835\n",
            "r_loss:0.1793321967124939\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.712\n",
            "t_loss:0.1442434936761856\n",
            "cmd_c_loss:0.06531240046024323\n",
            "cmd_t_loss:1.8588480949401855\n",
            "r_loss:0.1749781221151352\n",
            "accuracy_t:1.0\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.716\n",
            "t_loss:0.1383001059293747\n",
            "cmd_c_loss:0.057743996381759644\n",
            "cmd_t_loss:1.9199600219726562\n",
            "r_loss:0.1708616316318512\n",
            "accuracy_t:1.0\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.72\n",
            "t_loss:0.13267306983470917\n",
            "cmd_c_loss:0.07051805406808853\n",
            "cmd_t_loss:1.982007384300232\n",
            "r_loss:0.1671593189239502\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.72\n",
            "t_loss:0.12735290825366974\n",
            "cmd_c_loss:0.06332720071077347\n",
            "cmd_t_loss:2.044942617416382\n",
            "r_loss:0.1636659950017929\n",
            "accuracy_t:1.0\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.722\n",
            "t_loss:0.12233294546604156\n",
            "cmd_c_loss:0.0761956200003624\n",
            "cmd_t_loss:2.108708620071411\n",
            "r_loss:0.16055814921855927\n",
            "accuracy_t:1.0\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.726\n",
            "t_loss:0.11761485785245895\n",
            "cmd_c_loss:0.06950850039720535\n",
            "cmd_t_loss:2.173267364501953\n",
            "r_loss:0.15763413906097412\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.724\n",
            "t_loss:0.11318149417638779\n",
            "cmd_c_loss:0.08243024349212646\n",
            "cmd_t_loss:2.2385547161102295\n",
            "r_loss:0.15505212545394897\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.724\n",
            "t_loss:0.10901793837547302\n",
            "cmd_c_loss:0.07621035724878311\n",
            "cmd_t_loss:2.3045122623443604\n",
            "r_loss:0.15262474119663239\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.726\n",
            "t_loss:0.10512475669384003\n",
            "cmd_c_loss:0.0889156237244606\n",
            "cmd_t_loss:2.3710920810699463\n",
            "r_loss:0.15049242973327637\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.726\n",
            "t_loss:0.10149160027503967\n",
            "cmd_c_loss:0.08288757503032684\n",
            "cmd_t_loss:2.4381778240203857\n",
            "r_loss:0.14848382771015167\n",
            "accuracy_t:1.0\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.728\n",
            "t_loss:0.09809747338294983\n",
            "cmd_c_loss:0.09520416706800461\n",
            "cmd_t_loss:2.505739688873291\n",
            "r_loss:0.14672918617725372\n",
            "accuracy_t:1.0\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.73\n",
            "t_loss:0.09494452178478241\n",
            "cmd_c_loss:0.08964194357395172\n",
            "cmd_t_loss:2.573662042617798\n",
            "r_loss:0.14506281912326813\n",
            "accuracy_t:1.0\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.732\n",
            "t_loss:0.09201456606388092\n",
            "cmd_c_loss:0.1017618328332901\n",
            "cmd_t_loss:2.641868829727173\n",
            "r_loss:0.14361073076725006\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.73\n",
            "t_loss:0.08932402729988098\n",
            "cmd_c_loss:0.09689333289861679\n",
            "cmd_t_loss:2.7102627754211426\n",
            "r_loss:0.14222760498523712\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.73\n",
            "t_loss:0.08683596551418304\n",
            "cmd_c_loss:0.10880912840366364\n",
            "cmd_t_loss:2.7787818908691406\n",
            "r_loss:0.1410178691148758\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.73\n",
            "t_loss:0.08451919257640839\n",
            "cmd_c_loss:0.10468427836894989\n",
            "cmd_t_loss:2.8473846912384033\n",
            "r_loss:0.13986779749393463\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.732\n",
            "t_loss:0.08241678774356842\n",
            "cmd_c_loss:0.11638472229242325\n",
            "cmd_t_loss:2.915984630584717\n",
            "r_loss:0.13885149359703064\n",
            "accuracy_t:1.0\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.734\n",
            "t_loss:0.08047459274530411\n",
            "cmd_c_loss:0.11288774758577347\n",
            "cmd_t_loss:2.9844915866851807\n",
            "r_loss:0.13789065182209015\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.732\n",
            "t_loss:0.07868867367506027\n",
            "cmd_c_loss:0.12432487308979034\n",
            "cmd_t_loss:3.052856206893921\n",
            "r_loss:0.13703322410583496\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.732\n",
            "t_loss:0.07708083093166351\n",
            "cmd_c_loss:0.12131714075803757\n",
            "cmd_t_loss:3.1209635734558105\n",
            "r_loss:0.13622663915157318\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.73\n",
            "t_loss:0.0755898579955101\n",
            "cmd_c_loss:0.1325588971376419\n",
            "cmd_t_loss:3.188728094100952\n",
            "r_loss:0.13550080358982086\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.73\n",
            "t_loss:0.07425323128700256\n",
            "cmd_c_loss:0.12989526987075806\n",
            "cmd_t_loss:3.2560715675354004\n",
            "r_loss:0.13482438027858734\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.728\n",
            "t_loss:0.07300513237714767\n",
            "cmd_c_loss:0.1409938484430313\n",
            "cmd_t_loss:3.3229100704193115\n",
            "r_loss:0.13420286774635315\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.73\n",
            "t_loss:0.07190860062837601\n",
            "cmd_c_loss:0.13849535584449768\n",
            "cmd_t_loss:3.3892602920532227\n",
            "r_loss:0.13364292681217194\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.726\n",
            "t_loss:0.07086338847875595\n",
            "cmd_c_loss:0.14955712854862213\n",
            "cmd_t_loss:3.45489239692688\n",
            "r_loss:0.1331057995557785\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.722\n",
            "t_loss:0.0698801800608635\n",
            "cmd_c_loss:0.14708773791790009\n",
            "cmd_t_loss:3.519716262817383\n",
            "r_loss:0.13264599442481995\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.724\n",
            "t_loss:0.0690084844827652\n",
            "cmd_c_loss:0.15825004875659943\n",
            "cmd_t_loss:3.5837559700012207\n",
            "r_loss:0.1321820318698883\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.722\n",
            "t_loss:0.06819278001785278\n",
            "cmd_c_loss:0.15581384301185608\n",
            "cmd_t_loss:3.646881580352783\n",
            "r_loss:0.1318160444498062\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.72\n",
            "t_loss:0.06736711412668228\n",
            "cmd_c_loss:0.16714002192020416\n",
            "cmd_t_loss:3.708961248397827\n",
            "r_loss:0.13141490519046783\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.724\n",
            "t_loss:0.0666394904255867\n",
            "cmd_c_loss:0.16467782855033875\n",
            "cmd_t_loss:3.7701056003570557\n",
            "r_loss:0.13113130629062653\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.722\n",
            "t_loss:0.06596145033836365\n",
            "cmd_c_loss:0.17593204975128174\n",
            "cmd_t_loss:3.8300843238830566\n",
            "r_loss:0.13078927993774414\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.722\n",
            "t_loss:0.06520529836416245\n",
            "cmd_c_loss:0.17313189804553986\n",
            "cmd_t_loss:3.8889119625091553\n",
            "r_loss:0.13057342171669006\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.722\n",
            "t_loss:0.06458532810211182\n",
            "cmd_c_loss:0.18403597176074982\n",
            "cmd_t_loss:3.9466958045959473\n",
            "r_loss:0.13028527796268463\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.72\n",
            "t_loss:0.0639568641781807\n",
            "cmd_c_loss:0.1806800812482834\n",
            "cmd_t_loss:4.0031890869140625\n",
            "r_loss:0.13013304769992828\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.72\n",
            "t_loss:0.06324274837970734\n",
            "cmd_c_loss:0.1913321614265442\n",
            "cmd_t_loss:4.058431148529053\n",
            "r_loss:0.12987872958183289\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.728\n",
            "t_loss:0.06278566271066666\n",
            "cmd_c_loss:0.18740493059158325\n",
            "cmd_t_loss:4.1125874519348145\n",
            "r_loss:0.12978149950504303\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.06230214238166809\n",
            "cmd_c_loss:0.19783011078834534\n",
            "cmd_t_loss:4.165212631225586\n",
            "r_loss:0.12954479455947876\n",
            "accuracy_t:1.0\n",
            "best_result:0.734000027179718\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_target_0_to_1.pkl\n",
            "test_accuracy:0.6930171251296997\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_common_0_to_1.pkl\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_target_0_to_1.pkl\n",
            "pos num: 5\n",
            "neg num: 5\n",
            "pos num: 9\n",
            "neg num: 10\n",
            "unlabelled num: 1384\n",
            "1384\n",
            "Train combined model...\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_common_0_to_1.pkl\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_target_0_to_1.pkl\n",
            "valid accuracy: 0.828\n",
            "test accuracy: 0.8066534914361001\n",
            "Train common model...\n",
            "c_loss:0.7724646925926208\n",
            "cmd_c_loss:0.11681152135133743\n",
            "cmd_t_loss:0.10539602488279343\n",
            "r_loss:0.8162294030189514\n",
            "accuracy_s:0.5013353824615479\n",
            "c_loss:0.7665666341781616\n",
            "cmd_c_loss:0.11416224390268326\n",
            "cmd_t_loss:0.10806865990161896\n",
            "r_loss:0.8129191994667053\n",
            "accuracy_s:0.5017169117927551\n",
            "c_loss:0.7607860565185547\n",
            "cmd_c_loss:0.11136948317289352\n",
            "cmd_t_loss:0.11088601499795914\n",
            "r_loss:0.8094521164894104\n",
            "accuracy_s:0.5017169117927551\n",
            "c_loss:0.7551450729370117\n",
            "cmd_c_loss:0.10842554271221161\n",
            "cmd_t_loss:0.11385643482208252\n",
            "r_loss:0.8058217763900757\n",
            "accuracy_s:0.5017169117927551\n",
            "c_loss:0.7496650815010071\n",
            "cmd_c_loss:0.10532236099243164\n",
            "cmd_t_loss:0.11698770523071289\n",
            "r_loss:0.8020219802856445\n",
            "accuracy_s:0.5020984411239624\n",
            "c_loss:0.7443659901618958\n",
            "cmd_c_loss:0.10205157101154327\n",
            "cmd_t_loss:0.12028864771127701\n",
            "r_loss:0.7980462908744812\n",
            "accuracy_s:0.502861499786377\n",
            "c_loss:0.7392662763595581\n",
            "cmd_c_loss:0.09860411286354065\n",
            "cmd_t_loss:0.12376803159713745\n",
            "r_loss:0.7938876748085022\n",
            "accuracy_s:0.504387617111206\n",
            "c_loss:0.7343823313713074\n",
            "cmd_c_loss:0.09497061371803284\n",
            "cmd_t_loss:0.12743572890758514\n",
            "r_loss:0.7895396947860718\n",
            "accuracy_s:0.5051507353782654\n",
            "c_loss:0.7297279238700867\n",
            "cmd_c_loss:0.09114141017198563\n",
            "cmd_t_loss:0.13130176067352295\n",
            "r_loss:0.7849956154823303\n",
            "accuracy_s:0.5047691464424133\n",
            "c_loss:0.7253137230873108\n",
            "cmd_c_loss:0.08710601180791855\n",
            "cmd_t_loss:0.1353766918182373\n",
            "r_loss:0.7802485823631287\n",
            "accuracy_s:0.5059137940406799\n",
            "c_loss:0.7211475372314453\n",
            "cmd_c_loss:0.08285394310951233\n",
            "cmd_t_loss:0.13967174291610718\n",
            "r_loss:0.7752920985221863\n",
            "accuracy_s:0.5040060877799988\n",
            "c_loss:0.7172336578369141\n",
            "cmd_c_loss:0.07837367057800293\n",
            "cmd_t_loss:0.14419913291931152\n",
            "r_loss:0.7701191902160645\n",
            "accuracy_s:0.5036245584487915\n",
            "c_loss:0.7135727405548096\n",
            "cmd_c_loss:0.07365341484546661\n",
            "cmd_t_loss:0.14897029101848602\n",
            "r_loss:0.7647234201431274\n",
            "accuracy_s:0.5036245584487915\n",
            "c_loss:0.7101617455482483\n",
            "cmd_c_loss:0.06868080794811249\n",
            "cmd_t_loss:0.15399940311908722\n",
            "r_loss:0.7590981721878052\n",
            "accuracy_s:0.5047691464424133\n",
            "c_loss:0.7069942951202393\n",
            "cmd_c_loss:0.0634429007768631\n",
            "cmd_t_loss:0.15929996967315674\n",
            "r_loss:0.753237247467041\n",
            "accuracy_s:0.5089660286903381\n",
            "c_loss:0.7040602564811707\n",
            "cmd_c_loss:0.057926204055547714\n",
            "cmd_t_loss:0.16488581895828247\n",
            "r_loss:0.7471345663070679\n",
            "accuracy_s:0.5131629109382629\n",
            "c_loss:0.7013466954231262\n",
            "cmd_c_loss:0.05211701616644859\n",
            "cmd_t_loss:0.1707724630832672\n",
            "r_loss:0.7407845258712769\n",
            "accuracy_s:0.5169782638549805\n",
            "c_loss:0.6988375782966614\n",
            "cmd_c_loss:0.04600121080875397\n",
            "cmd_t_loss:0.17697525024414062\n",
            "r_loss:0.7341822385787964\n",
            "accuracy_s:0.520412027835846\n",
            "c_loss:0.6965147852897644\n",
            "cmd_c_loss:0.03956374153494835\n",
            "cmd_t_loss:0.18351103365421295\n",
            "r_loss:0.7273225784301758\n",
            "accuracy_s:0.5272796750068665\n",
            "c_loss:0.6943582892417908\n",
            "cmd_c_loss:0.03278975561261177\n",
            "cmd_t_loss:0.1903962343931198\n",
            "r_loss:0.7202016711235046\n",
            "accuracy_s:0.5284242630004883\n",
            "c_loss:0.6923465132713318\n",
            "cmd_c_loss:0.02566475234925747\n",
            "cmd_t_loss:0.1976502686738968\n",
            "r_loss:0.7128161787986755\n",
            "accuracy_s:0.5341472625732422\n",
            "c_loss:0.6904573440551758\n",
            "cmd_c_loss:0.018176443874835968\n",
            "cmd_t_loss:0.20529133081436157\n",
            "r_loss:0.7051646113395691\n",
            "accuracy_s:0.5398702621459961\n",
            "c_loss:0.6886687278747559\n",
            "cmd_c_loss:0.01032547652721405\n",
            "cmd_t_loss:0.21333861351013184\n",
            "r_loss:0.6972485780715942\n",
            "accuracy_s:0.5417779684066772\n",
            "c_loss:0.686959445476532\n",
            "cmd_c_loss:0.00815028976649046\n",
            "cmd_t_loss:0.2218128740787506\n",
            "r_loss:0.6890838146209717\n",
            "accuracy_s:0.5497901439666748\n",
            "c_loss:0.685336709022522\n",
            "cmd_c_loss:0.010786732658743858\n",
            "cmd_t_loss:0.23073634505271912\n",
            "r_loss:0.6805574297904968\n",
            "accuracy_s:0.5528424382209778\n",
            "c_loss:0.6837212443351746\n",
            "cmd_c_loss:0.00852117594331503\n",
            "cmd_t_loss:0.24013063311576843\n",
            "r_loss:0.6718158721923828\n",
            "accuracy_s:0.5585654377937317\n",
            "c_loss:0.6821594834327698\n",
            "cmd_c_loss:0.011236289516091347\n",
            "cmd_t_loss:0.2500183582305908\n",
            "r_loss:0.6627398729324341\n",
            "accuracy_s:0.5646699666976929\n",
            "c_loss:0.6805597543716431\n",
            "cmd_c_loss:0.008967411704361439\n",
            "cmd_t_loss:0.26042333245277405\n",
            "r_loss:0.6534221768379211\n",
            "accuracy_s:0.573826789855957\n",
            "c_loss:0.6789906620979309\n",
            "cmd_c_loss:0.011678938753902912\n",
            "cmd_t_loss:0.2713724374771118\n",
            "r_loss:0.6438028216362\n",
            "accuracy_s:0.5784052014350891\n",
            "c_loss:0.677342414855957\n",
            "cmd_c_loss:0.009497999213635921\n",
            "cmd_t_loss:0.28289127349853516\n",
            "r_loss:0.6339204907417297\n",
            "accuracy_s:0.5845097303390503\n",
            "c_loss:0.675711452960968\n",
            "cmd_c_loss:0.012122416868805885\n",
            "cmd_t_loss:0.29500719904899597\n",
            "r_loss:0.6237713098526001\n",
            "accuracy_s:0.5906142592430115\n",
            "c_loss:0.6739642024040222\n",
            "cmd_c_loss:0.010118724778294563\n",
            "cmd_t_loss:0.3077484369277954\n",
            "r_loss:0.6133476495742798\n",
            "accuracy_s:0.597481906414032\n",
            "c_loss:0.6722298264503479\n",
            "cmd_c_loss:0.01257652323693037\n",
            "cmd_t_loss:0.32114189863204956\n",
            "r_loss:0.6026933193206787\n",
            "accuracy_s:0.6005341410636902\n",
            "c_loss:0.6703456044197083\n",
            "cmd_c_loss:0.010832387022674084\n",
            "cmd_t_loss:0.33521971106529236\n",
            "r_loss:0.5917642116546631\n",
            "accuracy_s:0.6062571406364441\n",
            "c_loss:0.6684767603874207\n",
            "cmd_c_loss:0.013052205555140972\n",
            "cmd_t_loss:0.3500101864337921\n",
            "r_loss:0.5806397199630737\n",
            "accuracy_s:0.6127431988716125\n",
            "c_loss:0.6664270162582397\n",
            "cmd_c_loss:0.011641370132565498\n",
            "cmd_t_loss:0.3655426800251007\n",
            "r_loss:0.5692533850669861\n",
            "accuracy_s:0.622281551361084\n",
            "c_loss:0.6643999218940735\n",
            "cmd_c_loss:0.013561654835939407\n",
            "cmd_t_loss:0.38184961676597595\n",
            "r_loss:0.5577061176300049\n",
            "accuracy_s:0.6306753158569336\n",
            "c_loss:0.6621618866920471\n",
            "cmd_c_loss:0.012546392157673836\n",
            "cmd_t_loss:0.3989647328853607\n",
            "r_loss:0.5459223985671997\n",
            "accuracy_s:0.6390690803527832\n",
            "c_loss:0.6599576473236084\n",
            "cmd_c_loss:0.014117876067757607\n",
            "cmd_t_loss:0.4169173240661621\n",
            "r_loss:0.5340129733085632\n",
            "accuracy_s:0.6455551385879517\n",
            "c_loss:0.6575121283531189\n",
            "cmd_c_loss:0.013549487106502056\n",
            "cmd_t_loss:0.4357461929321289\n",
            "r_loss:0.521906852722168\n",
            "accuracy_s:0.6516596674919128\n",
            "c_loss:0.6551137566566467\n",
            "cmd_c_loss:0.014733239077031612\n",
            "cmd_t_loss:0.45548319816589355\n",
            "r_loss:0.5097099542617798\n",
            "accuracy_s:0.6600534319877625\n",
            "c_loss:0.6524422764778137\n",
            "cmd_c_loss:0.014654019847512245\n",
            "cmd_t_loss:0.47616130113601685\n",
            "r_loss:0.4973675012588501\n",
            "accuracy_s:0.6650133728981018\n",
            "c_loss:0.6498333215713501\n",
            "cmd_c_loss:0.015421140938997269\n",
            "cmd_t_loss:0.49781128764152527\n",
            "r_loss:0.48496729135513306\n",
            "accuracy_s:0.6726440191268921\n",
            "c_loss:0.6469178199768066\n",
            "cmd_c_loss:0.01586424931883812\n",
            "cmd_t_loss:0.5204703211784363\n",
            "r_loss:0.47248488664627075\n",
            "accuracy_s:0.6776039600372314\n",
            "c_loss:0.6440815329551697\n",
            "cmd_c_loss:0.016195684671401978\n",
            "cmd_t_loss:0.5441673398017883\n",
            "r_loss:0.45997899770736694\n",
            "accuracy_s:0.6837084889411926\n",
            "c_loss:0.6409029960632324\n",
            "cmd_c_loss:0.017186272889375687\n",
            "cmd_t_loss:0.5689337849617004\n",
            "r_loss:0.44746094942092896\n",
            "accuracy_s:0.6905761361122131\n",
            "c_loss:0.637822151184082\n",
            "cmd_c_loss:0.01706850714981556\n",
            "cmd_t_loss:0.5947999954223633\n",
            "r_loss:0.4349515438079834\n",
            "accuracy_s:0.6959176063537598\n",
            "c_loss:0.6343605518341064\n",
            "cmd_c_loss:0.018629472702741623\n",
            "cmd_t_loss:0.6218001842498779\n",
            "r_loss:0.4225054085254669\n",
            "accuracy_s:0.7039297819137573\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.62\n",
            "c_loss:0.6310169100761414\n",
            "cmd_c_loss:0.018055519089102745\n",
            "cmd_t_loss:0.6499592065811157\n",
            "r_loss:0.4100986421108246\n",
            "accuracy_s:0.716901957988739\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.624\n",
            "c_loss:0.6272510290145874\n",
            "cmd_c_loss:0.02020629309117794\n",
            "cmd_t_loss:0.679309606552124\n",
            "r_loss:0.3978329598903656\n",
            "accuracy_s:0.7249141335487366\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.626\n",
            "c_loss:0.6236255764961243\n",
            "cmd_c_loss:0.019171539694070816\n",
            "cmd_t_loss:0.7098783254623413\n",
            "r_loss:0.38563674688339233\n",
            "accuracy_s:0.7333078980445862\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.636\n",
            "c_loss:0.619533360004425\n",
            "cmd_c_loss:0.021936217322945595\n",
            "cmd_t_loss:0.7416908740997314\n",
            "r_loss:0.3736582398414612\n",
            "accuracy_s:0.7420831918716431\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.642\n",
            "c_loss:0.6156058311462402\n",
            "cmd_c_loss:0.02043868415057659\n",
            "cmd_t_loss:0.774770200252533\n",
            "r_loss:0.36177700757980347\n",
            "accuracy_s:0.7535291910171509\n",
            "valid accuracy: 0.642\n",
            "c_loss:0.6111642718315125\n",
            "cmd_c_loss:0.0238517876714468\n",
            "cmd_t_loss:0.8091303706169128\n",
            "r_loss:0.35018497705459595\n",
            "accuracy_s:0.7607783079147339\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.656\n",
            "c_loss:0.6069151759147644\n",
            "cmd_c_loss:0.021899159997701645\n",
            "cmd_t_loss:0.8447944521903992\n",
            "r_loss:0.338714599609375\n",
            "accuracy_s:0.7668828964233398\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.662\n",
            "c_loss:0.6021012663841248\n",
            "cmd_c_loss:0.026022953912615776\n",
            "cmd_t_loss:0.8817859888076782\n",
            "r_loss:0.32759231328964233\n",
            "accuracy_s:0.772987425327301\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.666\n",
            "c_loss:0.5975112915039062\n",
            "cmd_c_loss:0.023654986172914505\n",
            "cmd_t_loss:0.9201070070266724\n",
            "r_loss:0.3166133165359497\n",
            "accuracy_s:0.7798550128936768\n",
            "valid accuracy: 0.666\n",
            "c_loss:0.592301070690155\n",
            "cmd_c_loss:0.02860366366803646\n",
            "cmd_t_loss:0.9597741365432739\n",
            "r_loss:0.30603471398353577\n",
            "accuracy_s:0.7855780124664307\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.68\n",
            "c_loss:0.5873485803604126\n",
            "cmd_c_loss:0.025835543870925903\n",
            "cmd_t_loss:1.0007871389389038\n",
            "r_loss:0.29562491178512573\n",
            "accuracy_s:0.793590247631073\n",
            "valid accuracy: 0.68\n",
            "c_loss:0.581716001033783\n",
            "cmd_c_loss:0.03157386928796768\n",
            "cmd_t_loss:1.0431526899337769\n",
            "r_loss:0.28565123677253723\n",
            "accuracy_s:0.8012208938598633\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.686\n",
            "c_loss:0.576367974281311\n",
            "cmd_c_loss:0.028207579627633095\n",
            "cmd_t_loss:1.0868581533432007\n",
            "r_loss:0.2758682668209076\n",
            "accuracy_s:0.8069438934326172\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.696\n",
            "c_loss:0.5702890157699585\n",
            "cmd_c_loss:0.03469495847821236\n",
            "cmd_t_loss:1.1319236755371094\n",
            "r_loss:0.26654598116874695\n",
            "accuracy_s:0.8126668930053711\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.7\n",
            "c_loss:0.5645213723182678\n",
            "cmd_c_loss:0.030694831162691116\n",
            "cmd_t_loss:1.17833411693573\n",
            "r_loss:0.25743064284324646\n",
            "accuracy_s:0.8172453045845032\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.706\n",
            "c_loss:0.5579724311828613\n",
            "cmd_c_loss:0.03802276775240898\n",
            "cmd_t_loss:1.2260761260986328\n",
            "r_loss:0.24880442023277283\n",
            "accuracy_s:0.8275467157363892\n",
            "valid accuracy: 0.706\n",
            "c_loss:0.5517700910568237\n",
            "cmd_c_loss:0.033400386571884155\n",
            "cmd_t_loss:1.2751375436782837\n",
            "r_loss:0.24038536846637726\n",
            "accuracy_s:0.8313620686531067\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.708\n",
            "c_loss:0.5447292327880859\n",
            "cmd_c_loss:0.04168229177594185\n",
            "cmd_t_loss:1.3255031108856201\n",
            "r_loss:0.23248590528964996\n",
            "accuracy_s:0.8378481268882751\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.718\n",
            "c_loss:0.5380795001983643\n",
            "cmd_c_loss:0.03638554364442825\n",
            "cmd_t_loss:1.3771507740020752\n",
            "r_loss:0.224784255027771\n",
            "accuracy_s:0.8473864793777466\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.722\n",
            "c_loss:0.5305365324020386\n",
            "cmd_c_loss:0.0457153394818306\n",
            "cmd_t_loss:1.430039882659912\n",
            "r_loss:0.21762903034687042\n",
            "accuracy_s:0.8492941856384277\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.734\n",
            "c_loss:0.5234327912330627\n",
            "cmd_c_loss:0.03964754566550255\n",
            "cmd_t_loss:1.4841561317443848\n",
            "r_loss:0.21065792441368103\n",
            "accuracy_s:0.8557802438735962\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.744\n",
            "c_loss:0.5153920650482178\n",
            "cmd_c_loss:0.05010441318154335\n",
            "cmd_t_loss:1.5394665002822876\n",
            "r_loss:0.20425137877464294\n",
            "accuracy_s:0.8618847727775574\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.75\n",
            "c_loss:0.5078354477882385\n",
            "cmd_c_loss:0.0431768074631691\n",
            "cmd_t_loss:1.5959421396255493\n",
            "r_loss:0.19801431894302368\n",
            "accuracy_s:0.8691338896751404\n",
            "valid accuracy: 0.746\n",
            "c_loss:0.4993129372596741\n",
            "cmd_c_loss:0.05480629950761795\n",
            "cmd_t_loss:1.6535323858261108\n",
            "r_loss:0.1923515498638153\n",
            "accuracy_s:0.8718046545982361\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.754\n",
            "c_loss:0.49132415652275085\n",
            "cmd_c_loss:0.04694748297333717\n",
            "cmd_t_loss:1.7122044563293457\n",
            "r_loss:0.18684165179729462\n",
            "accuracy_s:0.8760015368461609\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.758\n",
            "c_loss:0.4823454022407532\n",
            "cmd_c_loss:0.059790316969156265\n",
            "cmd_t_loss:1.7719484567642212\n",
            "r_loss:0.18191109597682953\n",
            "accuracy_s:0.8790537714958191\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.766\n",
            "c_loss:0.47397443652153015\n",
            "cmd_c_loss:0.05094056576490402\n",
            "cmd_t_loss:1.83272123336792\n",
            "r_loss:0.17711007595062256\n",
            "accuracy_s:0.8832506537437439\n",
            "valid accuracy: 0.756\n",
            "c_loss:0.4645736813545227\n",
            "cmd_c_loss:0.06516019254922867\n",
            "cmd_t_loss:1.8944919109344482\n",
            "r_loss:0.17288386821746826\n",
            "accuracy_s:0.8840137124061584\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.772\n",
            "c_loss:0.4558980166912079\n",
            "cmd_c_loss:0.05521634593605995\n",
            "cmd_t_loss:1.9572253227233887\n",
            "r_loss:0.16875973343849182\n",
            "accuracy_s:0.8904998302459717\n",
            "valid accuracy: 0.764\n",
            "c_loss:0.44613200426101685\n",
            "cmd_c_loss:0.07109557092189789\n",
            "cmd_t_loss:2.020885467529297\n",
            "r_loss:0.16518987715244293\n",
            "accuracy_s:0.8882105946540833\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.78\n",
            "c_loss:0.437277227640152\n",
            "cmd_c_loss:0.05980301648378372\n",
            "cmd_t_loss:2.085390090942383\n",
            "r_loss:0.16170024871826172\n",
            "accuracy_s:0.8988935351371765\n",
            "valid accuracy: 0.766\n",
            "c_loss:0.4272637367248535\n",
            "cmd_c_loss:0.07770325243473053\n",
            "cmd_t_loss:2.1507444381713867\n",
            "r_loss:0.15872731804847717\n",
            "accuracy_s:0.8943151235580444\n",
            "valid accuracy: 0.78\n",
            "c_loss:0.4185088276863098\n",
            "cmd_c_loss:0.06467781215906143\n",
            "cmd_t_loss:2.2168757915496826\n",
            "r_loss:0.15581867098808289\n",
            "accuracy_s:0.905761182308197\n",
            "valid accuracy: 0.76\n",
            "c_loss:0.40860623121261597\n",
            "cmd_c_loss:0.08508569747209549\n",
            "cmd_t_loss:2.283710241317749\n",
            "r_loss:0.15337495505809784\n",
            "accuracy_s:0.8969858884811401\n",
            "valid accuracy: 0.776\n",
            "c_loss:0.4007605016231537\n",
            "cmd_c_loss:0.06967714428901672\n",
            "cmd_t_loss:2.3512229919433594\n",
            "r_loss:0.15097717940807343\n",
            "accuracy_s:0.9133918285369873\n",
            "valid accuracy: 0.762\n",
            "c_loss:0.3920980393886566\n",
            "cmd_c_loss:0.09303498268127441\n",
            "cmd_t_loss:2.419351816177368\n",
            "r_loss:0.148984894156456\n",
            "accuracy_s:0.8962228298187256\n",
            "valid accuracy: 0.772\n",
            "c_loss:0.3866104781627655\n",
            "cmd_c_loss:0.07459130883216858\n",
            "cmd_t_loss:2.487993001937866\n",
            "r_loss:0.14702396094799042\n",
            "accuracy_s:0.9076688289642334\n",
            "valid accuracy: 0.752\n",
            "c_loss:0.3794722557067871\n",
            "cmd_c_loss:0.10221153497695923\n",
            "cmd_t_loss:2.5570785999298096\n",
            "r_loss:0.14541570842266083\n",
            "accuracy_s:0.8874475359916687\n",
            "valid accuracy: 0.778\n",
            "c_loss:0.37449729442596436\n",
            "cmd_c_loss:0.0794682726264\n",
            "cmd_t_loss:2.6265718936920166\n",
            "r_loss:0.1438041627407074\n",
            "accuracy_s:0.905761182308197\n",
            "valid accuracy: 0.758\n",
            "c_loss:0.3650219738483429\n",
            "cmd_c_loss:0.11164641380310059\n",
            "cmd_t_loss:2.6963720321655273\n",
            "r_loss:0.14251354336738586\n",
            "accuracy_s:0.8885921239852905\n",
            "valid accuracy: 0.778\n",
            "c_loss:0.3580436706542969\n",
            "cmd_c_loss:0.08198036998510361\n",
            "cmd_t_loss:2.7663979530334473\n",
            "r_loss:0.1411748230457306\n",
            "accuracy_s:0.91301029920578\n",
            "valid accuracy: 0.768\n",
            "c_loss:0.3469451665878296\n",
            "cmd_c_loss:0.12099893391132355\n",
            "cmd_t_loss:2.8365602493286133\n",
            "r_loss:0.14013415575027466\n",
            "accuracy_s:0.8985120058059692\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.782\n",
            "c_loss:0.3399789035320282\n",
            "cmd_c_loss:0.0853254571557045\n",
            "cmd_t_loss:2.9067697525024414\n",
            "r_loss:0.13901039958000183\n",
            "accuracy_s:0.9164441227912903\n",
            "valid accuracy: 0.778\n",
            "c_loss:0.3291679620742798\n",
            "cmd_c_loss:0.13185766339302063\n",
            "cmd_t_loss:2.9769341945648193\n",
            "r_loss:0.13816797733306885\n",
            "accuracy_s:0.9065242409706116\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.788\n",
            "c_loss:0.3233833611011505\n",
            "cmd_c_loss:0.08995002508163452\n",
            "cmd_t_loss:3.0469777584075928\n",
            "r_loss:0.13720987737178802\n",
            "accuracy_s:0.9248378276824951\n",
            "valid accuracy: 0.78\n",
            "c_loss:0.3132908344268799\n",
            "cmd_c_loss:0.14250317215919495\n",
            "cmd_t_loss:3.116736650466919\n",
            "r_loss:0.13651727139949799\n",
            "accuracy_s:0.9114841818809509\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.792\n",
            "c_loss:0.30862370133399963\n",
            "cmd_c_loss:0.09500797092914581\n",
            "cmd_t_loss:3.186201572418213\n",
            "r_loss:0.13569851219654083\n",
            "accuracy_s:0.9282716512680054\n",
            "valid accuracy: 0.786\n",
            "c_loss:0.29920774698257446\n",
            "cmd_c_loss:0.15352821350097656\n",
            "cmd_t_loss:3.255223512649536\n",
            "r_loss:0.13512931764125824\n",
            "accuracy_s:0.9168256521224976\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.802\n",
            "c_loss:0.2954165041446686\n",
            "cmd_c_loss:0.10035661607980728\n",
            "cmd_t_loss:3.3237040042877197\n",
            "r_loss:0.1344154179096222\n",
            "accuracy_s:0.9290347099304199\n",
            "valid accuracy: 0.786\n",
            "c_loss:0.28646016120910645\n",
            "cmd_c_loss:0.164548859000206\n",
            "cmd_t_loss:3.391538381576538\n",
            "r_loss:0.13396026194095612\n",
            "accuracy_s:0.9198778867721558\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.806\n",
            "c_loss:0.2835623025894165\n",
            "cmd_c_loss:0.10603426396846771\n",
            "cmd_t_loss:3.4586093425750732\n",
            "r_loss:0.13332544267177582\n",
            "accuracy_s:0.9309424161911011\n",
            "valid accuracy: 0.792\n",
            "c_loss:0.27497050166130066\n",
            "cmd_c_loss:0.17658664286136627\n",
            "cmd_t_loss:3.5248539447784424\n",
            "r_loss:0.13297869265079498\n",
            "accuracy_s:0.9225486516952515\n",
            "valid accuracy: 0.802\n",
            "c_loss:0.2731213867664337\n",
            "cmd_c_loss:0.11298663914203644\n",
            "cmd_t_loss:3.590109348297119\n",
            "r_loss:0.13240790367126465\n",
            "accuracy_s:0.930560827255249\n",
            "valid accuracy: 0.794\n",
            "c_loss:0.26445189118385315\n",
            "cmd_c_loss:0.18731148540973663\n",
            "cmd_t_loss:3.65427303314209\n",
            "r_loss:0.13215641677379608\n",
            "accuracy_s:0.9252193570137024\n",
            "valid accuracy: 0.802\n",
            "c_loss:0.2634505033493042\n",
            "cmd_c_loss:0.11746327579021454\n",
            "cmd_t_loss:3.71732234954834\n",
            "r_loss:0.13164907693862915\n",
            "accuracy_s:0.9317054748535156\n",
            "valid accuracy: 0.794\n",
            "c_loss:0.254344642162323\n",
            "cmd_c_loss:0.19464373588562012\n",
            "cmd_t_loss:3.7791664600372314\n",
            "r_loss:0.13146354258060455\n",
            "accuracy_s:0.9282716512680054\n",
            "valid accuracy: 0.802\n",
            "c_loss:0.2530682384967804\n",
            "cmd_c_loss:0.12087011337280273\n",
            "cmd_t_loss:3.8397374153137207\n",
            "r_loss:0.1310003250837326\n",
            "accuracy_s:0.9332315921783447\n",
            "valid accuracy: 0.79\n",
            "c_loss:0.24364125728607178\n",
            "cmd_c_loss:0.20455676317214966\n",
            "cmd_t_loss:3.89898681640625\n",
            "r_loss:0.13086137175559998\n",
            "accuracy_s:0.9301792979240417\n",
            "valid accuracy: 0.802\n",
            "c_loss:0.2408038079738617\n",
            "cmd_c_loss:0.1257065385580063\n",
            "cmd_t_loss:3.9568986892700195\n",
            "r_loss:0.13044841587543488\n",
            "accuracy_s:0.9393361210823059\n",
            "valid accuracy: 0.792\n",
            "c_loss:0.23095731437206268\n",
            "cmd_c_loss:0.2150343656539917\n",
            "cmd_t_loss:4.013427734375\n",
            "r_loss:0.13034291565418243\n",
            "accuracy_s:0.9362838864326477\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.808\n",
            "c_loss:0.22639793157577515\n",
            "cmd_c_loss:0.1293172389268875\n",
            "cmd_t_loss:4.068464756011963\n",
            "r_loss:0.12998338043689728\n",
            "accuracy_s:0.9465852975845337\n",
            "valid accuracy: 0.804\n",
            "c_loss:0.21684910356998444\n",
            "cmd_c_loss:0.22532865405082703\n",
            "cmd_t_loss:4.122108459472656\n",
            "r_loss:0.12990835309028625\n",
            "accuracy_s:0.943914532661438\n",
            "valid accuracy: 0.808\n",
            "c_loss:0.21162749826908112\n",
            "cmd_c_loss:0.1319272518157959\n",
            "cmd_t_loss:4.174260139465332\n",
            "r_loss:0.12958665192127228\n",
            "accuracy_s:0.9500190615653992\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.81\n",
            "c_loss:0.20284312963485718\n",
            "cmd_c_loss:0.23430967330932617\n",
            "cmd_t_loss:4.2248640060424805\n",
            "r_loss:0.12953801453113556\n",
            "accuracy_s:0.9504005908966064\n",
            "valid accuracy: 0.81\n",
            "c_loss:0.19799299538135529\n",
            "cmd_c_loss:0.13329295814037323\n",
            "cmd_t_loss:4.2741007804870605\n",
            "r_loss:0.12925055623054504\n",
            "accuracy_s:0.9553605318069458\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.814\n",
            "c_loss:0.19044961035251617\n",
            "cmd_c_loss:0.24229921400547028\n",
            "cmd_t_loss:4.321854591369629\n",
            "r_loss:0.12922778725624084\n",
            "accuracy_s:0.9561235904693604\n",
            "valid accuracy: 0.814\n",
            "c_loss:0.18653278052806854\n",
            "cmd_c_loss:0.13713794946670532\n",
            "cmd_t_loss:4.36808967590332\n",
            "r_loss:0.12894850969314575\n",
            "accuracy_s:0.9607020020484924\n",
            "valid accuracy: 0.812\n",
            "c_loss:0.18062368035316467\n",
            "cmd_c_loss:0.25076785683631897\n",
            "cmd_t_loss:4.4129958152771\n",
            "r_loss:0.12894460558891296\n",
            "accuracy_s:0.958794355392456\n",
            "valid accuracy: 0.81\n",
            "c_loss:0.17885571718215942\n",
            "cmd_c_loss:0.13708122074604034\n",
            "cmd_t_loss:4.456431865692139\n",
            "r_loss:0.12869574129581451\n",
            "accuracy_s:0.9633727669715881\n",
            "valid accuracy: 0.808\n",
            "c_loss:0.1761237382888794\n",
            "cmd_c_loss:0.2526279091835022\n",
            "cmd_t_loss:4.4984893798828125\n",
            "r_loss:0.1286952793598175\n",
            "accuracy_s:0.9595574140548706\n",
            "valid accuracy: 0.804\n",
            "c_loss:0.17847970128059387\n",
            "cmd_c_loss:0.1402733325958252\n",
            "cmd_t_loss:4.539255142211914\n",
            "r_loss:0.12844347953796387\n",
            "accuracy_s:0.958794355392456\n",
            "valid accuracy: 0.802\n",
            "c_loss:0.17896421253681183\n",
            "cmd_c_loss:0.2582986056804657\n",
            "cmd_t_loss:4.578627586364746\n",
            "r_loss:0.12850578129291534\n",
            "accuracy_s:0.9545974731445312\n",
            "valid accuracy: 0.8\n",
            "c_loss:0.18863442540168762\n",
            "cmd_c_loss:0.13513241708278656\n",
            "cmd_t_loss:4.616846084594727\n",
            "r_loss:0.12821069359779358\n",
            "accuracy_s:0.9473483562469482\n",
            "valid accuracy: 0.79\n",
            "c_loss:0.19011475145816803\n",
            "cmd_c_loss:0.2466193437576294\n",
            "cmd_t_loss:4.6539201736450195\n",
            "r_loss:0.12837539613246918\n",
            "accuracy_s:0.9370469450950623\n",
            "valid accuracy: 0.79\n",
            "c_loss:0.205240860581398\n",
            "cmd_c_loss:0.1342659741640091\n",
            "cmd_t_loss:4.689821720123291\n",
            "r_loss:0.12804658710956573\n",
            "accuracy_s:0.9309424161911011\n",
            "valid accuracy: 0.778\n",
            "c_loss:0.19115816056728363\n",
            "cmd_c_loss:0.2435525357723236\n",
            "cmd_t_loss:4.724757671356201\n",
            "r_loss:0.1282115876674652\n",
            "accuracy_s:0.9359023571014404\n",
            "valid accuracy: 0.8\n",
            "c_loss:0.17288321256637573\n",
            "cmd_c_loss:0.13178889453411102\n",
            "cmd_t_loss:4.758480072021484\n",
            "r_loss:0.12782905995845795\n",
            "accuracy_s:0.9557420611381531\n",
            "valid accuracy: 0.806\n",
            "c_loss:0.14080403745174408\n",
            "cmd_c_loss:0.2432745397090912\n",
            "cmd_t_loss:4.7916259765625\n",
            "r_loss:0.12780646979808807\n",
            "accuracy_s:0.9725295901298523\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.832\n",
            "c_loss:0.122683085501194\n",
            "cmd_c_loss:0.14091351628303528\n",
            "cmd_t_loss:4.823819637298584\n",
            "r_loss:0.1276242434978485\n",
            "accuracy_s:0.9881724715232849\n",
            "valid accuracy: 0.822\n",
            "c_loss:0.11567564308643341\n",
            "cmd_c_loss:0.23898935317993164\n",
            "cmd_t_loss:4.8549299240112305\n",
            "r_loss:0.12743093073368073\n",
            "accuracy_s:0.9881724715232849\n",
            "valid accuracy: 0.8\n",
            "c_loss:0.11358301341533661\n",
            "cmd_c_loss:0.13873238861560822\n",
            "cmd_t_loss:4.8856024742126465\n",
            "r_loss:0.12738396227359772\n",
            "accuracy_s:0.9919877648353577\n",
            "valid accuracy: 0.824\n",
            "c_loss:0.11052630841732025\n",
            "cmd_c_loss:0.24633091688156128\n",
            "cmd_t_loss:4.915411949157715\n",
            "r_loss:0.1271613985300064\n",
            "accuracy_s:0.9904616475105286\n",
            "valid accuracy: 0.804\n",
            "c_loss:0.10853085666894913\n",
            "cmd_c_loss:0.1356402188539505\n",
            "cmd_t_loss:4.944477558135986\n",
            "r_loss:0.1271204650402069\n",
            "accuracy_s:0.9923693537712097\n",
            "valid accuracy: 0.82\n",
            "c_loss:0.10710378736257553\n",
            "cmd_c_loss:0.23813313245773315\n",
            "cmd_t_loss:4.972898006439209\n",
            "r_loss:0.1269444227218628\n",
            "accuracy_s:0.9912247061729431\n",
            "valid accuracy: 0.814\n",
            "c_loss:0.10524912923574448\n",
            "cmd_c_loss:0.14767195284366608\n",
            "cmd_t_loss:5.00098991394043\n",
            "r_loss:0.12691928446292877\n",
            "accuracy_s:0.9931324124336243\n",
            "valid accuracy: 0.81\n",
            "c_loss:0.1059894934296608\n",
            "cmd_c_loss:0.23693300783634186\n",
            "cmd_t_loss:5.02763557434082\n",
            "r_loss:0.12680277228355408\n",
            "accuracy_s:0.9919877648353577\n",
            "valid accuracy: 0.826\n",
            "c_loss:0.10512348264455795\n",
            "cmd_c_loss:0.14987429976463318\n",
            "cmd_t_loss:5.0549726486206055\n",
            "r_loss:0.12681271135807037\n",
            "accuracy_s:0.9923693537712097\n",
            "valid accuracy: 0.814\n",
            "c_loss:0.10184764862060547\n",
            "cmd_c_loss:0.23128415644168854\n",
            "cmd_t_loss:5.080718517303467\n",
            "r_loss:0.12676642835140228\n",
            "accuracy_s:0.9935139417648315\n",
            "valid accuracy: 0.83\n",
            "c_loss:0.10676935315132141\n",
            "cmd_c_loss:0.14571286737918854\n",
            "cmd_t_loss:5.1065473556518555\n",
            "r_loss:0.12681303918361664\n",
            "accuracy_s:0.9919877648353577\n",
            "valid accuracy: 0.814\n",
            "c_loss:0.10933839529752731\n",
            "cmd_c_loss:0.24192872643470764\n",
            "cmd_t_loss:5.131071090698242\n",
            "r_loss:0.1268438696861267\n",
            "accuracy_s:0.9893170595169067\n",
            "valid accuracy: 0.808\n",
            "c_loss:0.12422049045562744\n",
            "cmd_c_loss:0.1450449377298355\n",
            "cmd_t_loss:5.156719207763672\n",
            "r_loss:0.12678848206996918\n",
            "accuracy_s:0.974818766117096\n",
            "valid accuracy: 0.796\n",
            "c_loss:0.1497778743505478\n",
            "cmd_c_loss:0.24154816567897797\n",
            "cmd_t_loss:5.1791276931762695\n",
            "r_loss:0.1268807053565979\n",
            "accuracy_s:0.9568867087364197\n",
            "valid accuracy: 0.764\n",
            "c_loss:0.23016555607318878\n",
            "cmd_c_loss:0.14883658289909363\n",
            "cmd_t_loss:5.203960418701172\n",
            "r_loss:0.12716816365718842\n",
            "accuracy_s:0.8969858884811401\n",
            "valid accuracy: 0.744\n",
            "c_loss:0.2901049554347992\n",
            "cmd_c_loss:0.20613348484039307\n",
            "cmd_t_loss:5.223642349243164\n",
            "r_loss:0.12745659053325653\n",
            "accuracy_s:0.8588324785232544\n",
            "valid accuracy: 0.706\n",
            "c_loss:0.2868775725364685\n",
            "cmd_c_loss:0.15021543204784393\n",
            "cmd_t_loss:5.247957706451416\n",
            "r_loss:0.12762537598609924\n",
            "accuracy_s:0.8653185963630676\n",
            "valid accuracy: 0.766\n",
            "c_loss:0.1366814374923706\n",
            "cmd_c_loss:0.19793929159641266\n",
            "cmd_t_loss:5.26295280456543\n",
            "r_loss:0.12809690833091736\n",
            "accuracy_s:0.9679511785507202\n",
            "valid accuracy: 0.816\n",
            "c_loss:0.08284096419811249\n",
            "cmd_c_loss:0.14145082235336304\n",
            "cmd_t_loss:5.287081718444824\n",
            "r_loss:0.12825194001197815\n",
            "accuracy_s:0.9931324124336243\n",
            "valid accuracy: 0.816\n",
            "c_loss:0.07933009415864944\n",
            "cmd_c_loss:0.15365037322044373\n",
            "cmd_t_loss:5.2963175773620605\n",
            "r_loss:0.12826350331306458\n",
            "accuracy_s:0.9946585297584534\n",
            "best_result:0.8320000171661377\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_common_0_to_1.pkl\n",
            "test_accuracy:0.7987483739852905\n",
            "Train target model...\n",
            "t_loss:0.7430464625358582\n",
            "cmd_c_loss:0.09896921366453171\n",
            "cmd_t_loss:0.09363710135221481\n",
            "r_loss:0.8194661736488342\n",
            "accuracy_t:0.5024154782295227\n",
            "t_loss:0.737173855304718\n",
            "cmd_c_loss:0.09639938920736313\n",
            "cmd_t_loss:0.09628624469041824\n",
            "r_loss:0.8161803483963013\n",
            "accuracy_t:0.5056360960006714\n",
            "t_loss:0.7313789129257202\n",
            "cmd_c_loss:0.09369195997714996\n",
            "cmd_t_loss:0.09908849745988846\n",
            "r_loss:0.8127391934394836\n",
            "accuracy_t:0.510466992855072\n",
            "t_loss:0.7256742715835571\n",
            "cmd_c_loss:0.09083984792232513\n",
            "cmd_t_loss:0.1020522266626358\n",
            "r_loss:0.809136152267456\n",
            "accuracy_t:0.510466992855072\n",
            "t_loss:0.7200708389282227\n",
            "cmd_c_loss:0.08783531934022903\n",
            "cmd_t_loss:0.10518591850996017\n",
            "r_loss:0.8053648471832275\n",
            "accuracy_t:0.5169082283973694\n",
            "t_loss:0.7145773768424988\n",
            "cmd_c_loss:0.08467048406600952\n",
            "cmd_t_loss:0.10849860310554504\n",
            "r_loss:0.8014189600944519\n",
            "accuracy_t:0.512077271938324\n",
            "t_loss:0.7092004418373108\n",
            "cmd_c_loss:0.08133704215288162\n",
            "cmd_t_loss:0.11199935525655746\n",
            "r_loss:0.7972916960716248\n",
            "accuracy_t:0.512077271938324\n",
            "t_loss:0.7039440870285034\n",
            "cmd_c_loss:0.07782599329948425\n",
            "cmd_t_loss:0.11569809168577194\n",
            "r_loss:0.7929763197898865\n",
            "accuracy_t:0.5136876106262207\n",
            "t_loss:0.6988095045089722\n",
            "cmd_c_loss:0.07412838935852051\n",
            "cmd_t_loss:0.11960461735725403\n",
            "r_loss:0.7884660959243774\n",
            "accuracy_t:0.5265700221061707\n",
            "t_loss:0.6937949061393738\n",
            "cmd_c_loss:0.07023455202579498\n",
            "cmd_t_loss:0.12372913956642151\n",
            "r_loss:0.7837542295455933\n",
            "accuracy_t:0.5378422141075134\n",
            "t_loss:0.6888957619667053\n",
            "cmd_c_loss:0.0661344900727272\n",
            "cmd_t_loss:0.12808272242546082\n",
            "r_loss:0.7788341641426086\n",
            "accuracy_t:0.5378422141075134\n",
            "t_loss:0.6841041445732117\n",
            "cmd_c_loss:0.0618174783885479\n",
            "cmd_t_loss:0.13267719745635986\n",
            "r_loss:0.773698627948761\n",
            "accuracy_t:0.5507246255874634\n",
            "t_loss:0.6794105172157288\n",
            "cmd_c_loss:0.057272836565971375\n",
            "cmd_t_loss:0.1375228464603424\n",
            "r_loss:0.7683413624763489\n",
            "accuracy_t:0.5636070966720581\n",
            "t_loss:0.6748009920120239\n",
            "cmd_c_loss:0.052489329129457474\n",
            "cmd_t_loss:0.14263403415679932\n",
            "r_loss:0.7627555727958679\n",
            "accuracy_t:0.5700483322143555\n",
            "t_loss:0.6702603101730347\n",
            "cmd_c_loss:0.04745519533753395\n",
            "cmd_t_loss:0.14802329242229462\n",
            "r_loss:0.756935179233551\n",
            "accuracy_t:0.5748792290687561\n",
            "t_loss:0.6657705307006836\n",
            "cmd_c_loss:0.04215845465660095\n",
            "cmd_t_loss:0.15370501577854156\n",
            "r_loss:0.7508738040924072\n",
            "accuracy_t:0.5958132147789001\n",
            "t_loss:0.6613133549690247\n",
            "cmd_c_loss:0.036586783826351166\n",
            "cmd_t_loss:0.15969377756118774\n",
            "r_loss:0.7445660829544067\n",
            "accuracy_t:0.6119162440299988\n",
            "t_loss:0.656868040561676\n",
            "cmd_c_loss:0.030728111043572426\n",
            "cmd_t_loss:0.16600452363491058\n",
            "r_loss:0.7380067110061646\n",
            "accuracy_t:0.6231883764266968\n",
            "t_loss:0.6524136662483215\n",
            "cmd_c_loss:0.024571135640144348\n",
            "cmd_t_loss:0.1726507842540741\n",
            "r_loss:0.7311912178993225\n",
            "accuracy_t:0.6457327008247375\n",
            "t_loss:0.6479291915893555\n",
            "cmd_c_loss:0.018106922507286072\n",
            "cmd_t_loss:0.1796499490737915\n",
            "r_loss:0.724116325378418\n",
            "accuracy_t:0.6602254509925842\n",
            "t_loss:0.6433942914009094\n",
            "cmd_c_loss:0.011337177827954292\n",
            "cmd_t_loss:0.18701845407485962\n",
            "r_loss:0.716780960559845\n",
            "accuracy_t:0.6698873043060303\n",
            "t_loss:0.6387878060340881\n",
            "cmd_c_loss:0.006556074135005474\n",
            "cmd_t_loss:0.19477492570877075\n",
            "r_loss:0.7091922760009766\n",
            "accuracy_t:0.684380054473877\n",
            "t_loss:0.6340910792350769\n",
            "cmd_c_loss:0.0119921350851655\n",
            "cmd_t_loss:0.20293793082237244\n",
            "r_loss:0.7011294364929199\n",
            "accuracy_t:0.7053139805793762\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.572\n",
            "t_loss:0.6292860507965088\n",
            "cmd_c_loss:0.006865479983389378\n",
            "cmd_t_loss:0.21152488887310028\n",
            "r_loss:0.692901074886322\n",
            "accuracy_t:0.7326892018318176\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.574\n",
            "t_loss:0.6243560910224915\n",
            "cmd_c_loss:0.01243680715560913\n",
            "cmd_t_loss:0.2205563634634018\n",
            "r_loss:0.6843696236610413\n",
            "accuracy_t:0.739130437374115\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.58\n",
            "t_loss:0.6192855834960938\n",
            "cmd_c_loss:0.007368740625679493\n",
            "cmd_t_loss:0.2300540804862976\n",
            "r_loss:0.6754788756370544\n",
            "accuracy_t:0.7520129084587097\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.59\n",
            "t_loss:0.6140607595443726\n",
            "cmd_c_loss:0.012705551460385323\n",
            "cmd_t_loss:0.24004089832305908\n",
            "r_loss:0.6664587259292603\n",
            "accuracy_t:0.7648953199386597\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.592\n",
            "t_loss:0.6086699962615967\n",
            "cmd_c_loss:0.008054802194237709\n",
            "cmd_t_loss:0.25053635239601135\n",
            "r_loss:0.6569278240203857\n",
            "accuracy_t:0.772946834564209\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.596\n",
            "t_loss:0.603103518486023\n",
            "cmd_c_loss:0.012876948341727257\n",
            "cmd_t_loss:0.26156386733055115\n",
            "r_loss:0.6474043130874634\n",
            "accuracy_t:0.782608687877655\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.602\n",
            "t_loss:0.5973526239395142\n",
            "cmd_c_loss:0.00889564584940672\n",
            "cmd_t_loss:0.2731468379497528\n",
            "r_loss:0.6372663378715515\n",
            "accuracy_t:0.7922705411911011\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.604\n",
            "t_loss:0.5914103984832764\n",
            "cmd_c_loss:0.013000101782381535\n",
            "cmd_t_loss:0.2853066325187683\n",
            "r_loss:0.6272410750389099\n",
            "accuracy_t:0.7954911589622498\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.606\n",
            "t_loss:0.5852705836296082\n",
            "cmd_c_loss:0.009867922402918339\n",
            "cmd_t_loss:0.2980712652206421\n",
            "r_loss:0.6165338754653931\n",
            "accuracy_t:0.8019323945045471\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.61\n",
            "t_loss:0.578926682472229\n",
            "cmd_c_loss:0.013108340092003345\n",
            "cmd_t_loss:0.31146571040153503\n",
            "r_loss:0.6060240268707275\n",
            "accuracy_t:0.8099839091300964\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.614\n",
            "t_loss:0.5723760724067688\n",
            "cmd_c_loss:0.010953802615404129\n",
            "cmd_t_loss:0.325516015291214\n",
            "r_loss:0.594791829586029\n",
            "accuracy_t:0.8196457624435425\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.616\n",
            "t_loss:0.5656161904335022\n",
            "cmd_c_loss:0.013228558003902435\n",
            "cmd_t_loss:0.3402465283870697\n",
            "r_loss:0.5838274359703064\n",
            "accuracy_t:0.8293075561523438\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.62\n",
            "t_loss:0.5586439371109009\n",
            "cmd_c_loss:0.012139413505792618\n",
            "cmd_t_loss:0.35568419098854065\n",
            "r_loss:0.5721253752708435\n",
            "accuracy_t:0.8421900272369385\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.622\n",
            "t_loss:0.5514574646949768\n",
            "cmd_c_loss:0.013383585959672928\n",
            "cmd_t_loss:0.37185612320899963\n",
            "r_loss:0.5607532262802124\n",
            "accuracy_t:0.8599033951759338\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.628\n",
            "t_loss:0.544054388999939\n",
            "cmd_c_loss:0.013414459303021431\n",
            "cmd_t_loss:0.38878822326660156\n",
            "r_loss:0.5486468076705933\n",
            "accuracy_t:0.8776167631149292\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.63\n",
            "t_loss:0.5364343523979187\n",
            "cmd_c_loss:0.013594145886600018\n",
            "cmd_t_loss:0.4065036475658417\n",
            "r_loss:0.5369246006011963\n",
            "accuracy_t:0.8921095132827759\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.632\n",
            "t_loss:0.5285959243774414\n",
            "cmd_c_loss:0.014770125970244408\n",
            "cmd_t_loss:0.4250311851501465\n",
            "r_loss:0.5244912505149841\n",
            "accuracy_t:0.9017713069915771\n",
            "valid accuracy: 0.632\n",
            "t_loss:0.5205393433570862\n",
            "cmd_c_loss:0.013880225829780102\n",
            "cmd_t_loss:0.4443996548652649\n",
            "r_loss:0.5124891996383667\n",
            "accuracy_t:0.9066022634506226\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.634\n",
            "t_loss:0.5122656226158142\n",
            "cmd_c_loss:0.016200343146920204\n",
            "cmd_t_loss:0.464633047580719\n",
            "r_loss:0.49981579184532166\n",
            "accuracy_t:0.9130434989929199\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.638\n",
            "t_loss:0.5037767887115479\n",
            "cmd_c_loss:0.014261294156312943\n",
            "cmd_t_loss:0.4857581555843353\n",
            "r_loss:0.4876205623149872\n",
            "accuracy_t:0.9178743958473206\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.646\n",
            "t_loss:0.4950752258300781\n",
            "cmd_c_loss:0.01770227961242199\n",
            "cmd_t_loss:0.5077972412109375\n",
            "r_loss:0.4748080372810364\n",
            "accuracy_t:0.9259259104728699\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.65\n",
            "t_loss:0.48616188764572144\n",
            "cmd_c_loss:0.014756674878299236\n",
            "cmd_t_loss:0.5307809114456177\n",
            "r_loss:0.462515652179718\n",
            "accuracy_t:0.9355877637863159\n",
            "valid accuracy: 0.65\n",
            "t_loss:0.47703829407691956\n",
            "cmd_c_loss:0.01927594095468521\n",
            "cmd_t_loss:0.5547257661819458\n",
            "r_loss:0.44967079162597656\n",
            "accuracy_t:0.9436392784118652\n",
            "valid accuracy: 0.648\n",
            "t_loss:0.4677089750766754\n",
            "cmd_c_loss:0.01538605336099863\n",
            "cmd_t_loss:0.579659640789032\n",
            "r_loss:0.43738433718681335\n",
            "accuracy_t:0.9500805139541626\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.652\n",
            "t_loss:0.45818063616752625\n",
            "cmd_c_loss:0.020923957228660583\n",
            "cmd_t_loss:0.6055997610092163\n",
            "r_loss:0.42461925745010376\n",
            "accuracy_t:0.95652174949646\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.658\n",
            "t_loss:0.44845762848854065\n",
            "cmd_c_loss:0.016169829294085503\n",
            "cmd_t_loss:0.6325681805610657\n",
            "r_loss:0.4124468266963959\n",
            "accuracy_t:0.9597423672676086\n",
            "valid accuracy: 0.656\n",
            "t_loss:0.4385472238063812\n",
            "cmd_c_loss:0.022650068625807762\n",
            "cmd_t_loss:0.660577654838562\n",
            "r_loss:0.3998737633228302\n",
            "accuracy_t:0.9629629850387573\n",
            "valid accuracy: 0.656\n",
            "t_loss:0.4284586012363434\n",
            "cmd_c_loss:0.017127662897109985\n",
            "cmd_t_loss:0.6896635890007019\n",
            "r_loss:0.3879197835922241\n",
            "accuracy_t:0.967793881893158\n",
            "valid accuracy: 0.654\n",
            "t_loss:0.41820016503334045\n",
            "cmd_c_loss:0.024462252855300903\n",
            "cmd_t_loss:0.7198402881622314\n",
            "r_loss:0.3756435215473175\n",
            "accuracy_t:0.9694041609764099\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.66\n",
            "t_loss:0.40778419375419617\n",
            "cmd_c_loss:0.018282737582921982\n",
            "cmd_t_loss:0.751126229763031\n",
            "r_loss:0.3640083968639374\n",
            "accuracy_t:0.9758453965187073\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.668\n",
            "t_loss:0.39722543954849243\n",
            "cmd_c_loss:0.026374874636530876\n",
            "cmd_t_loss:0.783531904220581\n",
            "r_loss:0.35213160514831543\n",
            "accuracy_t:0.9758453965187073\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.672\n",
            "t_loss:0.3865375220775604\n",
            "cmd_c_loss:0.01966649480164051\n",
            "cmd_t_loss:0.8170814514160156\n",
            "r_loss:0.3409090042114258\n",
            "accuracy_t:0.979066014289856\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.674\n",
            "t_loss:0.3757355809211731\n",
            "cmd_c_loss:0.02841845713555813\n",
            "cmd_t_loss:0.8517829179763794\n",
            "r_loss:0.3295242190361023\n",
            "accuracy_t:0.9838969111442566\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.676\n",
            "t_loss:0.3648410141468048\n",
            "cmd_c_loss:0.021334581077098846\n",
            "cmd_t_loss:0.8876504898071289\n",
            "r_loss:0.318798303604126\n",
            "accuracy_t:0.9855072498321533\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.686\n",
            "t_loss:0.3538743555545807\n",
            "cmd_c_loss:0.030697932466864586\n",
            "cmd_t_loss:0.9246982932090759\n",
            "r_loss:0.3079858124256134\n",
            "accuracy_t:0.9871175289154053\n",
            "valid accuracy: 0.686\n",
            "t_loss:0.34286031126976013\n",
            "cmd_c_loss:0.023455800488591194\n",
            "cmd_t_loss:0.9629420638084412\n",
            "r_loss:0.29783034324645996\n",
            "accuracy_t:0.9871175289154053\n",
            "valid accuracy: 0.686\n",
            "t_loss:0.3318236172199249\n",
            "cmd_c_loss:0.03356587514281273\n",
            "cmd_t_loss:1.0023974180221558\n",
            "r_loss:0.287653386592865\n",
            "accuracy_t:0.988727867603302\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.688\n",
            "t_loss:0.32077887654304504\n",
            "cmd_c_loss:0.026119275018572807\n",
            "cmd_t_loss:1.04305899143219\n",
            "r_loss:0.27812623977661133\n",
            "accuracy_t:0.990338146686554\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.692\n",
            "t_loss:0.3097592294216156\n",
            "cmd_c_loss:0.0368352048099041\n",
            "cmd_t_loss:1.0849441289901733\n",
            "r_loss:0.2686275243759155\n",
            "accuracy_t:0.990338146686554\n",
            "valid accuracy: 0.692\n",
            "t_loss:0.2987976670265198\n",
            "cmd_c_loss:0.029022006317973137\n",
            "cmd_t_loss:1.1280580759048462\n",
            "r_loss:0.2597762644290924\n",
            "accuracy_t:0.990338146686554\n",
            "valid accuracy: 0.688\n",
            "t_loss:0.2879182696342468\n",
            "cmd_c_loss:0.04032856598496437\n",
            "cmd_t_loss:1.1723980903625488\n",
            "r_loss:0.2509891986846924\n",
            "accuracy_t:0.9919484853744507\n",
            "valid accuracy: 0.686\n",
            "t_loss:0.2771526873111725\n",
            "cmd_c_loss:0.0321764275431633\n",
            "cmd_t_loss:1.217962384223938\n",
            "r_loss:0.2428465038537979\n",
            "accuracy_t:0.9919484853744507\n",
            "valid accuracy: 0.688\n",
            "t_loss:0.2665291130542755\n",
            "cmd_c_loss:0.04394511133432388\n",
            "cmd_t_loss:1.264744758605957\n",
            "r_loss:0.23479194939136505\n",
            "accuracy_t:0.9919484853744507\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.694\n",
            "t_loss:0.2560829818248749\n",
            "cmd_c_loss:0.035495612770318985\n",
            "cmd_t_loss:1.3127446174621582\n",
            "r_loss:0.2273741513490677\n",
            "accuracy_t:0.9919484853744507\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.702\n",
            "t_loss:0.24582946300506592\n",
            "cmd_c_loss:0.04763682931661606\n",
            "cmd_t_loss:1.3619362115859985\n",
            "r_loss:0.2200659215450287\n",
            "accuracy_t:0.9919484853744507\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.708\n",
            "t_loss:0.23580782115459442\n",
            "cmd_c_loss:0.03907112404704094\n",
            "cmd_t_loss:1.4123069047927856\n",
            "r_loss:0.2133740931749344\n",
            "accuracy_t:0.9919484853744507\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.712\n",
            "t_loss:0.22602345049381256\n",
            "cmd_c_loss:0.05160433053970337\n",
            "cmd_t_loss:1.4638413190841675\n",
            "r_loss:0.20681340992450714\n",
            "accuracy_t:0.9935587644577026\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.716\n",
            "t_loss:0.21651221811771393\n",
            "cmd_c_loss:0.04310794547200203\n",
            "cmd_t_loss:1.5165150165557861\n",
            "r_loss:0.2008427083492279\n",
            "accuracy_t:0.9935587644577026\n",
            "valid accuracy: 0.714\n",
            "t_loss:0.2072969377040863\n",
            "cmd_c_loss:0.05600356310606003\n",
            "cmd_t_loss:1.5703150033950806\n",
            "r_loss:0.1950223594903946\n",
            "accuracy_t:0.9951691031455994\n",
            "valid accuracy: 0.716\n",
            "t_loss:0.19838571548461914\n",
            "cmd_c_loss:0.04764575511217117\n",
            "cmd_t_loss:1.6252110004425049\n",
            "r_loss:0.18975360691547394\n",
            "accuracy_t:0.9951691031455994\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.72\n",
            "t_loss:0.18980467319488525\n",
            "cmd_c_loss:0.060797546058893204\n",
            "cmd_t_loss:1.6811598539352417\n",
            "r_loss:0.18465754389762878\n",
            "accuracy_t:0.998389720916748\n",
            "valid accuracy: 0.72\n",
            "t_loss:0.18156178295612335\n",
            "cmd_c_loss:0.05254640057682991\n",
            "cmd_t_loss:1.738128423690796\n",
            "r_loss:0.18006524443626404\n",
            "accuracy_t:0.998389720916748\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.722\n",
            "t_loss:0.1736554354429245\n",
            "cmd_c_loss:0.06586294621229172\n",
            "cmd_t_loss:1.7960643768310547\n",
            "r_loss:0.1756667196750641\n",
            "accuracy_t:0.998389720916748\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.726\n",
            "t_loss:0.16609829664230347\n",
            "cmd_c_loss:0.057661935687065125\n",
            "cmd_t_loss:1.8549457788467407\n",
            "r_loss:0.1717107743024826\n",
            "accuracy_t:0.998389720916748\n",
            "valid accuracy: 0.724\n",
            "t_loss:0.15889613330364227\n",
            "cmd_c_loss:0.07108604162931442\n",
            "cmd_t_loss:1.9147279262542725\n",
            "r_loss:0.1679742932319641\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.726\n",
            "t_loss:0.1520397961139679\n",
            "cmd_c_loss:0.06292036175727844\n",
            "cmd_t_loss:1.9753731489181519\n",
            "r_loss:0.16460570693016052\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.726\n",
            "t_loss:0.1455269157886505\n",
            "cmd_c_loss:0.07644530385732651\n",
            "cmd_t_loss:2.036823034286499\n",
            "r_loss:0.1614803820848465\n",
            "accuracy_t:1.0\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.728\n",
            "t_loss:0.1393604576587677\n",
            "cmd_c_loss:0.06868791580200195\n",
            "cmd_t_loss:2.0990469455718994\n",
            "r_loss:0.15864020586013794\n",
            "accuracy_t:1.0\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.732\n",
            "t_loss:0.1335267722606659\n",
            "cmd_c_loss:0.0826849564909935\n",
            "cmd_t_loss:2.1619925498962402\n",
            "r_loss:0.15605930984020233\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.732\n",
            "t_loss:0.12802812457084656\n",
            "cmd_c_loss:0.07567816227674484\n",
            "cmd_t_loss:2.2256293296813965\n",
            "r_loss:0.15368421375751495\n",
            "accuracy_t:1.0\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.734\n",
            "t_loss:0.12285557389259338\n",
            "cmd_c_loss:0.08989587426185608\n",
            "cmd_t_loss:2.2899229526519775\n",
            "r_loss:0.15157556533813477\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.73\n",
            "t_loss:0.11799299716949463\n",
            "cmd_c_loss:0.08288777619600296\n",
            "cmd_t_loss:2.354763984680176\n",
            "r_loss:0.14959506690502167\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.728\n",
            "t_loss:0.11343705654144287\n",
            "cmd_c_loss:0.0966811403632164\n",
            "cmd_t_loss:2.4201500415802\n",
            "r_loss:0.14788173139095306\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.726\n",
            "t_loss:0.10917118191719055\n",
            "cmd_c_loss:0.0896856039762497\n",
            "cmd_t_loss:2.486029624938965\n",
            "r_loss:0.14622339606285095\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.722\n",
            "t_loss:0.1051950603723526\n",
            "cmd_c_loss:0.10307381302118301\n",
            "cmd_t_loss:2.5523691177368164\n",
            "r_loss:0.144834965467453\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.718\n",
            "t_loss:0.10148639976978302\n",
            "cmd_c_loss:0.09624908119440079\n",
            "cmd_t_loss:2.619072437286377\n",
            "r_loss:0.14343802630901337\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.714\n",
            "t_loss:0.09803178906440735\n",
            "cmd_c_loss:0.10972116887569427\n",
            "cmd_t_loss:2.6861140727996826\n",
            "r_loss:0.142304927110672\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.712\n",
            "t_loss:0.09483491629362106\n",
            "cmd_c_loss:0.1038881316781044\n",
            "cmd_t_loss:2.7534749507904053\n",
            "r_loss:0.14112214744091034\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.716\n",
            "t_loss:0.09186595678329468\n",
            "cmd_c_loss:0.11779050529003143\n",
            "cmd_t_loss:2.821066379547119\n",
            "r_loss:0.14018411934375763\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.716\n",
            "t_loss:0.08913523703813553\n",
            "cmd_c_loss:0.1123572289943695\n",
            "cmd_t_loss:2.8888397216796875\n",
            "r_loss:0.13917005062103271\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.716\n",
            "t_loss:0.08659827709197998\n",
            "cmd_c_loss:0.12595120072364807\n",
            "cmd_t_loss:2.9567461013793945\n",
            "r_loss:0.13837987184524536\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.716\n",
            "t_loss:0.08429501950740814\n",
            "cmd_c_loss:0.12066655606031418\n",
            "cmd_t_loss:3.0247609615325928\n",
            "r_loss:0.13750357925891876\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.716\n",
            "t_loss:0.08218984305858612\n",
            "cmd_c_loss:0.13410437107086182\n",
            "cmd_t_loss:3.0927960872650146\n",
            "r_loss:0.13683460652828217\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.718\n",
            "t_loss:0.08023159205913544\n",
            "cmd_c_loss:0.12917636334896088\n",
            "cmd_t_loss:3.1607539653778076\n",
            "r_loss:0.13607046008110046\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.722\n",
            "t_loss:0.07846561819314957\n",
            "cmd_c_loss:0.14257952570915222\n",
            "cmd_t_loss:3.2285869121551514\n",
            "r_loss:0.13550090789794922\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.724\n",
            "t_loss:0.07688146084547043\n",
            "cmd_c_loss:0.13794367015361786\n",
            "cmd_t_loss:3.2961273193359375\n",
            "r_loss:0.13483260571956635\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.722\n",
            "t_loss:0.07546711713075638\n",
            "cmd_c_loss:0.15129221975803375\n",
            "cmd_t_loss:3.3634588718414307\n",
            "r_loss:0.1343459039926529\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.724\n",
            "t_loss:0.07418210059404373\n",
            "cmd_c_loss:0.14681309461593628\n",
            "cmd_t_loss:3.430300712585449\n",
            "r_loss:0.1337534785270691\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.724\n",
            "t_loss:0.07308376580476761\n",
            "cmd_c_loss:0.1600656360387802\n",
            "cmd_t_loss:3.4965665340423584\n",
            "r_loss:0.13333705067634583\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.722\n",
            "t_loss:0.07207024097442627\n",
            "cmd_c_loss:0.1556047946214676\n",
            "cmd_t_loss:3.5621862411499023\n",
            "r_loss:0.13281051814556122\n",
            "accuracy_t:1.0\n",
            "best_result:0.734000027179718\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_target_0_to_1.pkl\n",
            "test_accuracy:0.6933465003967285\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_common_0_to_1.pkl\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_target_0_to_1.pkl\n",
            "pos num: 5\n",
            "neg num: 5\n",
            "pos num: 10\n",
            "neg num: 10\n",
            "unlabelled num: 1364\n",
            "1364\n",
            "Train combined model...\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_common_0_to_1.pkl\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_target_0_to_1.pkl\n",
            "valid accuracy: 0.832\n",
            "test accuracy: 0.7987483530961792\n",
            "Train common model...\n",
            "c_loss:0.8010980486869812\n",
            "cmd_c_loss:0.08913227170705795\n",
            "cmd_t_loss:0.10536549240350723\n",
            "r_loss:0.773368775844574\n",
            "accuracy_s:0.4982961118221283\n",
            "c_loss:0.7938885688781738\n",
            "cmd_c_loss:0.08649619668722153\n",
            "cmd_t_loss:0.10799827426671982\n",
            "r_loss:0.7704227566719055\n",
            "accuracy_s:0.49867475032806396\n",
            "c_loss:0.7868027687072754\n",
            "cmd_c_loss:0.08371791243553162\n",
            "cmd_t_loss:0.11077412217855453\n",
            "r_loss:0.7673379778862\n",
            "accuracy_s:0.49791744351387024\n",
            "c_loss:0.7798688411712646\n",
            "cmd_c_loss:0.08078977465629578\n",
            "cmd_t_loss:0.11370058357715607\n",
            "r_loss:0.764109194278717\n",
            "accuracy_s:0.4971601665019989\n",
            "c_loss:0.773114025592804\n",
            "cmd_c_loss:0.07770399749279022\n",
            "cmd_t_loss:0.11678579449653625\n",
            "r_loss:0.7607308030128479\n",
            "accuracy_s:0.4960242211818695\n",
            "c_loss:0.7665644288063049\n",
            "cmd_c_loss:0.07445213198661804\n",
            "cmd_t_loss:0.12003885209560394\n",
            "r_loss:0.757196843624115\n",
            "accuracy_s:0.49450966715812683\n",
            "c_loss:0.7602442502975464\n",
            "cmd_c_loss:0.07102575153112411\n",
            "cmd_t_loss:0.12346828728914261\n",
            "r_loss:0.7535014748573303\n",
            "accuracy_s:0.49450966715812683\n",
            "c_loss:0.7541755437850952\n",
            "cmd_c_loss:0.06741547584533691\n",
            "cmd_t_loss:0.1270836591720581\n",
            "r_loss:0.7496389746665955\n",
            "accuracy_s:0.49640288949012756\n",
            "c_loss:0.74837726354599\n",
            "cmd_c_loss:0.06361190974712372\n",
            "cmd_t_loss:0.13089537620544434\n",
            "r_loss:0.7456033229827881\n",
            "accuracy_s:0.49640288949012756\n",
            "c_loss:0.7428652048110962\n",
            "cmd_c_loss:0.059605080634355545\n",
            "cmd_t_loss:0.13491380214691162\n",
            "r_loss:0.7413885593414307\n",
            "accuracy_s:0.4941309988498688\n",
            "c_loss:0.7376510500907898\n",
            "cmd_c_loss:0.05538482964038849\n",
            "cmd_t_loss:0.13915006816387177\n",
            "r_loss:0.7369884252548218\n",
            "accuracy_s:0.49526694416999817\n",
            "c_loss:0.7327426671981812\n",
            "cmd_c_loss:0.050940122455358505\n",
            "cmd_t_loss:0.14361627399921417\n",
            "r_loss:0.7323973774909973\n",
            "accuracy_s:0.49526694416999817\n",
            "c_loss:0.7281431555747986\n",
            "cmd_c_loss:0.04626016691327095\n",
            "cmd_t_loss:0.14832401275634766\n",
            "r_loss:0.727609395980835\n",
            "accuracy_s:0.49564558267593384\n",
            "c_loss:0.7238513231277466\n",
            "cmd_c_loss:0.04133329167962074\n",
            "cmd_t_loss:0.1532871127128601\n",
            "r_loss:0.7226187586784363\n",
            "accuracy_s:0.49526694416999817\n",
            "c_loss:0.719861626625061\n",
            "cmd_c_loss:0.03614795580506325\n",
            "cmd_t_loss:0.15851885080337524\n",
            "r_loss:0.7174198627471924\n",
            "accuracy_s:0.4960242211818695\n",
            "c_loss:0.7161639928817749\n",
            "cmd_c_loss:0.030692242085933685\n",
            "cmd_t_loss:0.16403278708457947\n",
            "r_loss:0.7120079398155212\n",
            "accuracy_s:0.49299508333206177\n",
            "c_loss:0.7127447128295898\n",
            "cmd_c_loss:0.02495541051030159\n",
            "cmd_t_loss:0.16984453797340393\n",
            "r_loss:0.7063783407211304\n",
            "accuracy_s:0.48996591567993164\n",
            "c_loss:0.7095866799354553\n",
            "cmd_c_loss:0.018928302451968193\n",
            "cmd_t_loss:0.17596973478794098\n",
            "r_loss:0.7005274295806885\n",
            "accuracy_s:0.4869367778301239\n",
            "c_loss:0.7066711783409119\n",
            "cmd_c_loss:0.012609444558620453\n",
            "cmd_t_loss:0.18242552876472473\n",
            "r_loss:0.6944534778594971\n",
            "accuracy_s:0.49337372183799744\n",
            "c_loss:0.7039808630943298\n",
            "cmd_c_loss:0.006158589385449886\n",
            "cmd_t_loss:0.1892281472682953\n",
            "r_loss:0.6881616115570068\n",
            "accuracy_s:0.49337372183799744\n",
            "c_loss:0.7015781402587891\n",
            "cmd_c_loss:0.010965758934617043\n",
            "cmd_t_loss:0.19639472663402557\n",
            "r_loss:0.6817815899848938\n",
            "accuracy_s:0.49867475032806396\n",
            "c_loss:0.698955237865448\n",
            "cmd_c_loss:0.007322225719690323\n",
            "cmd_t_loss:0.20394596457481384\n",
            "r_loss:0.6747292280197144\n",
            "accuracy_s:0.5043544173240662\n",
            "c_loss:0.6968827247619629\n",
            "cmd_c_loss:0.01042269915342331\n",
            "cmd_t_loss:0.21190130710601807\n",
            "r_loss:0.6678997278213501\n",
            "accuracy_s:0.5073835849761963\n",
            "c_loss:0.6944663524627686\n",
            "cmd_c_loss:0.008661126717925072\n",
            "cmd_t_loss:0.22028329968452454\n",
            "r_loss:0.660291314125061\n",
            "accuracy_s:0.5111700296401978\n",
            "c_loss:0.6925952434539795\n",
            "cmd_c_loss:0.009771970100700855\n",
            "cmd_t_loss:0.22911152243614197\n",
            "r_loss:0.6529815793037415\n",
            "accuracy_s:0.5157137513160706\n",
            "c_loss:0.6903004050254822\n",
            "cmd_c_loss:0.010115799494087696\n",
            "cmd_t_loss:0.23841001093387604\n",
            "r_loss:0.6448323130607605\n",
            "accuracy_s:0.5206361413002014\n",
            "c_loss:0.6885240077972412\n",
            "cmd_c_loss:0.009087924845516682\n",
            "cmd_t_loss:0.24820202589035034\n",
            "r_loss:0.6370293498039246\n",
            "accuracy_s:0.5285876393318176\n",
            "c_loss:0.686262309551239\n",
            "cmd_c_loss:0.011662697419524193\n",
            "cmd_t_loss:0.25851115584373474\n",
            "r_loss:0.6283483505249023\n",
            "accuracy_s:0.537675142288208\n",
            "c_loss:0.6844916343688965\n",
            "cmd_c_loss:0.008409476839005947\n",
            "cmd_t_loss:0.26936495304107666\n",
            "r_loss:0.620046079158783\n",
            "accuracy_s:0.5414615869522095\n",
            "c_loss:0.6821892857551575\n",
            "cmd_c_loss:0.013276847079396248\n",
            "cmd_t_loss:0.28078940510749817\n",
            "r_loss:0.6108518838882446\n",
            "accuracy_s:0.5460053086280823\n",
            "c_loss:0.6803537607192993\n",
            "cmd_c_loss:0.00777877401560545\n",
            "cmd_t_loss:0.2928122282028198\n",
            "r_loss:0.6020485758781433\n",
            "accuracy_s:0.5543354749679565\n",
            "c_loss:0.6779569983482361\n",
            "cmd_c_loss:0.01491647120565176\n",
            "cmd_t_loss:0.3054625391960144\n",
            "r_loss:0.5923741459846497\n",
            "accuracy_s:0.5607724189758301\n",
            "c_loss:0.6760014295578003\n",
            "cmd_c_loss:0.0072578852996230125\n",
            "cmd_t_loss:0.3187691569328308\n",
            "r_loss:0.5830705165863037\n",
            "accuracy_s:0.566073477268219\n",
            "c_loss:0.6734771132469177\n",
            "cmd_c_loss:0.016508206725120544\n",
            "cmd_t_loss:0.3327632546424866\n",
            "r_loss:0.5729693174362183\n",
            "accuracy_s:0.5740249752998352\n",
            "c_loss:0.6713569164276123\n",
            "cmd_c_loss:0.006935494020581245\n",
            "cmd_t_loss:0.34747037291526794\n",
            "r_loss:0.5631663203239441\n",
            "accuracy_s:0.5812192559242249\n",
            "c_loss:0.6686896681785583\n",
            "cmd_c_loss:0.01795213297009468\n",
            "cmd_t_loss:0.36292627453804016\n",
            "r_loss:0.552707314491272\n",
            "accuracy_s:0.5899280309677124\n",
            "c_loss:0.666365385055542\n",
            "cmd_c_loss:0.006911048665642738\n",
            "cmd_t_loss:0.37916299700737\n",
            "r_loss:0.5424109101295471\n",
            "accuracy_s:0.5963650345802307\n",
            "c_loss:0.6635482311248779\n",
            "cmd_c_loss:0.019168611615896225\n",
            "cmd_t_loss:0.3962140381336212\n",
            "r_loss:0.5316612720489502\n",
            "accuracy_s:0.6043165326118469\n",
            "c_loss:0.6609866619110107\n",
            "cmd_c_loss:0.007253377232700586\n",
            "cmd_t_loss:0.41411253809928894\n",
            "r_loss:0.5208982229232788\n",
            "accuracy_s:0.6134040355682373\n",
            "c_loss:0.6580104231834412\n",
            "cmd_c_loss:0.02014886401593685\n",
            "cmd_t_loss:0.43288862705230713\n",
            "r_loss:0.5099127888679504\n",
            "accuracy_s:0.6266565918922424\n",
            "c_loss:0.6551885008811951\n",
            "cmd_c_loss:0.007973907515406609\n",
            "cmd_t_loss:0.45258012413978577\n",
            "r_loss:0.49874868988990784\n",
            "accuracy_s:0.6349867582321167\n",
            "c_loss:0.6520394086837769\n",
            "cmd_c_loss:0.0209390576928854\n",
            "cmd_t_loss:0.47321465611457825\n",
            "r_loss:0.4875775873661041\n",
            "accuracy_s:0.6474820375442505\n",
            "c_loss:0.6489435434341431\n",
            "cmd_c_loss:0.009044025093317032\n",
            "cmd_t_loss:0.49482616782188416\n",
            "r_loss:0.47610411047935486\n",
            "accuracy_s:0.6584627032279968\n",
            "c_loss:0.6456054449081421\n",
            "cmd_c_loss:0.021597040817141533\n",
            "cmd_t_loss:0.5174447298049927\n",
            "r_loss:0.46480289101600647\n",
            "accuracy_s:0.6683074831962585\n",
            "c_loss:0.6422263383865356\n",
            "cmd_c_loss:0.010418761521577835\n",
            "cmd_t_loss:0.5411038398742676\n",
            "r_loss:0.4531286358833313\n",
            "accuracy_s:0.681938648223877\n",
            "c_loss:0.6386818289756775\n",
            "cmd_c_loss:0.022177565842866898\n",
            "cmd_t_loss:0.5658338665962219\n",
            "r_loss:0.4417634904384613\n",
            "accuracy_s:0.6910261511802673\n",
            "c_loss:0.6350117921829224\n",
            "cmd_c_loss:0.01205410435795784\n",
            "cmd_t_loss:0.5916595458984375\n",
            "r_loss:0.43000099062919617\n",
            "accuracy_s:0.7012495398521423\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.588\n",
            "c_loss:0.6312429904937744\n",
            "cmd_c_loss:0.022729480639100075\n",
            "cmd_t_loss:0.6186057329177856\n",
            "r_loss:0.4186473786830902\n",
            "accuracy_s:0.7080651521682739\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.594\n",
            "c_loss:0.6272738575935364\n",
            "cmd_c_loss:0.013911418616771698\n",
            "cmd_t_loss:0.6466967463493347\n",
            "r_loss:0.4069119691848755\n",
            "accuracy_s:0.7145020961761475\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.602\n",
            "c_loss:0.6232615113258362\n",
            "cmd_c_loss:0.023300470784306526\n",
            "cmd_t_loss:0.6759573221206665\n",
            "r_loss:0.39565059542655945\n",
            "accuracy_s:0.7205603718757629\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.614\n",
            "c_loss:0.6189846992492676\n",
            "cmd_c_loss:0.01596643216907978\n",
            "cmd_t_loss:0.7064014077186584\n",
            "r_loss:0.3840548098087311\n",
            "accuracy_s:0.728890597820282\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.618\n",
            "c_loss:0.6147091388702393\n",
            "cmd_c_loss:0.023936765268445015\n",
            "cmd_t_loss:0.7380521297454834\n",
            "r_loss:0.37297260761260986\n",
            "accuracy_s:0.7398712635040283\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.628\n",
            "c_loss:0.6101149320602417\n",
            "cmd_c_loss:0.01820945367217064\n",
            "cmd_t_loss:0.770922064781189\n",
            "r_loss:0.3616248071193695\n",
            "accuracy_s:0.7485800981521606\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.638\n",
            "c_loss:0.6055554151535034\n",
            "cmd_c_loss:0.024692749604582787\n",
            "cmd_t_loss:0.8050307631492615\n",
            "r_loss:0.3508085310459137\n",
            "accuracy_s:0.7565315961837769\n",
            "valid accuracy: 0.638\n",
            "c_loss:0.6006329655647278\n",
            "cmd_c_loss:0.020656399428844452\n",
            "cmd_t_loss:0.8403877019882202\n",
            "r_loss:0.33980780839920044\n",
            "accuracy_s:0.7659977078437805\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.648\n",
            "c_loss:0.5957677960395813\n",
            "cmd_c_loss:0.025660034269094467\n",
            "cmd_t_loss:0.8770130276679993\n",
            "r_loss:0.32934126257896423\n",
            "accuracy_s:0.7705414891242981\n",
            "valid accuracy: 0.646\n",
            "c_loss:0.5905062556266785\n",
            "cmd_c_loss:0.023399626836180687\n",
            "cmd_t_loss:0.9149157404899597\n",
            "r_loss:0.31877100467681885\n",
            "accuracy_s:0.7750852108001709\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.652\n",
            "c_loss:0.5853128433227539\n",
            "cmd_c_loss:0.027068408206105232\n",
            "cmd_t_loss:0.9541141986846924\n",
            "r_loss:0.3087311387062073\n",
            "accuracy_s:0.7841726541519165\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.66\n",
            "c_loss:0.5796931385993958\n",
            "cmd_c_loss:0.026564382016658783\n",
            "cmd_t_loss:0.9946162700653076\n",
            "r_loss:0.29866132140159607\n",
            "accuracy_s:0.7898523211479187\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.666\n",
            "c_loss:0.5741354823112488\n",
            "cmd_c_loss:0.028919996693730354\n",
            "cmd_t_loss:1.0364333391189575\n",
            "r_loss:0.2891163229942322\n",
            "accuracy_s:0.798182487487793\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.676\n",
            "c_loss:0.5681259632110596\n",
            "cmd_c_loss:0.029902854934334755\n",
            "cmd_t_loss:1.079578161239624\n",
            "r_loss:0.27960994839668274\n",
            "accuracy_s:0.8015903234481812\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.688\n",
            "c_loss:0.5621839165687561\n",
            "cmd_c_loss:0.030994735658168793\n",
            "cmd_t_loss:1.1240429878234863\n",
            "r_loss:0.27061548829078674\n",
            "accuracy_s:0.8084059357643127\n",
            "valid accuracy: 0.684\n",
            "c_loss:0.5557591915130615\n",
            "cmd_c_loss:0.033462248742580414\n",
            "cmd_t_loss:1.1698341369628906\n",
            "r_loss:0.2617237865924835\n",
            "accuracy_s:0.8114350438117981\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.696\n",
            "c_loss:0.5494195222854614\n",
            "cmd_c_loss:0.03330032154917717\n",
            "cmd_t_loss:1.2169506549835205\n",
            "r_loss:0.2533250153064728\n",
            "accuracy_s:0.819007933139801\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.708\n",
            "c_loss:0.5425468683242798\n",
            "cmd_c_loss:0.0372963584959507\n",
            "cmd_t_loss:1.2653977870941162\n",
            "r_loss:0.24508905410766602\n",
            "accuracy_s:0.8212798237800598\n",
            "valid accuracy: 0.708\n",
            "c_loss:0.5358050465583801\n",
            "cmd_c_loss:0.03585314005613327\n",
            "cmd_t_loss:1.3151618242263794\n",
            "r_loss:0.23731525242328644\n",
            "accuracy_s:0.8288527131080627\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.724\n",
            "c_loss:0.5284513831138611\n",
            "cmd_c_loss:0.04146844521164894\n",
            "cmd_t_loss:1.3662364482879639\n",
            "r_loss:0.22975754737854004\n",
            "accuracy_s:0.8318818807601929\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.732\n",
            "c_loss:0.5213145613670349\n",
            "cmd_c_loss:0.03862980753183365\n",
            "cmd_t_loss:1.4185954332351685\n",
            "r_loss:0.2226317971944809\n",
            "accuracy_s:0.8386974334716797\n",
            "valid accuracy: 0.732\n",
            "c_loss:0.5134520530700684\n",
            "cmd_c_loss:0.045999303460121155\n",
            "cmd_t_loss:1.4722137451171875\n",
            "r_loss:0.21576187014579773\n",
            "accuracy_s:0.8436198234558105\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.734\n",
            "c_loss:0.5059363842010498\n",
            "cmd_c_loss:0.04156585782766342\n",
            "cmd_t_loss:1.5270657539367676\n",
            "r_loss:0.20929549634456635\n",
            "accuracy_s:0.8523286581039429\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.738\n",
            "c_loss:0.49755072593688965\n",
            "cmd_c_loss:0.050899095833301544\n",
            "cmd_t_loss:1.5831378698349\n",
            "r_loss:0.20311205089092255\n",
            "accuracy_s:0.8546005487442017\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.742\n",
            "c_loss:0.48968207836151123\n",
            "cmd_c_loss:0.044638119637966156\n",
            "cmd_t_loss:1.640412449836731\n",
            "r_loss:0.19731305539608002\n",
            "accuracy_s:0.8599015474319458\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.75\n",
            "c_loss:0.4807787239551544\n",
            "cmd_c_loss:0.05627061799168587\n",
            "cmd_t_loss:1.6988303661346436\n",
            "r_loss:0.1918090134859085\n",
            "accuracy_s:0.8621734380722046\n",
            "valid accuracy: 0.75\n",
            "c_loss:0.47259268164634705\n",
            "cmd_c_loss:0.04791920259594917\n",
            "cmd_t_loss:1.758350133895874\n",
            "r_loss:0.186676025390625\n",
            "accuracy_s:0.8708822131156921\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.764\n",
            "c_loss:0.4632032513618469\n",
            "cmd_c_loss:0.06223088130354881\n",
            "cmd_t_loss:1.8189043998718262\n",
            "r_loss:0.18183660507202148\n",
            "accuracy_s:0.8727754354476929\n",
            "valid accuracy: 0.762\n",
            "c_loss:0.45475253462791443\n",
            "cmd_c_loss:0.05142253264784813\n",
            "cmd_t_loss:1.8804523944854736\n",
            "r_loss:0.17734761536121368\n",
            "accuracy_s:0.8803483247756958\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.768\n",
            "c_loss:0.4449383318424225\n",
            "cmd_c_loss:0.0687142089009285\n",
            "cmd_t_loss:1.9429429769515991\n",
            "r_loss:0.17315012216567993\n",
            "accuracy_s:0.8803483247756958\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.772\n",
            "c_loss:0.4363093972206116\n",
            "cmd_c_loss:0.05510307848453522\n",
            "cmd_t_loss:2.006302833557129\n",
            "r_loss:0.169272780418396\n",
            "accuracy_s:0.8886785507202148\n",
            "valid accuracy: 0.77\n",
            "c_loss:0.4261748790740967\n",
            "cmd_c_loss:0.0758267194032669\n",
            "cmd_t_loss:2.0704944133758545\n",
            "r_loss:0.16568684577941895\n",
            "accuracy_s:0.886027991771698\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.784\n",
            "c_loss:0.41755247116088867\n",
            "cmd_c_loss:0.058974962681531906\n",
            "cmd_t_loss:2.135451555252075\n",
            "r_loss:0.1623767614364624\n",
            "accuracy_s:0.8954941034317017\n",
            "valid accuracy: 0.778\n",
            "c_loss:0.4073082208633423\n",
            "cmd_c_loss:0.08323919028043747\n",
            "cmd_t_loss:2.201084613800049\n",
            "r_loss:0.1593589186668396\n",
            "accuracy_s:0.8920863270759583\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.786\n",
            "c_loss:0.39911705255508423\n",
            "cmd_c_loss:0.062279656529426575\n",
            "cmd_t_loss:2.2673540115356445\n",
            "r_loss:0.1565527319908142\n",
            "accuracy_s:0.904202938079834\n",
            "valid accuracy: 0.772\n",
            "c_loss:0.38927048444747925\n",
            "cmd_c_loss:0.09087970852851868\n",
            "cmd_t_loss:2.334228754043579\n",
            "r_loss:0.15405328571796417\n",
            "accuracy_s:0.8924649953842163\n",
            "valid accuracy: 0.78\n",
            "c_loss:0.3824324309825897\n",
            "cmd_c_loss:0.06595946848392487\n",
            "cmd_t_loss:2.401587724685669\n",
            "r_loss:0.1516847014427185\n",
            "accuracy_s:0.9117758274078369\n",
            "valid accuracy: 0.768\n",
            "c_loss:0.3737000524997711\n",
            "cmd_c_loss:0.10009866207838058\n",
            "cmd_t_loss:2.469369888305664\n",
            "r_loss:0.14964386820793152\n",
            "accuracy_s:0.8829988837242126\n",
            "valid accuracy: 0.784\n",
            "c_loss:0.3687836527824402\n",
            "cmd_c_loss:0.07075566053390503\n",
            "cmd_t_loss:2.537527322769165\n",
            "r_loss:0.14765186607837677\n",
            "accuracy_s:0.9083680510520935\n",
            "valid accuracy: 0.764\n",
            "c_loss:0.36020803451538086\n",
            "cmd_c_loss:0.11029557883739471\n",
            "cmd_t_loss:2.6059799194335938\n",
            "r_loss:0.14600050449371338\n",
            "accuracy_s:0.8795910477638245\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.788\n",
            "c_loss:0.35569074749946594\n",
            "cmd_c_loss:0.07588696479797363\n",
            "cmd_t_loss:2.674668073654175\n",
            "r_loss:0.14432649314403534\n",
            "accuracy_s:0.9034456610679626\n",
            "valid accuracy: 0.772\n",
            "c_loss:0.3455280661582947\n",
            "cmd_c_loss:0.1201586201786995\n",
            "cmd_t_loss:2.743469476699829\n",
            "r_loss:0.14299321174621582\n",
            "accuracy_s:0.8811056613922119\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.8\n",
            "c_loss:0.34070056676864624\n",
            "cmd_c_loss:0.08104468137025833\n",
            "cmd_t_loss:2.8123390674591064\n",
            "r_loss:0.14157980680465698\n",
            "accuracy_s:0.9079893827438354\n",
            "valid accuracy: 0.782\n",
            "c_loss:0.32949385046958923\n",
            "cmd_c_loss:0.12903140485286713\n",
            "cmd_t_loss:2.881213903427124\n",
            "r_loss:0.1405111700296402\n",
            "accuracy_s:0.8894358277320862\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.802\n",
            "c_loss:0.32472026348114014\n",
            "cmd_c_loss:0.08570321649312973\n",
            "cmd_t_loss:2.9500327110290527\n",
            "r_loss:0.1393056958913803\n",
            "accuracy_s:0.9151836633682251\n",
            "valid accuracy: 0.788\n",
            "c_loss:0.3134019076824188\n",
            "cmd_c_loss:0.13703885674476624\n",
            "cmd_t_loss:3.0187268257141113\n",
            "r_loss:0.1384560912847519\n",
            "accuracy_s:0.8992805480957031\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.806\n",
            "c_loss:0.30904626846313477\n",
            "cmd_c_loss:0.09068945050239563\n",
            "cmd_t_loss:3.0872957706451416\n",
            "r_loss:0.1374170184135437\n",
            "accuracy_s:0.9219992160797119\n",
            "valid accuracy: 0.786\n",
            "c_loss:0.2981701195240021\n",
            "cmd_c_loss:0.14530713856220245\n",
            "cmd_t_loss:3.155618190765381\n",
            "r_loss:0.13675087690353394\n",
            "accuracy_s:0.904581606388092\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.814\n",
            "c_loss:0.29441964626312256\n",
            "cmd_c_loss:0.0960794985294342\n",
            "cmd_t_loss:3.2236948013305664\n",
            "r_loss:0.1358499377965927\n",
            "accuracy_s:0.9265429973602295\n",
            "valid accuracy: 0.788\n",
            "c_loss:0.28420722484588623\n",
            "cmd_c_loss:0.15405435860157013\n",
            "cmd_t_loss:3.291400194168091\n",
            "r_loss:0.13532958924770355\n",
            "accuracy_s:0.9076107740402222\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.816\n",
            "c_loss:0.2813887894153595\n",
            "cmd_c_loss:0.10204668343067169\n",
            "cmd_t_loss:3.358670473098755\n",
            "r_loss:0.134540393948555\n",
            "accuracy_s:0.930329442024231\n",
            "valid accuracy: 0.786\n",
            "c_loss:0.27176669239997864\n",
            "cmd_c_loss:0.163225457072258\n",
            "cmd_t_loss:3.42539644241333\n",
            "r_loss:0.13414520025253296\n",
            "accuracy_s:0.912154495716095\n",
            "valid accuracy: 0.806\n",
            "c_loss:0.27000439167022705\n",
            "cmd_c_loss:0.10833263397216797\n",
            "cmd_t_loss:3.4915482997894287\n",
            "r_loss:0.13345003128051758\n",
            "accuracy_s:0.9318439960479736\n",
            "valid accuracy: 0.784\n",
            "c_loss:0.26067429780960083\n",
            "cmd_c_loss:0.17248393595218658\n",
            "cmd_t_loss:3.556986093521118\n",
            "r_loss:0.13315902650356293\n",
            "accuracy_s:0.914804995059967\n",
            "valid accuracy: 0.804\n",
            "c_loss:0.2599508762359619\n",
            "cmd_c_loss:0.11563687026500702\n",
            "cmd_t_loss:3.6215758323669434\n",
            "r_loss:0.13254070281982422\n",
            "accuracy_s:0.9310867190361023\n",
            "valid accuracy: 0.782\n",
            "c_loss:0.2504279911518097\n",
            "cmd_c_loss:0.18261198699474335\n",
            "cmd_t_loss:3.6852705478668213\n",
            "r_loss:0.13233120739459991\n",
            "accuracy_s:0.9189701080322266\n",
            "valid accuracy: 0.798\n",
            "c_loss:0.25072941184043884\n",
            "cmd_c_loss:0.12363821268081665\n",
            "cmd_t_loss:3.7478911876678467\n",
            "r_loss:0.13180215656757355\n",
            "accuracy_s:0.9341158866882324\n",
            "valid accuracy: 0.782\n",
            "c_loss:0.24087144434452057\n",
            "cmd_c_loss:0.18874195218086243\n",
            "cmd_t_loss:3.809417247772217\n",
            "r_loss:0.13161233067512512\n",
            "accuracy_s:0.9231351613998413\n",
            "valid accuracy: 0.792\n",
            "c_loss:0.24256713688373566\n",
            "cmd_c_loss:0.12840665876865387\n",
            "cmd_t_loss:3.869727373123169\n",
            "r_loss:0.13121694326400757\n",
            "accuracy_s:0.9360091090202332\n",
            "valid accuracy: 0.782\n",
            "c_loss:0.23257902264595032\n",
            "cmd_c_loss:0.19155609607696533\n",
            "cmd_t_loss:3.9287877082824707\n",
            "r_loss:0.13104397058486938\n",
            "accuracy_s:0.9242711067199707\n",
            "valid accuracy: 0.8\n",
            "c_loss:0.2358967810869217\n",
            "cmd_c_loss:0.13194169104099274\n",
            "cmd_t_loss:3.9866065979003906\n",
            "r_loss:0.13071133196353912\n",
            "accuracy_s:0.9356304407119751\n",
            "valid accuracy: 0.792\n",
            "c_loss:0.2240244448184967\n",
            "cmd_c_loss:0.19617974758148193\n",
            "cmd_t_loss:4.043056011199951\n",
            "r_loss:0.13059356808662415\n",
            "accuracy_s:0.9276788830757141\n",
            "valid accuracy: 0.802\n",
            "c_loss:0.22618912160396576\n",
            "cmd_c_loss:0.14163923263549805\n",
            "cmd_t_loss:4.09813928604126\n",
            "r_loss:0.13027682900428772\n",
            "accuracy_s:0.9382809400558472\n",
            "valid accuracy: 0.794\n",
            "c_loss:0.21086090803146362\n",
            "cmd_c_loss:0.20114296674728394\n",
            "cmd_t_loss:4.151864051818848\n",
            "r_loss:0.1301574558019638\n",
            "accuracy_s:0.9360091090202332\n",
            "valid accuracy: 0.808\n",
            "c_loss:0.2092752903699875\n",
            "cmd_c_loss:0.1471279114484787\n",
            "cmd_t_loss:4.2042927742004395\n",
            "r_loss:0.12989665567874908\n",
            "accuracy_s:0.9466111063957214\n",
            "valid accuracy: 0.798\n",
            "c_loss:0.19259579479694366\n",
            "cmd_c_loss:0.2028900533914566\n",
            "cmd_t_loss:4.255437850952148\n",
            "r_loss:0.12977473437786102\n",
            "accuracy_s:0.9485043287277222\n",
            "valid accuracy: 0.814\n",
            "c_loss:0.1862623542547226\n",
            "cmd_c_loss:0.15182487666606903\n",
            "cmd_t_loss:4.3050618171691895\n",
            "r_loss:0.1295648217201233\n",
            "accuracy_s:0.9594850540161133\n",
            "valid accuracy: 0.812\n",
            "c_loss:0.17329534888267517\n",
            "cmd_c_loss:0.2067641168832779\n",
            "cmd_t_loss:4.353479385375977\n",
            "r_loss:0.12943674623966217\n",
            "accuracy_s:0.9606209993362427\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.82\n",
            "c_loss:0.16766172647476196\n",
            "cmd_c_loss:0.1508873552083969\n",
            "cmd_t_loss:4.400658130645752\n",
            "r_loss:0.12924562394618988\n",
            "accuracy_s:0.9681938886642456\n",
            "valid accuracy: 0.812\n",
            "c_loss:0.15839135646820068\n",
            "cmd_c_loss:0.21064065396785736\n",
            "cmd_t_loss:4.446420192718506\n",
            "r_loss:0.1291344314813614\n",
            "accuracy_s:0.9693297743797302\n",
            "valid accuracy: 0.82\n",
            "c_loss:0.15621672570705414\n",
            "cmd_c_loss:0.1598484367132187\n",
            "cmd_t_loss:4.491026878356934\n",
            "r_loss:0.12892071902751923\n",
            "accuracy_s:0.9738735556602478\n",
            "valid accuracy: 0.818\n",
            "c_loss:0.14822624623775482\n",
            "cmd_c_loss:0.2188054472208023\n",
            "cmd_t_loss:4.534397602081299\n",
            "r_loss:0.12884065508842468\n",
            "accuracy_s:0.9753881096839905\n",
            "valid accuracy: 0.82\n",
            "c_loss:0.14802932739257812\n",
            "cmd_c_loss:0.15736763179302216\n",
            "cmd_t_loss:4.576413631439209\n",
            "r_loss:0.12870891392230988\n",
            "accuracy_s:0.9761453866958618\n",
            "valid accuracy: 0.818\n",
            "c_loss:0.1410902887582779\n",
            "cmd_c_loss:0.22054901719093323\n",
            "cmd_t_loss:4.617545127868652\n",
            "r_loss:0.12862098217010498\n",
            "accuracy_s:0.9784172773361206\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.824\n",
            "c_loss:0.14408361911773682\n",
            "cmd_c_loss:0.16496442258358002\n",
            "cmd_t_loss:4.657385349273682\n",
            "r_loss:0.12846878170967102\n",
            "accuracy_s:0.9757667779922485\n",
            "valid accuracy: 0.808\n",
            "c_loss:0.13809490203857422\n",
            "cmd_c_loss:0.2221287339925766\n",
            "cmd_t_loss:4.695949554443359\n",
            "r_loss:0.12836116552352905\n",
            "accuracy_s:0.9769026637077332\n",
            "valid accuracy: 0.824\n",
            "c_loss:0.14755824208259583\n",
            "cmd_c_loss:0.15984037518501282\n",
            "cmd_t_loss:4.733417987823486\n",
            "r_loss:0.12824411690235138\n",
            "accuracy_s:0.9693297743797302\n",
            "valid accuracy: 0.818\n",
            "c_loss:0.14848078787326813\n",
            "cmd_c_loss:0.2208375781774521\n",
            "cmd_t_loss:4.770135879516602\n",
            "r_loss:0.12818096578121185\n",
            "accuracy_s:0.9644074440002441\n",
            "valid accuracy: 0.796\n",
            "c_loss:0.18121106922626495\n",
            "cmd_c_loss:0.16149519383907318\n",
            "cmd_t_loss:4.805596828460693\n",
            "r_loss:0.12795066833496094\n",
            "accuracy_s:0.9424460530281067\n",
            "valid accuracy: 0.77\n",
            "c_loss:0.2087000608444214\n",
            "cmd_c_loss:0.21234345436096191\n",
            "cmd_t_loss:4.840072154998779\n",
            "r_loss:0.12805278599262238\n",
            "accuracy_s:0.9174554944038391\n",
            "valid accuracy: 0.736\n",
            "c_loss:0.304438978433609\n",
            "cmd_c_loss:0.148478701710701\n",
            "cmd_t_loss:4.8738484382629395\n",
            "r_loss:0.12793712317943573\n",
            "accuracy_s:0.8595228791236877\n",
            "valid accuracy: 0.706\n",
            "c_loss:0.3310399353504181\n",
            "cmd_c_loss:0.1784534901380539\n",
            "cmd_t_loss:4.9064812660217285\n",
            "r_loss:0.1281990110874176\n",
            "accuracy_s:0.8326391577720642\n",
            "valid accuracy: 0.736\n",
            "c_loss:0.24408400058746338\n",
            "cmd_c_loss:0.16217491030693054\n",
            "cmd_t_loss:4.938525676727295\n",
            "r_loss:0.12790383398532867\n",
            "accuracy_s:0.8886785507202148\n",
            "valid accuracy: 0.796\n",
            "c_loss:0.12654919922351837\n",
            "cmd_c_loss:0.16358040273189545\n",
            "cmd_t_loss:4.96956729888916\n",
            "r_loss:0.12788943946361542\n",
            "accuracy_s:0.9723589420318604\n",
            "valid accuracy: 0.82\n",
            "c_loss:0.0981874018907547\n",
            "cmd_c_loss:0.15693414211273193\n",
            "cmd_t_loss:4.999985694885254\n",
            "r_loss:0.12741579115390778\n",
            "accuracy_s:0.9924271106719971\n",
            "valid accuracy: 0.81\n",
            "c_loss:0.09569850564002991\n",
            "cmd_c_loss:0.1652357578277588\n",
            "cmd_t_loss:5.029535293579102\n",
            "r_loss:0.12728320062160492\n",
            "accuracy_s:0.9924271106719971\n",
            "valid accuracy: 0.822\n",
            "c_loss:0.09324083477258682\n",
            "cmd_c_loss:0.18194542825222015\n",
            "cmd_t_loss:5.058990955352783\n",
            "r_loss:0.12702420353889465\n",
            "accuracy_s:0.9931843876838684\n",
            "valid accuracy: 0.812\n",
            "c_loss:0.09043487161397934\n",
            "cmd_c_loss:0.161310613155365\n",
            "cmd_t_loss:5.08661413192749\n",
            "r_loss:0.12688632309436798\n",
            "accuracy_s:0.9931843876838684\n",
            "valid accuracy: 0.824\n",
            "c_loss:0.08878225833177567\n",
            "cmd_c_loss:0.18184445798397064\n",
            "cmd_t_loss:5.114274978637695\n",
            "r_loss:0.12680651247501373\n",
            "accuracy_s:0.9935630559921265\n",
            "valid accuracy: 0.822\n",
            "c_loss:0.08771120756864548\n",
            "cmd_c_loss:0.1630980223417282\n",
            "cmd_t_loss:5.140787124633789\n",
            "r_loss:0.12673170864582062\n",
            "accuracy_s:0.9931843876838684\n",
            "valid accuracy: 0.824\n",
            "c_loss:0.08582238852977753\n",
            "cmd_c_loss:0.18192951381206512\n",
            "cmd_t_loss:5.167466163635254\n",
            "r_loss:0.12667985260486603\n",
            "accuracy_s:0.9939416646957397\n",
            "valid accuracy: 0.82\n",
            "c_loss:0.08465253561735153\n",
            "cmd_c_loss:0.17311158776283264\n",
            "cmd_t_loss:5.191282272338867\n",
            "r_loss:0.12669487297534943\n",
            "accuracy_s:0.9939416646957397\n",
            "valid accuracy: 0.82\n",
            "c_loss:0.0844356045126915\n",
            "cmd_c_loss:0.16996338963508606\n",
            "cmd_t_loss:5.216096878051758\n",
            "r_loss:0.126655712723732\n",
            "accuracy_s:0.9946990013122559\n",
            "valid accuracy: 0.808\n",
            "c_loss:0.08171790093183517\n",
            "cmd_c_loss:0.2090151011943817\n",
            "cmd_t_loss:5.23848819732666\n",
            "r_loss:0.12681721150875092\n",
            "accuracy_s:0.9943203330039978\n",
            "best_result:0.8240000009536743\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_common_0_to_1.pkl\n",
            "test_accuracy:0.7984189987182617\n",
            "Train target model...\n",
            "t_loss:0.788381814956665\n",
            "cmd_c_loss:0.13897688686847687\n",
            "cmd_t_loss:0.09865499287843704\n",
            "r_loss:0.8194444179534912\n",
            "accuracy_t:0.4945397675037384\n",
            "t_loss:0.7813003063201904\n",
            "cmd_c_loss:0.1363140046596527\n",
            "cmd_t_loss:0.10125850141048431\n",
            "r_loss:0.8161370754241943\n",
            "accuracy_t:0.4945397675037384\n",
            "t_loss:0.7743262648582458\n",
            "cmd_c_loss:0.13350769877433777\n",
            "cmd_t_loss:0.10400897264480591\n",
            "r_loss:0.8126738667488098\n",
            "accuracy_t:0.4945397675037384\n",
            "t_loss:0.7674787044525146\n",
            "cmd_c_loss:0.13055047392845154\n",
            "cmd_t_loss:0.10691427439451218\n",
            "r_loss:0.8090485334396362\n",
            "accuracy_t:0.4945397675037384\n",
            "t_loss:0.760775625705719\n",
            "cmd_c_loss:0.12743410468101501\n",
            "cmd_t_loss:0.10998325794935226\n",
            "r_loss:0.8052547574043274\n",
            "accuracy_t:0.4945397675037384\n",
            "t_loss:0.7542320489883423\n",
            "cmd_c_loss:0.12415026873350143\n",
            "cmd_t_loss:0.11322486400604248\n",
            "r_loss:0.8012859225273132\n",
            "accuracy_t:0.49141964316368103\n",
            "t_loss:0.7478606104850769\n",
            "cmd_c_loss:0.12068989872932434\n",
            "cmd_t_loss:0.1166485846042633\n",
            "r_loss:0.7971357703208923\n",
            "accuracy_t:0.48829951882362366\n",
            "t_loss:0.7416709065437317\n",
            "cmd_c_loss:0.11704380065202713\n",
            "cmd_t_loss:0.12026436626911163\n",
            "r_loss:0.7927973866462708\n",
            "accuracy_t:0.48829951882362366\n",
            "t_loss:0.7356687784194946\n",
            "cmd_c_loss:0.11320216208696365\n",
            "cmd_t_loss:0.1240832582116127\n",
            "r_loss:0.7882639765739441\n",
            "accuracy_t:0.4945397675037384\n",
            "t_loss:0.7298563718795776\n",
            "cmd_c_loss:0.10915481299161911\n",
            "cmd_t_loss:0.12811526656150818\n",
            "r_loss:0.7835291028022766\n",
            "accuracy_t:0.4976598918437958\n",
            "t_loss:0.7242324352264404\n",
            "cmd_c_loss:0.10489078611135483\n",
            "cmd_t_loss:0.13237330317497253\n",
            "r_loss:0.7785857319831848\n",
            "accuracy_t:0.5007800459861755\n",
            "t_loss:0.718790590763092\n",
            "cmd_c_loss:0.10039886832237244\n",
            "cmd_t_loss:0.13686919212341309\n",
            "r_loss:0.7734273672103882\n",
            "accuracy_t:0.511700451374054\n",
            "t_loss:0.7135207056999207\n",
            "cmd_c_loss:0.09566714614629745\n",
            "cmd_t_loss:0.1416165977716446\n",
            "r_loss:0.7680473923683167\n",
            "accuracy_t:0.5101404190063477\n",
            "t_loss:0.7084094285964966\n",
            "cmd_c_loss:0.09068351238965988\n",
            "cmd_t_loss:0.1466292440891266\n",
            "r_loss:0.7624393105506897\n",
            "accuracy_t:0.5148205757141113\n",
            "t_loss:0.7034399509429932\n",
            "cmd_c_loss:0.08543479442596436\n",
            "cmd_t_loss:0.15192097425460815\n",
            "r_loss:0.7565968036651611\n",
            "accuracy_t:0.5163806676864624\n",
            "t_loss:0.6985918283462524\n",
            "cmd_c_loss:0.07990769296884537\n",
            "cmd_t_loss:0.15750686824321747\n",
            "r_loss:0.750514030456543\n",
            "accuracy_t:0.513260543346405\n",
            "t_loss:0.6938421130180359\n",
            "cmd_c_loss:0.07408802956342697\n",
            "cmd_t_loss:0.1634041666984558\n",
            "r_loss:0.7441853284835815\n",
            "accuracy_t:0.5273010730743408\n",
            "t_loss:0.6891658902168274\n",
            "cmd_c_loss:0.06796121597290039\n",
            "cmd_t_loss:0.1696295589208603\n",
            "r_loss:0.7376050353050232\n",
            "accuracy_t:0.5507020354270935\n",
            "t_loss:0.6845382452011108\n",
            "cmd_c_loss:0.06151234358549118\n",
            "cmd_t_loss:0.17620043456554413\n",
            "r_loss:0.7307684421539307\n",
            "accuracy_t:0.5553821921348572\n",
            "t_loss:0.6799310445785522\n",
            "cmd_c_loss:0.05472575128078461\n",
            "cmd_t_loss:0.18313589692115784\n",
            "r_loss:0.7236713171005249\n",
            "accuracy_t:0.5569422841072083\n",
            "t_loss:0.6753175854682922\n",
            "cmd_c_loss:0.047585565596818924\n",
            "cmd_t_loss:0.19045542180538177\n",
            "r_loss:0.7163099050521851\n",
            "accuracy_t:0.5741029381752014\n",
            "t_loss:0.6706709861755371\n",
            "cmd_c_loss:0.040076009929180145\n",
            "cmd_t_loss:0.19817736744880676\n",
            "r_loss:0.708681583404541\n",
            "accuracy_t:0.588143527507782\n",
            "t_loss:0.6659660339355469\n",
            "cmd_c_loss:0.03218163549900055\n",
            "cmd_t_loss:0.20632554590702057\n",
            "r_loss:0.7007848620414734\n",
            "accuracy_t:0.5975039005279541\n",
            "t_loss:0.6611779928207397\n",
            "cmd_c_loss:0.023888880386948586\n",
            "cmd_t_loss:0.2149215042591095\n",
            "r_loss:0.6926196217536926\n",
            "accuracy_t:0.6177847385406494\n",
            "t_loss:0.6562845706939697\n",
            "cmd_c_loss:0.015191739425063133\n",
            "cmd_t_loss:0.22398756444454193\n",
            "r_loss:0.684188723564148\n",
            "accuracy_t:0.6255850195884705\n",
            "t_loss:0.6512653231620789\n",
            "cmd_c_loss:0.006443848833441734\n",
            "cmd_t_loss:0.23354880511760712\n",
            "r_loss:0.6755034327507019\n",
            "accuracy_t:0.6333853602409363\n",
            "t_loss:0.6461014747619629\n",
            "cmd_c_loss:0.014115476049482822\n",
            "cmd_t_loss:0.24363143742084503\n",
            "r_loss:0.6668278574943542\n",
            "accuracy_t:0.6474258899688721\n",
            "t_loss:0.6407777667045593\n",
            "cmd_c_loss:0.007838902994990349\n",
            "cmd_t_loss:0.25426003336906433\n",
            "r_loss:0.6570658087730408\n",
            "accuracy_t:0.6614664793014526\n",
            "t_loss:0.6352803111076355\n",
            "cmd_c_loss:0.013746639713644981\n",
            "cmd_t_loss:0.2654625475406647\n",
            "r_loss:0.6479281187057495\n",
            "accuracy_t:0.6848673820495605\n",
            "t_loss:0.6295973658561707\n",
            "cmd_c_loss:0.009394556283950806\n",
            "cmd_t_loss:0.27726680040359497\n",
            "r_loss:0.6375374794006348\n",
            "accuracy_t:0.7004680037498474\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.552\n",
            "t_loss:0.6237198114395142\n",
            "cmd_c_loss:0.013216284103691578\n",
            "cmd_t_loss:0.2897005081176758\n",
            "r_loss:0.6279094219207764\n",
            "accuracy_t:0.7254289984703064\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.556\n",
            "t_loss:0.6176406741142273\n",
            "cmd_c_loss:0.011062868870794773\n",
            "cmd_t_loss:0.30278900265693665\n",
            "r_loss:0.6169630885124207\n",
            "accuracy_t:0.7503899931907654\n",
            "valid accuracy: 0.556\n",
            "t_loss:0.6113529205322266\n",
            "cmd_c_loss:0.012656762264668941\n",
            "cmd_t_loss:0.31656333804130554\n",
            "r_loss:0.6068631410598755\n",
            "accuracy_t:0.764430582523346\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.572\n",
            "t_loss:0.6048509478569031\n",
            "cmd_c_loss:0.012834019958972931\n",
            "cmd_t_loss:0.33105361461639404\n",
            "r_loss:0.595406174659729\n",
            "accuracy_t:0.7925117015838623\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.574\n",
            "t_loss:0.5981295704841614\n",
            "cmd_c_loss:0.01210961863398552\n",
            "cmd_t_loss:0.3462882936000824\n",
            "r_loss:0.5848680138587952\n",
            "accuracy_t:0.8049921989440918\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.578\n",
            "t_loss:0.5911866426467896\n",
            "cmd_c_loss:0.014696920290589333\n",
            "cmd_t_loss:0.3622979521751404\n",
            "r_loss:0.5729529857635498\n",
            "accuracy_t:0.8190327882766724\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.596\n",
            "t_loss:0.5840201377868652\n",
            "cmd_c_loss:0.011602017097175121\n",
            "cmd_t_loss:0.3791086971759796\n",
            "r_loss:0.5620223879814148\n",
            "accuracy_t:0.8361934423446655\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.6\n",
            "t_loss:0.5766287446022034\n",
            "cmd_c_loss:0.016635749489068985\n",
            "cmd_t_loss:0.3967519998550415\n",
            "r_loss:0.549714982509613\n",
            "accuracy_t:0.848673939704895\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.608\n",
            "t_loss:0.5690114498138428\n",
            "cmd_c_loss:0.011160297319293022\n",
            "cmd_t_loss:0.4152577817440033\n",
            "r_loss:0.538448691368103\n",
            "accuracy_t:0.873634934425354\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.616\n",
            "t_loss:0.5611673593521118\n",
            "cmd_c_loss:0.01862999051809311\n",
            "cmd_t_loss:0.4346505105495453\n",
            "r_loss:0.525826632976532\n",
            "accuracy_t:0.8876755237579346\n",
            "valid accuracy: 0.604\n",
            "t_loss:0.553097128868103\n",
            "cmd_c_loss:0.010810980573296547\n",
            "cmd_t_loss:0.4549570679664612\n",
            "r_loss:0.5142937302589417\n",
            "accuracy_t:0.8939157724380493\n",
            "valid accuracy: 0.61\n",
            "t_loss:0.5448042154312134\n",
            "cmd_c_loss:0.02065896801650524\n",
            "cmd_t_loss:0.476205438375473\n",
            "r_loss:0.5014458894729614\n",
            "accuracy_t:0.9017160534858704\n",
            "valid accuracy: 0.612\n",
            "t_loss:0.5362869501113892\n",
            "cmd_c_loss:0.010581929236650467\n",
            "cmd_t_loss:0.49841663241386414\n",
            "r_loss:0.4897269010543823\n",
            "accuracy_t:0.9048361778259277\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.62\n",
            "t_loss:0.5275487303733826\n",
            "cmd_c_loss:0.022706475108861923\n",
            "cmd_t_loss:0.5216172933578491\n",
            "r_loss:0.4767526388168335\n",
            "accuracy_t:0.9173166751861572\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.622\n",
            "t_loss:0.5185927748680115\n",
            "cmd_c_loss:0.010503632016479969\n",
            "cmd_t_loss:0.545825719833374\n",
            "r_loss:0.464937686920166\n",
            "accuracy_t:0.923556923866272\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.628\n",
            "t_loss:0.5094188451766968\n",
            "cmd_c_loss:0.024766886606812477\n",
            "cmd_t_loss:0.5710673928260803\n",
            "r_loss:0.4519389569759369\n",
            "accuracy_t:0.9282371401786804\n",
            "valid accuracy: 0.628\n",
            "t_loss:0.5000333189964294\n",
            "cmd_c_loss:0.010608082637190819\n",
            "cmd_t_loss:0.5973674654960632\n",
            "r_loss:0.4401226043701172\n",
            "accuracy_t:0.9344773888587952\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.63\n",
            "t_loss:0.49043917655944824\n",
            "cmd_c_loss:0.026840440928936005\n",
            "cmd_t_loss:0.6247379183769226\n",
            "r_loss:0.4272051453590393\n",
            "accuracy_t:0.9391575455665588\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.638\n",
            "t_loss:0.4806404709815979\n",
            "cmd_c_loss:0.01092466153204441\n",
            "cmd_t_loss:0.6531955599784851\n",
            "r_loss:0.41548675298690796\n",
            "accuracy_t:0.9438377618789673\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.654\n",
            "t_loss:0.47064170241355896\n",
            "cmd_c_loss:0.02892313152551651\n",
            "cmd_t_loss:0.6827613711357117\n",
            "r_loss:0.4027579128742218\n",
            "accuracy_t:0.9469578862190247\n",
            "valid accuracy: 0.652\n",
            "t_loss:0.4604484438896179\n",
            "cmd_c_loss:0.011479565873742104\n",
            "cmd_t_loss:0.7134539484977722\n",
            "r_loss:0.3912326395511627\n",
            "accuracy_t:0.9578782916069031\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.656\n",
            "t_loss:0.45006629824638367\n",
            "cmd_c_loss:0.031010622158646584\n",
            "cmd_t_loss:0.7452996373176575\n",
            "r_loss:0.37879449129104614\n",
            "accuracy_t:0.9578782916069031\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.66\n",
            "t_loss:0.4395065903663635\n",
            "cmd_c_loss:0.012297309003770351\n",
            "cmd_t_loss:0.778315007686615\n",
            "r_loss:0.3675524890422821\n",
            "accuracy_t:0.9609984159469604\n",
            "valid accuracy: 0.66\n",
            "t_loss:0.42877960205078125\n",
            "cmd_c_loss:0.03310982137918472\n",
            "cmd_t_loss:0.8125087022781372\n",
            "r_loss:0.35550129413604736\n",
            "accuracy_t:0.9641185402870178\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.662\n",
            "t_loss:0.4178963899612427\n",
            "cmd_c_loss:0.013409171253442764\n",
            "cmd_t_loss:0.8479000329971313\n",
            "r_loss:0.34462615847587585\n",
            "accuracy_t:0.9641185402870178\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.664\n",
            "t_loss:0.40686729550361633\n",
            "cmd_c_loss:0.03525180742144585\n",
            "cmd_t_loss:0.8844997882843018\n",
            "r_loss:0.33305075764656067\n",
            "accuracy_t:0.9656786322593689\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.666\n",
            "t_loss:0.3957151472568512\n",
            "cmd_c_loss:0.014866990968585014\n",
            "cmd_t_loss:0.9223243594169617\n",
            "r_loss:0.3226129710674286\n",
            "accuracy_t:0.9703587889671326\n",
            "valid accuracy: 0.664\n",
            "t_loss:0.3844580352306366\n",
            "cmd_c_loss:0.0375170074403286\n",
            "cmd_t_loss:0.9613743424415588\n",
            "r_loss:0.31159186363220215\n",
            "accuracy_t:0.9719188809394836\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.668\n",
            "t_loss:0.3731170892715454\n",
            "cmd_c_loss:0.016752954572439194\n",
            "cmd_t_loss:1.0016664266586304\n",
            "r_loss:0.3016524612903595\n",
            "accuracy_t:0.9781591296195984\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.67\n",
            "t_loss:0.36170855164527893\n",
            "cmd_c_loss:0.040158964693546295\n",
            "cmd_t_loss:1.0432034730911255\n",
            "r_loss:0.2912541925907135\n",
            "accuracy_t:0.9781591296195984\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.672\n",
            "t_loss:0.35026174783706665\n",
            "cmd_c_loss:0.01919640600681305\n",
            "cmd_t_loss:1.0859938859939575\n",
            "r_loss:0.28186190128326416\n",
            "accuracy_t:0.9781591296195984\n",
            "valid accuracy: 0.672\n",
            "t_loss:0.33880066871643066\n",
            "cmd_c_loss:0.04354694113135338\n",
            "cmd_t_loss:1.1300294399261475\n",
            "r_loss:0.2721453011035919\n",
            "accuracy_t:0.9781591296195984\n",
            "valid accuracy: 0.672\n",
            "t_loss:0.32735687494277954\n",
            "cmd_c_loss:0.02188858948647976\n",
            "cmd_t_loss:1.1753079891204834\n",
            "r_loss:0.26333141326904297\n",
            "accuracy_t:0.9781591296195984\n",
            "valid accuracy: 0.672\n",
            "t_loss:0.3159619867801666\n",
            "cmd_c_loss:0.047220755368471146\n",
            "cmd_t_loss:1.2218273878097534\n",
            "r_loss:0.254335880279541\n",
            "accuracy_t:0.9812792539596558\n",
            "valid accuracy: 0.672\n",
            "t_loss:0.3046380579471588\n",
            "cmd_c_loss:0.024862907826900482\n",
            "cmd_t_loss:1.2695651054382324\n",
            "r_loss:0.24613362550735474\n",
            "accuracy_t:0.9812792539596558\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.674\n",
            "t_loss:0.29342490434646606\n",
            "cmd_c_loss:0.051015496253967285\n",
            "cmd_t_loss:1.3185155391693115\n",
            "r_loss:0.2378808706998825\n",
            "accuracy_t:0.9859594106674194\n",
            "valid accuracy: 0.672\n",
            "t_loss:0.2823443114757538\n",
            "cmd_c_loss:0.028170978650450706\n",
            "cmd_t_loss:1.3686649799346924\n",
            "r_loss:0.230320006608963\n",
            "accuracy_t:0.9875195026397705\n",
            "valid accuracy: 0.67\n",
            "t_loss:0.27142491936683655\n",
            "cmd_c_loss:0.054831285029649734\n",
            "cmd_t_loss:1.4199893474578857\n",
            "r_loss:0.22281870245933533\n",
            "accuracy_t:0.9875195026397705\n",
            "valid accuracy: 0.674\n",
            "t_loss:0.26070746779441833\n",
            "cmd_c_loss:0.03175969794392586\n",
            "cmd_t_loss:1.4724763631820679\n",
            "r_loss:0.21592532098293304\n",
            "accuracy_t:0.9906396269798279\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.678\n",
            "t_loss:0.25021421909332275\n",
            "cmd_c_loss:0.05867939442396164\n",
            "cmd_t_loss:1.526106357574463\n",
            "r_loss:0.20917652547359467\n",
            "accuracy_t:0.9906396269798279\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.682\n",
            "t_loss:0.2399754822254181\n",
            "cmd_c_loss:0.03566857427358627\n",
            "cmd_t_loss:1.580857276916504\n",
            "r_loss:0.2029677927494049\n",
            "accuracy_t:0.9937597513198853\n",
            "valid accuracy: 0.682\n",
            "t_loss:0.23001094162464142\n",
            "cmd_c_loss:0.06268905848264694\n",
            "cmd_t_loss:1.6367065906524658\n",
            "r_loss:0.1969699114561081\n",
            "accuracy_t:0.9953197836875916\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.686\n",
            "t_loss:0.2203442007303238\n",
            "cmd_c_loss:0.03996863588690758\n",
            "cmd_t_loss:1.6936482191085815\n",
            "r_loss:0.19145001471042633\n",
            "accuracy_t:0.9953197836875916\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.692\n",
            "t_loss:0.21098491549491882\n",
            "cmd_c_loss:0.0669938251376152\n",
            "cmd_t_loss:1.751639485359192\n",
            "r_loss:0.18619689345359802\n",
            "accuracy_t:0.9953197836875916\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.698\n",
            "t_loss:0.2019464373588562\n",
            "cmd_c_loss:0.04473156854510307\n",
            "cmd_t_loss:1.8106797933578491\n",
            "r_loss:0.18135607242584229\n",
            "accuracy_t:0.9968798756599426\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.702\n",
            "t_loss:0.19324007630348206\n",
            "cmd_c_loss:0.07172483950853348\n",
            "cmd_t_loss:1.870735764503479\n",
            "r_loss:0.17682965099811554\n",
            "accuracy_t:0.9968798756599426\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.704\n",
            "t_loss:0.18488681316375732\n",
            "cmd_c_loss:0.05002022907137871\n",
            "cmd_t_loss:1.9317848682403564\n",
            "r_loss:0.17264387011528015\n",
            "accuracy_t:0.9968798756599426\n",
            "valid accuracy: 0.704\n",
            "t_loss:0.176900252699852\n",
            "cmd_c_loss:0.0769796371459961\n",
            "cmd_t_loss:1.9938135147094727\n",
            "r_loss:0.16880910098552704\n",
            "accuracy_t:0.9968798756599426\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.706\n",
            "t_loss:0.169266015291214\n",
            "cmd_c_loss:0.055855777114629745\n",
            "cmd_t_loss:2.0567984580993652\n",
            "r_loss:0.1652388572692871\n",
            "accuracy_t:0.9968798756599426\n",
            "valid accuracy: 0.706\n",
            "t_loss:0.1619955152273178\n",
            "cmd_c_loss:0.08270146697759628\n",
            "cmd_t_loss:2.1207244396209717\n",
            "r_loss:0.16204538941383362\n",
            "accuracy_t:0.9968798756599426\n",
            "valid accuracy: 0.704\n",
            "t_loss:0.15507829189300537\n",
            "cmd_c_loss:0.06209277734160423\n",
            "cmd_t_loss:2.1855204105377197\n",
            "r_loss:0.15903927385807037\n",
            "accuracy_t:0.9968798756599426\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.708\n",
            "t_loss:0.1485348641872406\n",
            "cmd_c_loss:0.08866719156503677\n",
            "cmd_t_loss:2.2511603832244873\n",
            "r_loss:0.1564140021800995\n",
            "accuracy_t:0.9968798756599426\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.14234398305416107\n",
            "cmd_c_loss:0.06853203475475311\n",
            "cmd_t_loss:2.317589521408081\n",
            "r_loss:0.15391093492507935\n",
            "accuracy_t:0.9968798756599426\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.13649627566337585\n",
            "cmd_c_loss:0.09480255097150803\n",
            "cmd_t_loss:2.3847036361694336\n",
            "r_loss:0.15177461504936218\n",
            "accuracy_t:0.9968798756599426\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.13100069761276245\n",
            "cmd_c_loss:0.07502161711454391\n",
            "cmd_t_loss:2.4524571895599365\n",
            "r_loss:0.14970244467258453\n",
            "accuracy_t:0.9968798756599426\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.12584207952022552\n",
            "cmd_c_loss:0.10095446556806564\n",
            "cmd_t_loss:2.520779848098755\n",
            "r_loss:0.1479770690202713\n",
            "accuracy_t:0.9984399080276489\n",
            "valid accuracy: 0.708\n",
            "t_loss:0.12101148068904877\n",
            "cmd_c_loss:0.08145876228809357\n",
            "cmd_t_loss:2.5895605087280273\n",
            "r_loss:0.14625345170497894\n",
            "accuracy_t:0.9984399080276489\n",
            "valid accuracy: 0.706\n",
            "t_loss:0.1164860725402832\n",
            "cmd_c_loss:0.10731799155473709\n",
            "cmd_t_loss:2.6587107181549072\n",
            "r_loss:0.14486663043498993\n",
            "accuracy_t:0.9984399080276489\n",
            "valid accuracy: 0.708\n",
            "t_loss:0.11227383464574814\n",
            "cmd_c_loss:0.08837202191352844\n",
            "cmd_t_loss:2.7281363010406494\n",
            "r_loss:0.14341294765472412\n",
            "accuracy_t:0.9984399080276489\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.1083381250500679\n",
            "cmd_c_loss:0.11438854038715363\n",
            "cmd_t_loss:2.797755241394043\n",
            "r_loss:0.14230449497699738\n",
            "accuracy_t:0.9984399080276489\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.10465540736913681\n",
            "cmd_c_loss:0.09604833275079727\n",
            "cmd_t_loss:2.8674678802490234\n",
            "r_loss:0.1410558521747589\n",
            "accuracy_t:0.9984399080276489\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.10121916234493256\n",
            "cmd_c_loss:0.12211217731237411\n",
            "cmd_t_loss:2.937152624130249\n",
            "r_loss:0.14016760885715485\n",
            "accuracy_t:0.9984399080276489\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.09799756109714508\n",
            "cmd_c_loss:0.1043086051940918\n",
            "cmd_t_loss:3.0067241191864014\n",
            "r_loss:0.13907352089881897\n",
            "accuracy_t:0.9984399080276489\n",
            "valid accuracy: 0.708\n",
            "t_loss:0.09501457959413528\n",
            "cmd_c_loss:0.13004392385482788\n",
            "cmd_t_loss:3.076117515563965\n",
            "r_loss:0.1383557766675949\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.09219735860824585\n",
            "cmd_c_loss:0.11253833025693893\n",
            "cmd_t_loss:3.1452150344848633\n",
            "r_loss:0.13738887012004852\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.08957378566265106\n",
            "cmd_c_loss:0.13740617036819458\n",
            "cmd_t_loss:3.2139394283294678\n",
            "r_loss:0.13680392503738403\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.08710974454879761\n",
            "cmd_c_loss:0.12049888074398041\n",
            "cmd_t_loss:3.282111644744873\n",
            "r_loss:0.13594608008861542\n",
            "accuracy_t:1.0\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.712\n",
            "t_loss:0.08479531854391098\n",
            "cmd_c_loss:0.14473116397857666\n",
            "cmd_t_loss:3.349688768386841\n",
            "r_loss:0.13546815514564514\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.712\n",
            "t_loss:0.08263376355171204\n",
            "cmd_c_loss:0.12885107100009918\n",
            "cmd_t_loss:3.4165449142456055\n",
            "r_loss:0.13469906151294708\n",
            "accuracy_t:1.0\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.714\n",
            "t_loss:0.08059941977262497\n",
            "cmd_c_loss:0.1525086909532547\n",
            "cmd_t_loss:3.482658863067627\n",
            "r_loss:0.13431647419929504\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.07864096015691757\n",
            "cmd_c_loss:0.13735783100128174\n",
            "cmd_t_loss:3.5478622913360596\n",
            "r_loss:0.1336212307214737\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.07681204378604889\n",
            "cmd_c_loss:0.1605328470468521\n",
            "cmd_t_loss:3.6120429039001465\n",
            "r_loss:0.133321151137352\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.704\n",
            "t_loss:0.07507374882698059\n",
            "cmd_c_loss:0.14576469361782074\n",
            "cmd_t_loss:3.675178289413452\n",
            "r_loss:0.13269896805286407\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.704\n",
            "t_loss:0.07345322519540787\n",
            "cmd_c_loss:0.16848459839820862\n",
            "cmd_t_loss:3.7373015880584717\n",
            "r_loss:0.13247309625148773\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.07190004736185074\n",
            "cmd_c_loss:0.1535624861717224\n",
            "cmd_t_loss:3.798210620880127\n",
            "r_loss:0.13192105293273926\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.712\n",
            "t_loss:0.07039525359869003\n",
            "cmd_c_loss:0.17567048966884613\n",
            "cmd_t_loss:3.857874870300293\n",
            "r_loss:0.13176225125789642\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.714\n",
            "t_loss:0.0690443366765976\n",
            "cmd_c_loss:0.1602705419063568\n",
            "cmd_t_loss:3.9162824153900146\n",
            "r_loss:0.13126543164253235\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.708\n",
            "t_loss:0.06773297488689423\n",
            "cmd_c_loss:0.18176843225955963\n",
            "cmd_t_loss:3.9732351303100586\n",
            "r_loss:0.13118262588977814\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.714\n",
            "t_loss:0.06657318770885468\n",
            "cmd_c_loss:0.16590149700641632\n",
            "cmd_t_loss:4.028890132904053\n",
            "r_loss:0.13071812689304352\n",
            "accuracy_t:1.0\n",
            "Save model...\n",
            "Done!\n",
            "valid accuracy: 0.718\n",
            "t_loss:0.06617862731218338\n",
            "cmd_c_loss:0.18677839636802673\n",
            "cmd_t_loss:4.083185195922852\n",
            "r_loss:0.1307150274515152\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.698\n",
            "t_loss:0.06650568544864655\n",
            "cmd_c_loss:0.17025966942310333\n",
            "cmd_t_loss:4.135663986206055\n",
            "r_loss:0.13027474284172058\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.71\n",
            "t_loss:0.06849046796560287\n",
            "cmd_c_loss:0.1894533783197403\n",
            "cmd_t_loss:4.186546325683594\n",
            "r_loss:0.13036739826202393\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.692\n",
            "t_loss:0.07094745337963104\n",
            "cmd_c_loss:0.17133060097694397\n",
            "cmd_t_loss:4.234277725219727\n",
            "r_loss:0.12995564937591553\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.712\n",
            "t_loss:0.07532502710819244\n",
            "cmd_c_loss:0.18672747910022736\n",
            "cmd_t_loss:4.281743049621582\n",
            "r_loss:0.1301385909318924\n",
            "accuracy_t:0.9984399080276489\n",
            "valid accuracy: 0.668\n",
            "t_loss:0.0814371407032013\n",
            "cmd_c_loss:0.1670006811618805\n",
            "cmd_t_loss:4.322457313537598\n",
            "r_loss:0.12976011633872986\n",
            "accuracy_t:0.9984399080276489\n",
            "valid accuracy: 0.696\n",
            "t_loss:0.08588030934333801\n",
            "cmd_c_loss:0.17887108027935028\n",
            "cmd_t_loss:4.369986534118652\n",
            "r_loss:0.12994536757469177\n",
            "accuracy_t:0.9937597513198853\n",
            "valid accuracy: 0.65\n",
            "t_loss:0.08797633647918701\n",
            "cmd_c_loss:0.15986213088035583\n",
            "cmd_t_loss:4.403670310974121\n",
            "r_loss:0.12956850230693817\n",
            "accuracy_t:0.9968798756599426\n",
            "valid accuracy: 0.696\n",
            "t_loss:0.07966738939285278\n",
            "cmd_c_loss:0.16952887177467346\n",
            "cmd_t_loss:4.4574689865112305\n",
            "r_loss:0.12960104644298553\n",
            "accuracy_t:0.9968798756599426\n",
            "valid accuracy: 0.666\n",
            "t_loss:0.06421301513910294\n",
            "cmd_c_loss:0.14948610961437225\n",
            "cmd_t_loss:4.496682167053223\n",
            "r_loss:0.1291593760251999\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.714\n",
            "t_loss:0.055551156401634216\n",
            "cmd_c_loss:0.15332366526126862\n",
            "cmd_t_loss:4.549679279327393\n",
            "r_loss:0.12906497716903687\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.696\n",
            "t_loss:0.05048755928874016\n",
            "cmd_c_loss:0.13554100692272186\n",
            "cmd_t_loss:4.588969707489014\n",
            "r_loss:0.12858769297599792\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.714\n",
            "t_loss:0.051622942090034485\n",
            "cmd_c_loss:0.14474929869174957\n",
            "cmd_t_loss:4.629247188568115\n",
            "r_loss:0.1284504234790802\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.694\n",
            "t_loss:0.05034499987959862\n",
            "cmd_c_loss:0.1292259693145752\n",
            "cmd_t_loss:4.664462089538574\n",
            "r_loss:0.12804226577281952\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.706\n",
            "t_loss:0.05188388377428055\n",
            "cmd_c_loss:0.13494621217250824\n",
            "cmd_t_loss:4.701601028442383\n",
            "r_loss:0.12784603238105774\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.696\n",
            "t_loss:0.05087484419345856\n",
            "cmd_c_loss:0.12144618481397629\n",
            "cmd_t_loss:4.735110282897949\n",
            "r_loss:0.12752854824066162\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.706\n",
            "t_loss:0.05308312550187111\n",
            "cmd_c_loss:0.12812241911888123\n",
            "cmd_t_loss:4.770555019378662\n",
            "r_loss:0.12735842168331146\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.698\n",
            "t_loss:0.05252597853541374\n",
            "cmd_c_loss:0.1212698295712471\n",
            "cmd_t_loss:4.801390647888184\n",
            "r_loss:0.1271149069070816\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.704\n",
            "t_loss:0.057452037930488586\n",
            "cmd_c_loss:0.12842115759849548\n",
            "cmd_t_loss:4.83488130569458\n",
            "r_loss:0.12701286375522614\n",
            "accuracy_t:1.0\n",
            "valid accuracy: 0.674\n",
            "t_loss:0.061078183352947235\n",
            "cmd_c_loss:0.1158146932721138\n",
            "cmd_t_loss:4.857125282287598\n",
            "r_loss:0.1268579661846161\n",
            "accuracy_t:1.0\n",
            "best_result:0.7179999947547913\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_target_0_to_1.pkl\n",
            "test_accuracy:0.6910408139228821\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_common_0_to_1.pkl\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_target_0_to_1.pkl\n",
            "pos num: 5\n",
            "neg num: 5\n",
            "pos num: 9\n",
            "neg num: 10\n",
            "unlabelled num: 1345\n",
            "1345\n",
            "Train combined model...\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_common_0_to_1.pkl\n",
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/output/Cotrain_target_0_to_1.pkl\n",
            "valid accuracy: 0.824\n",
            "test accuracy: 0.7984189723320159\n",
            "best_result:0.844\n",
            "Test accuracy:0.8185111989459816\n",
            "Reslut from 0 domain to 1 doamin:None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}